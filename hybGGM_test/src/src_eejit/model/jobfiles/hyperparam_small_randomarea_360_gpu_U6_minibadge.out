SBATCH job
Started 14/11/2024 11:28:46
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
expandable_segments:True
UNet6 with 1 10 0.0001 4 360 start at Thu Nov 14 11:28:47 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.819812536239624
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9529114365577698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.3863213062286377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.270076036453247
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |  63609 MiB |  59799 MiB |
|       from large pool |   3801 MiB |   5814 MiB |  63366 MiB |  59564 MiB |
|       from small pool |      7 MiB |     24 MiB |    242 MiB |    235 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |  63609 MiB |  59799 MiB |
|       from large pool |   3801 MiB |   5814 MiB |  63366 MiB |  59564 MiB |
|       from small pool |      7 MiB |     24 MiB |    242 MiB |    235 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |  63608 MiB |  59799 MiB |
|       from large pool |   3801 MiB |   5814 MiB |  63366 MiB |  59564 MiB |
|       from small pool |      7 MiB |     24 MiB |    242 MiB |    235 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    2230    |    1909    |
|       from large pool |      47    |     102    |     995    |     948    |
|       from small pool |     274    |     352    |    1235    |     961    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    2230    |    1909    |
|       from large pool |      47    |     102    |     995    |     948    |
|       from small pool |     274    |     352    |    1235    |     961    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6869325637817383
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46848130226135254
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5421428680419922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5739983320236206
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    468 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    468 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    467 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    4262    |    3941    |
|       from large pool |      47    |     102    |    1968    |    1921    |
|       from small pool |     274    |     352    |    2294    |    2020    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    4262    |    3941    |
|       from large pool |      47    |     102    |    1968    |    1921    |
|       from small pool |     274    |     352    |    2294    |    2020    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2186293601989746
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5850042104721069
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7131848931312561
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 186970 MiB | 183161 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 186278 MiB | 182476 MiB |
|       from small pool |      7 MiB |     24 MiB |    692 MiB |    685 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 186970 MiB | 183161 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 186278 MiB | 182476 MiB |
|       from small pool |      7 MiB |     24 MiB |    692 MiB |    685 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 186970 MiB | 183161 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 186278 MiB | 182476 MiB |
|       from small pool |      7 MiB |     24 MiB |    692 MiB |    685 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    6271    |    5950    |
|       from large pool |      47    |     102    |    2936    |    2889    |
|       from small pool |     274    |     352    |    3335    |    3061    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    6271    |    5950    |
|       from large pool |      47    |     102    |    2936    |    2889    |
|       from small pool |     274    |     352    |    3335    |    3061    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5979920029640198
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.130446195602417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47118911147117615
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 248664 MiB | 244855 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 248664 MiB | 244855 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 248664 MiB | 244854 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    8280    |    7959    |
|       from large pool |      47    |     102    |    3908    |    3861    |
|       from small pool |     274    |     352    |    4372    |    4098    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    8280    |    7959    |
|       from large pool |      47    |     102    |    3908    |    3861    |
|       from small pool |     274    |     352    |    4372    |    4098    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5719398856163025
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.110304594039917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48696455359458923
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7697487473487854
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 310344 MiB | 306535 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 309195 MiB | 305393 MiB |
|       from small pool |      7 MiB |     24 MiB |   1148 MiB |   1141 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 310344 MiB | 306535 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 309195 MiB | 305393 MiB |
|       from small pool |      7 MiB |     24 MiB |   1148 MiB |   1141 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 310343 MiB | 306534 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 309195 MiB | 305393 MiB |
|       from small pool |      7 MiB |     24 MiB |   1148 MiB |   1140 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   10312    |    9991    |
|       from large pool |      47    |     102    |    4878    |    4831    |
|       from small pool |     274    |     352    |    5434    |    5160    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   10312    |    9991    |
|       from large pool |      47    |     102    |    4878    |    4831    |
|       from small pool |     274    |     352    |    5434    |    5160    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5989560484886169
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0078785419464111
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47610917687416077
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6136468648910522
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370673 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370673 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370672 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   12344    |   12023    |
|       from large pool |      47    |     102    |    5854    |    5807    |
|       from small pool |     274    |     352    |    6490    |    6216    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   12344    |   12023    |
|       from large pool |      47    |     102    |    5854    |    5807    |
|       from small pool |     274    |     352    |    6490    |    6216    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4699391722679138
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8132690191268921
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3295847177505493
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 433762 MiB | 429953 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 432138 MiB | 428336 MiB |
|       from small pool |      7 MiB |     24 MiB |   1624 MiB |   1617 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 433762 MiB | 429953 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 432138 MiB | 428336 MiB |
|       from small pool |      7 MiB |     24 MiB |   1624 MiB |   1617 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 433761 MiB | 429952 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 432138 MiB | 428336 MiB |
|       from small pool |      7 MiB |     24 MiB |   1623 MiB |   1616 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   14353    |   14032    |
|       from large pool |      47    |     102    |    6826    |    6779    |
|       from small pool |     274    |     352    |    7527    |    7253    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   14353    |   14032    |
|       from large pool |      47    |     102    |    6826    |    6779    |
|       from small pool |     274    |     352    |    7527    |    7253    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6827605366706848
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4973190426826477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.585635781288147
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.51414155960083
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1869 MiB |   1862 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1869 MiB |   1862 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1868 MiB |   1861 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   16385    |   16064    |
|       from large pool |      47    |     102    |    7801    |    7754    |
|       from small pool |     274    |     352    |    8584    |    8310    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   16385    |   16064    |
|       from large pool |      47    |     102    |    7801    |    7754    |
|       from small pool |     274    |     352    |    8584    |    8310    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45469796657562256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.624519407749176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 557136 MiB | 553327 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 555058 MiB | 551256 MiB |
|       from small pool |      7 MiB |     24 MiB |   2078 MiB |   2071 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 557136 MiB | 553327 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 555058 MiB | 551256 MiB |
|       from small pool |      7 MiB |     24 MiB |   2078 MiB |   2071 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 557135 MiB | 553326 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 555058 MiB | 551256 MiB |
|       from small pool |      7 MiB |     24 MiB |   2077 MiB |   2070 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   18371    |   18050    |
|       from large pool |      47    |     102    |    8769    |    8722    |
|       from small pool |     274    |     352    |    9602    |    9328    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   18371    |   18050    |
|       from large pool |      47    |     102    |    8769    |    8722    |
|       from small pool |     274    |     352    |    9602    |    9328    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9587867259979248
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6278560161590576
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49461838603019714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7044584155082703
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 618860 MiB | 615051 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612735 MiB |
|       from small pool |      7 MiB |     24 MiB |   2324 MiB |   2316 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 618860 MiB | 615051 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612735 MiB |
|       from small pool |      7 MiB |     24 MiB |   2324 MiB |   2316 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 618859 MiB | 615050 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612734 MiB |
|       from small pool |      7 MiB |     24 MiB |   2323 MiB |   2315 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   20403    |   20082    |
|       from large pool |      47    |     102    |    9745    |    9698    |
|       from small pool |     274    |     352    |   10658    |   10384    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   20403    |   20082    |
|       from large pool |      47    |     102    |    9745    |    9698    |
|       from small pool |     274    |     352    |   10658    |   10384    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5164517164230347
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4544129967689514
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 680540 MiB | 676730 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 677993 MiB | 674191 MiB |
|       from small pool |      7 MiB |     24 MiB |   2546 MiB |   2539 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 680540 MiB | 676730 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 677993 MiB | 674191 MiB |
|       from small pool |      7 MiB |     24 MiB |   2546 MiB |   2539 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 680539 MiB | 676730 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 677993 MiB | 674191 MiB |
|       from small pool |      7 MiB |     24 MiB |   2545 MiB |   2538 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   22389    |   22068    |
|       from large pool |      47    |     102    |   10713    |   10666    |
|       from small pool |     274    |     352    |   11676    |   11402    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   22389    |   22068    |
|       from large pool |      47    |     102    |   10713    |   10666    |
|       from small pool |     274    |     352    |   11676    |   11402    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.86475670337677
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47753116488456726
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5423285961151123
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 742236 MiB | 738427 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2777 MiB |   2770 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 742236 MiB | 738427 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2777 MiB |   2770 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 742235 MiB | 738426 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2776 MiB |   2769 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   24398    |   24077    |
|       from large pool |      47    |     102    |   11685    |   11638    |
|       from small pool |     274    |     352    |   12713    |   12439    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   24398    |   24077    |
|       from large pool |      47    |     102    |   11685    |   11638    |
|       from small pool |     274    |     352    |   12713    |   12439    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0763672590255737
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.039473056793213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5298306345939636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7522132992744446
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    785 GiB |    781 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    782 GiB |    778 GiB |
|       from small pool |      7 MiB |     24 MiB |      2 GiB |      2 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    785 GiB |    781 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    782 GiB |    778 GiB |
|       from small pool |      7 MiB |     24 MiB |      2 GiB |      2 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    785 GiB |    781 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    782 GiB |    778 GiB |
|       from small pool |      7 MiB |     24 MiB |      2 GiB |      2 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   26430    |   26109    |
|       from large pool |      47    |     102    |   12661    |   12614    |
|       from small pool |     274    |     352    |   13769    |   13495    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   26430    |   26109    |
|       from large pool |      47    |     102    |   12661    |   12614    |
|       from small pool |     274    |     352    |   13769    |   13495    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5095365643501282
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48460251092910767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8418570160865784
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   28439    |   28118    |
|       from large pool |      47    |     102    |   13633    |   13586    |
|       from small pool |     274    |     352    |   14806    |   14532    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   28439    |   28118    |
|       from large pool |      47    |     102    |   13633    |   13586    |
|       from small pool |     274    |     352    |   14806    |   14532    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4620964825153351
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47385135293006897
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.827709436416626
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    905 GiB |    901 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    902 GiB |    898 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    905 GiB |    901 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    902 GiB |    898 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    905 GiB |    901 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    902 GiB |    898 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   30448    |   30127    |
|       from large pool |      47    |     102    |   14604    |   14557    |
|       from small pool |     274    |     352    |   15844    |   15570    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   30448    |   30127    |
|       from large pool |      47    |     102    |   14604    |   14557    |
|       from small pool |     274    |     352    |   15844    |   15570    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2050328254699707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.6952083110809326
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.031891942024231
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2293715476989746
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   32480    |   32159    |
|       from large pool |      47    |     102    |   15572    |   15525    |
|       from small pool |     274    |     352    |   16908    |   16634    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   32480    |   32159    |
|       from large pool |      47    |     102    |   15572    |   15525    |
|       from small pool |     274    |     352    |   16908    |   16634    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49924877285957336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0482702255249023
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1026 GiB |   1022 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1022 GiB |   1018 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1026 GiB |   1022 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1022 GiB |   1018 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1026 GiB |   1022 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1022 GiB |   1018 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   34466    |   34145    |
|       from large pool |      47    |     102    |   16540    |   16493    |
|       from small pool |     274    |     352    |   17926    |   17652    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   34466    |   34145    |
|       from large pool |      47    |     102    |   16540    |   16493    |
|       from small pool |     274    |     352    |   17926    |   17652    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5716233253479004
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.473301887512207
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4562150239944458
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   36475    |   36154    |
|       from large pool |      47    |     102    |   17511    |   17464    |
|       from small pool |     274    |     352    |   18964    |   18690    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   36475    |   36154    |
|       from large pool |      47    |     102    |   17511    |   17464    |
|       from small pool |     274    |     352    |   18964    |   18690    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7648544311523438
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2041324377059937
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47707146406173706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.630420446395874
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1146 GiB |   1142 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1142 GiB |   1138 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1146 GiB |   1142 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1142 GiB |   1138 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1146 GiB |   1142 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1142 GiB |   1138 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   38507    |   38186    |
|       from large pool |      47    |     102    |   18487    |   18440    |
|       from small pool |     274    |     352    |   20020    |   19746    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   38507    |   38186    |
|       from large pool |      47    |     102    |   18487    |   18440    |
|       from small pool |     274    |     352    |   20020    |   19746    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.144110083580017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8894302248954773
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44735756516456604
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   40516    |   40195    |
|       from large pool |      47    |     102    |   19459    |   19412    |
|       from small pool |     274    |     352    |   21057    |   20783    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   40516    |   40195    |
|       from large pool |      47    |     102    |   19459    |   19412    |
|       from small pool |     274    |     352    |   21057    |   20783    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5024728775024414
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5545372366905212
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7979448437690735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5833857655525208
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1267 GiB |   1263 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1262 GiB |   1258 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1267 GiB |   1263 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1262 GiB |   1258 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1267 GiB |   1263 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1262 GiB |   1258 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   42548    |   42227    |
|       from large pool |      47    |     102    |   20434    |   20387    |
|       from small pool |     274    |     352    |   22114    |   21840    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   42548    |   42227    |
|       from large pool |      47    |     102    |   20434    |   20387    |
|       from small pool |     274    |     352    |   22114    |   21840    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5818025469779968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5606418251991272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5785847902297974
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   44557    |   44236    |
|       from large pool |      47    |     102    |   21406    |   21359    |
|       from small pool |     274    |     352    |   23151    |   22877    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   44557    |   44236    |
|       from large pool |      47    |     102    |   21406    |   21359    |
|       from small pool |     274    |     352    |   23151    |   22877    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1468136310577393
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.450875163078308
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6367223858833313
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5154714584350586
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1387 GiB |   1383 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1382 GiB |   1378 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1387 GiB |   1383 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1382 GiB |   1378 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1387 GiB |   1383 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1382 GiB |   1378 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   46589    |   46268    |
|       from large pool |      47    |     102    |   22381    |   22334    |
|       from small pool |     274    |     352    |   24208    |   23934    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   46589    |   46268    |
|       from large pool |      47    |     102    |   22381    |   22334    |
|       from small pool |     274    |     352    |   24208    |   23934    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5152022838592529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.528084397315979
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9421567320823669
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6088292002677917
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   48621    |   48300    |
|       from large pool |      47    |     102    |   23356    |   23309    |
|       from small pool |     274    |     352    |   25265    |   24991    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   48621    |   48300    |
|       from large pool |      47    |     102    |   23356    |   23309    |
|       from small pool |     274    |     352    |   25265    |   24991    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6201375126838684
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6374879479408264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5473155975341797
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5828478932380676
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1508 GiB |   1504 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1502 GiB |   1498 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1508 GiB |   1504 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1502 GiB |   1498 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1508 GiB |   1504 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1502 GiB |   1498 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   50653    |   50332    |
|       from large pool |      47    |     102    |   24331    |   24284    |
|       from small pool |     274    |     352    |   26322    |   26048    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   50653    |   50332    |
|       from large pool |      47    |     102    |   24331    |   24284    |
|       from small pool |     274    |     352    |   26322    |   26048    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6870982050895691
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5076937675476074
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.2537639141082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6441835165023804
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   52685    |   52364    |
|       from large pool |      47    |     102    |   25307    |   25260    |
|       from small pool |     274    |     352    |   27378    |   27104    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   52685    |   52364    |
|       from large pool |      47    |     102    |   25307    |   25260    |
|       from small pool |     274    |     352    |   27378    |   27104    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4633548855781555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6354823112487793
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5546389818191528
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1628 GiB |   1624 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1622 GiB |   1618 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1628 GiB |   1624 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1622 GiB |   1618 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1628 GiB |   1624 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1622 GiB |   1618 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   54694    |   54373    |
|       from large pool |      47    |     102    |   26278    |   26231    |
|       from small pool |     274    |     352    |   28416    |   28142    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   54694    |   54373    |
|       from large pool |      47    |     102    |   26278    |   26231    |
|       from small pool |     274    |     352    |   28416    |   28142    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.452296257019043
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7913306355476379
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6001733541488647
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6769973039627075
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   56726    |   56405    |
|       from large pool |      47    |     102    |   27250    |   27203    |
|       from small pool |     274    |     352    |   29476    |   29202    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   56726    |   56405    |
|       from large pool |      47    |     102    |   27250    |   27203    |
|       from small pool |     274    |     352    |   29476    |   29202    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4553399682044983
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8695197105407715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4755610227584839
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6617066860198975
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1749 GiB |   1745 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1742 GiB |   1738 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1749 GiB |   1745 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1742 GiB |   1738 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1749 GiB |   1745 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1742 GiB |   1738 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   58758    |   58437    |
|       from large pool |      47    |     102    |   28226    |   28179    |
|       from small pool |     274    |     352    |   30532    |   30258    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   58758    |   58437    |
|       from large pool |      47    |     102    |   28226    |   28179    |
|       from small pool |     274    |     352    |   30532    |   30258    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5238131284713745
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5245546698570251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   60744    |   60423    |
|       from large pool |      47    |     102    |   29194    |   29147    |
|       from small pool |     274    |     352    |   31550    |   31276    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   60744    |   60423    |
|       from large pool |      47    |     102    |   29194    |   29147    |
|       from small pool |     274    |     352    |   31550    |   31276    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5921008586883545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9015032052993774
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.9101366996765137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6102474927902222
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1869 GiB |   1865 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1862 GiB |   1858 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1869 GiB |   1865 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1862 GiB |   1858 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1869 GiB |   1865 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1862 GiB |   1858 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   62776    |   62455    |
|       from large pool |      47    |     102    |   30169    |   30122    |
|       from small pool |     274    |     352    |   32607    |   32333    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   62776    |   62455    |
|       from large pool |      47    |     102    |   30169    |   30122    |
|       from small pool |     274    |     352    |   32607    |   32333    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46769586205482483
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5767532587051392
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5057856440544128
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9696930050849915
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   64808    |   64487    |
|       from large pool |      47    |     102    |   31141    |   31094    |
|       from small pool |     274    |     352    |   33667    |   33393    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   64808    |   64487    |
|       from large pool |      47    |     102    |   31141    |   31094    |
|       from small pool |     274    |     352    |   33667    |   33393    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.587297797203064
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0258359909057617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5137578248977661
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1990 GiB |   1986 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1982 GiB |   1978 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1990 GiB |   1986 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1982 GiB |   1978 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1990 GiB |   1986 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1982 GiB |   1978 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   66817    |   66496    |
|       from large pool |      47    |     102    |   32109    |   32062    |
|       from small pool |     274    |     352    |   34708    |   34434    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   66817    |   66496    |
|       from large pool |      47    |     102    |   32109    |   32062    |
|       from small pool |     274    |     352    |   34708    |   34434    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.074904203414917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4704446494579315
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8295745253562927
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5119169354438782
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   68849    |   68528    |
|       from large pool |      47    |     102    |   33084    |   33037    |
|       from small pool |     274    |     352    |   35765    |   35491    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   68849    |   68528    |
|       from large pool |      47    |     102    |   33084    |   33037    |
|       from small pool |     274    |     352    |   35765    |   35491    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7610528469085693
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9171606302261353
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6281032562255859
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2110 GiB |   2107 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2102 GiB |   2099 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2110 GiB |   2107 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2102 GiB |   2099 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2110 GiB |   2107 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2102 GiB |   2099 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   70858    |   70537    |
|       from large pool |      47    |     102    |   34056    |   34009    |
|       from small pool |     274    |     352    |   36802    |   36528    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   70858    |   70537    |
|       from large pool |      47    |     102    |   34056    |   34009    |
|       from small pool |     274    |     352    |   36802    |   36528    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5952099561691284
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6960201859474182
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6789958477020264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4713931977748871
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   72890    |   72569    |
|       from large pool |      47    |     102    |   35027    |   34980    |
|       from small pool |     274    |     352    |   37863    |   37589    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   72890    |   72569    |
|       from large pool |      47    |     102    |   35027    |   34980    |
|       from small pool |     274    |     352    |   37863    |   37589    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4038227796554565
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.578901469707489
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48654380440711975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7137617468833923
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2231 GiB |   2227 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2222 GiB |   2219 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2231 GiB |   2227 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2222 GiB |   2219 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2231 GiB |   2227 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2222 GiB |   2219 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   74922    |   74601    |
|       from large pool |      47    |     102    |   35997    |   35950    |
|       from small pool |     274    |     352    |   38925    |   38651    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   74922    |   74601    |
|       from large pool |      47    |     102    |   35997    |   35950    |
|       from small pool |     274    |     352    |   38925    |   38651    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.586050271987915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4967315196990967
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   76908    |   76587    |
|       from large pool |      47    |     102    |   36964    |   36917    |
|       from small pool |     274    |     352    |   39944    |   39670    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   76908    |   76587    |
|       from large pool |      47    |     102    |   36964    |   36917    |
|       from small pool |     274    |     352    |   39944    |   39670    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.397573947906494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7835416197776794
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.8879265785217285
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5795229077339172
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2351 GiB |   2347 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2342 GiB |   2339 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2351 GiB |   2347 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2342 GiB |   2339 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2351 GiB |   2347 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2342 GiB |   2339 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   78940    |   78619    |
|       from large pool |      47    |     102    |   37940    |   37893    |
|       from small pool |     274    |     352    |   41000    |   40726    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   78940    |   78619    |
|       from large pool |      47    |     102    |   37940    |   37893    |
|       from small pool |     274    |     352    |   41000    |   40726    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46186575293540955
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6076156497001648
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6935876607894897
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   80949    |   80628    |
|       from large pool |      47    |     102    |   38912    |   38865    |
|       from small pool |     274    |     352    |   42037    |   41763    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   80949    |   80628    |
|       from large pool |      47    |     102    |   38912    |   38865    |
|       from small pool |     274    |     352    |   42037    |   41763    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5685961842536926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6882216334342957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5235651135444641
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.561565101146698
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2472 GiB |   2468 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2462 GiB |   2459 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2472 GiB |   2468 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2462 GiB |   2459 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2472 GiB |   2468 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2462 GiB |   2459 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   82981    |   82660    |
|       from large pool |      47    |     102    |   39883    |   39836    |
|       from small pool |     274    |     352    |   43098    |   42824    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   82981    |   82660    |
|       from large pool |      47    |     102    |   39883    |   39836    |
|       from small pool |     274    |     352    |   43098    |   42824    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5332809686660767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7282124757766724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.192653775215149
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4065489768981934
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   85013    |   84692    |
|       from large pool |      47    |     102    |   40858    |   40811    |
|       from small pool |     274    |     352    |   44155    |   43881    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   85013    |   84692    |
|       from large pool |      47    |     102    |   40858    |   40811    |
|       from small pool |     274    |     352    |   44155    |   43881    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.482292503118515
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0171582698822021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.007269859313965
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48738574981689453
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2592 GiB |   2589 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2582 GiB |   2579 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2592 GiB |   2589 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2582 GiB |   2579 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2592 GiB |   2589 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2582 GiB |   2579 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   87045    |   86724    |
|       from large pool |      47    |     102    |   41834    |   41787    |
|       from small pool |     274    |     352    |   45211    |   44937    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   87045    |   86724    |
|       from large pool |      47    |     102    |   41834    |   41787    |
|       from small pool |     274    |     352    |   45211    |   44937    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.58840799331665
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6192532181739807
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   89031    |   88710    |
|       from large pool |      47    |     102    |   42802    |   42755    |
|       from small pool |     274    |     352    |   46229    |   45955    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   89031    |   88710    |
|       from large pool |      47    |     102    |   42802    |   42755    |
|       from small pool |     274    |     352    |   46229    |   45955    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7556139826774597
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9493 MiB |   3682 GiB |   3676 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3668 GiB |   3662 GiB |
|       from small pool |      9 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9493 MiB |   3682 GiB |   3676 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3668 GiB |   3662 GiB |
|       from small pool |      9 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9493 MiB |   3682 GiB |   3676 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3668 GiB |   3662 GiB |
|       from small pool |      8 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9542 MiB |   9542 MiB |   3728 MiB |
|       from large pool |   5800 MiB |   9500 MiB |   9500 MiB |   3700 MiB |
|       from small pool |     14 MiB |     42 MiB |     42 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     672    |  117058    |  116623    |
|       from large pool |      69    |     178    |   61341    |   61272    |
|       from small pool |     366    |     557    |   55717    |   55351    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     672    |  117058    |  116623    |
|       from large pool |      69    |     178    |   61341    |   61272    |
|       from small pool |     366    |     557    |   55717    |   55351    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8054918646812439
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8987407088279724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.2919647693634033
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7529160976409912
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3742 GiB |   3735 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3728 GiB |   3720 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3742 GiB |   3735 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3728 GiB |   3720 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3742 GiB |   3735 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3728 GiB |   3720 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  119090    |  118533    |
|       from large pool |      93    |     178    |   62313    |   62220    |
|       from small pool |     464    |     557    |   56777    |   56313    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  119090    |  118533    |
|       from large pool |      93    |     178    |   62313    |   62220    |
|       from small pool |     464    |     557    |   56777    |   56313    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.619989275932312
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40582361817359924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41985389590263367
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4629015922546387
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3802 GiB |   3795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3788 GiB |   3780 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3802 GiB |   3795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3788 GiB |   3780 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3802 GiB |   3795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3788 GiB |   3780 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  121122    |  120565    |
|       from large pool |      93    |     178    |   63286    |   63193    |
|       from small pool |     464    |     557    |   57836    |   57372    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  121122    |  120565    |
|       from large pool |      93    |     178    |   63286    |   63193    |
|       from small pool |     464    |     557    |   57836    |   57372    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8853329420089722
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5445839762687683
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.674015462398529
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3862 GiB |   3855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3848 GiB |   3840 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3862 GiB |   3855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3848 GiB |   3840 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3862 GiB |   3855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3848 GiB |   3840 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  123131    |  122574    |
|       from large pool |      93    |     178    |   64254    |   64161    |
|       from small pool |     464    |     557    |   58877    |   58413    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  123131    |  122574    |
|       from large pool |      93    |     178    |   64254    |   64161    |
|       from small pool |     464    |     557    |   58877    |   58413    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4879615008831024
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0255072116851807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42342409491539
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3923 GiB |   3915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3908 GiB |   3900 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3923 GiB |   3915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3908 GiB |   3900 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3923 GiB |   3915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3908 GiB |   3900 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  125140    |  124583    |
|       from large pool |      93    |     178    |   65226    |   65133    |
|       from small pool |     464    |     557    |   59914    |   59450    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  125140    |  124583    |
|       from large pool |      93    |     178    |   65226    |   65133    |
|       from small pool |     464    |     557    |   59914    |   59450    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4279136657714844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7758976221084595
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3747066557407379
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6917065382003784
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3983 GiB |   3976 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3968 GiB |   3960 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3983 GiB |   3976 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3968 GiB |   3960 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3983 GiB |   3976 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3968 GiB |   3960 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  127172    |  126615    |
|       from large pool |      93    |     178    |   66196    |   66103    |
|       from small pool |     464    |     557    |   60976    |   60512    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  127172    |  126615    |
|       from large pool |      93    |     178    |   66196    |   66103    |
|       from small pool |     464    |     557    |   60976    |   60512    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4910371005535126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9175930619239807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41859519481658936
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5455162525177002
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4043 GiB |   4036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4028 GiB |   4020 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4043 GiB |   4036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4028 GiB |   4020 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4043 GiB |   4036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4028 GiB |   4020 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  129204    |  128647    |
|       from large pool |      93    |     178    |   67172    |   67079    |
|       from small pool |     464    |     557    |   62032    |   61568    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  129204    |  128647    |
|       from large pool |      93    |     178    |   67172    |   67079    |
|       from small pool |     464    |     557    |   62032    |   61568    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4035603404045105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7738136053085327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.258652925491333
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4103 GiB |   4096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4088 GiB |   4080 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4103 GiB |   4096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4088 GiB |   4080 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4103 GiB |   4096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4088 GiB |   4080 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  131213    |  130656    |
|       from large pool |      93    |     178    |   68144    |   68051    |
|       from small pool |     464    |     557    |   63069    |   62605    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  131213    |  130656    |
|       from large pool |      93    |     178    |   68144    |   68051    |
|       from small pool |     464    |     557    |   63069    |   62605    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6637643575668335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4387687146663666
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5114082098007202
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4561054706573486
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4164 GiB |   4156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4148 GiB |   4140 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4164 GiB |   4156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4148 GiB |   4140 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4164 GiB |   4156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4148 GiB |   4140 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  133245    |  132688    |
|       from large pool |      93    |     178    |   69119    |   69026    |
|       from small pool |     464    |     557    |   64126    |   63662    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  133245    |  132688    |
|       from large pool |      93    |     178    |   69119    |   69026    |
|       from small pool |     464    |     557    |   64126    |   63662    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3829658627510071
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.524093747138977
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4224 GiB |   4217 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4208 GiB |   4200 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4224 GiB |   4217 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4208 GiB |   4200 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4224 GiB |   4217 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4208 GiB |   4200 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  135231    |  134674    |
|       from large pool |      93    |     178    |   70087    |   69994    |
|       from small pool |     464    |     557    |   65144    |   64680    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  135231    |  134674    |
|       from large pool |      93    |     178    |   70087    |   69994    |
|       from small pool |     464    |     557    |   65144    |   64680    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9038376212120056
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5851014256477356
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4196215569972992
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6253869533538818
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4284 GiB |   4277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4268 GiB |   4260 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4284 GiB |   4277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4268 GiB |   4260 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4284 GiB |   4277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4268 GiB |   4260 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  137263    |  136706    |
|       from large pool |      93    |     178    |   71063    |   70970    |
|       from small pool |     464    |     557    |   66200    |   65736    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  137263    |  136706    |
|       from large pool |      93    |     178    |   71063    |   70970    |
|       from small pool |     464    |     557    |   66200    |   65736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46743452548980713
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3872469365596771
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4344 GiB |   4337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4328 GiB |   4320 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4344 GiB |   4337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4328 GiB |   4320 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4344 GiB |   4337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4328 GiB |   4320 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  139249    |  138692    |
|       from large pool |      93    |     178    |   72031    |   71938    |
|       from small pool |     464    |     557    |   67218    |   66754    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  139249    |  138692    |
|       from large pool |      93    |     178    |   72031    |   71938    |
|       from small pool |     464    |     557    |   67218    |   66754    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8338868618011475
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41059255599975586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.443751335144043
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4405 GiB |   4397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4388 GiB |   4380 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4405 GiB |   4397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4388 GiB |   4380 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4405 GiB |   4397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4388 GiB |   4380 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  141258    |  140701    |
|       from large pool |      93    |     178    |   73003    |   72910    |
|       from small pool |     464    |     557    |   68255    |   67791    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  141258    |  140701    |
|       from large pool |      93    |     178    |   73003    |   72910    |
|       from small pool |     464    |     557    |   68255    |   67791    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0170003175735474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.995087206363678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40507644414901733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6749089360237122
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4465 GiB |   4458 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4448 GiB |   4440 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4465 GiB |   4458 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4448 GiB |   4440 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4465 GiB |   4458 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4448 GiB |   4440 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  143290    |  142733    |
|       from large pool |      93    |     178    |   73979    |   73886    |
|       from small pool |     464    |     557    |   69311    |   68847    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  143290    |  142733    |
|       from large pool |      93    |     178    |   73979    |   73886    |
|       from small pool |     464    |     557    |   69311    |   68847    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4420895576477051
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43542855978012085
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7903597950935364
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4525 GiB |   4518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4508 GiB |   4501 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4525 GiB |   4518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4508 GiB |   4501 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4525 GiB |   4518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4508 GiB |   4501 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  145299    |  144742    |
|       from large pool |      93    |     178    |   74951    |   74858    |
|       from small pool |     464    |     557    |   70348    |   69884    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  145299    |  144742    |
|       from large pool |      93    |     178    |   74951    |   74858    |
|       from small pool |     464    |     557    |   70348    |   69884    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38722386956214905
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3567829728126526
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8009729385375977
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4585 GiB |   4578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4568 GiB |   4561 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4585 GiB |   4578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4568 GiB |   4561 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4585 GiB |   4578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4568 GiB |   4561 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  147308    |  146751    |
|       from large pool |      93    |     178    |   75922    |   75829    |
|       from small pool |     464    |     557    |   71386    |   70922    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  147308    |  146751    |
|       from large pool |      93    |     178    |   75922    |   75829    |
|       from small pool |     464    |     557    |   71386    |   70922    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1887037754058838
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5324246883392334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9487202763557434
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1619105339050293
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4646 GiB |   4638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4628 GiB |   4621 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4646 GiB |   4638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4628 GiB |   4621 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4646 GiB |   4638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4628 GiB |   4621 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  149340    |  148783    |
|       from large pool |      93    |     178    |   76890    |   76797    |
|       from small pool |     464    |     557    |   72450    |   71986    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  149340    |  148783    |
|       from large pool |      93    |     178    |   76890    |   76797    |
|       from small pool |     464    |     557    |   72450    |   71986    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4423845112323761
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9855327606201172
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4706 GiB |   4699 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4688 GiB |   4681 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4706 GiB |   4699 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4688 GiB |   4681 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4706 GiB |   4699 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4688 GiB |   4681 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  151326    |  150769    |
|       from large pool |      93    |     178    |   77858    |   77765    |
|       from small pool |     464    |     557    |   73468    |   73004    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  151326    |  150769    |
|       from large pool |      93    |     178    |   77858    |   77765    |
|       from small pool |     464    |     557    |   73468    |   73004    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4008445143699646
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.32944393157959
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3845133781433105
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4766 GiB |   4759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4748 GiB |   4741 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4766 GiB |   4759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4748 GiB |   4741 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4766 GiB |   4759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4748 GiB |   4741 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  153335    |  152778    |
|       from large pool |      93    |     178    |   78829    |   78736    |
|       from small pool |     464    |     557    |   74506    |   74042    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  153335    |  152778    |
|       from large pool |      93    |     178    |   78829    |   78736    |
|       from small pool |     464    |     557    |   74506    |   74042    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7258349061012268
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1670548915863037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4191601872444153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5944328904151917
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4826 GiB |   4819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4808 GiB |   4801 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4826 GiB |   4819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4808 GiB |   4801 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4826 GiB |   4819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4808 GiB |   4801 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  155367    |  154810    |
|       from large pool |      93    |     178    |   79805    |   79712    |
|       from small pool |     464    |     557    |   75562    |   75098    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  155367    |  154810    |
|       from large pool |      93    |     178    |   79805    |   79712    |
|       from small pool |     464    |     557    |   75562    |   75098    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1055978536605835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8371577262878418
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39751115441322327
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4887 GiB |   4879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4868 GiB |   4861 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4887 GiB |   4879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4868 GiB |   4861 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4887 GiB |   4879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4868 GiB |   4861 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  157376    |  156819    |
|       from large pool |      93    |     178    |   80777    |   80684    |
|       from small pool |     464    |     557    |   76599    |   76135    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  157376    |  156819    |
|       from large pool |      93    |     178    |   80777    |   80684    |
|       from small pool |     464    |     557    |   76599    |   76135    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35939866304397583
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48182982206344604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7070066332817078
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5354675054550171
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4947 GiB |   4940 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4928 GiB |   4921 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4947 GiB |   4940 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4928 GiB |   4921 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4947 GiB |   4940 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4928 GiB |   4921 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  159408    |  158851    |
|       from large pool |      93    |     178    |   81752    |   81659    |
|       from small pool |     464    |     557    |   77656    |   77192    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  159408    |  158851    |
|       from large pool |      93    |     178    |   81752    |   81659    |
|       from small pool |     464    |     557    |   77656    |   77192    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49496012926101685
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4740426540374756
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.530408501625061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5007 GiB |   5000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4988 GiB |   4981 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5007 GiB |   5000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4988 GiB |   4981 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5007 GiB |   5000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4988 GiB |   4981 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  161417    |  160860    |
|       from large pool |      93    |     178    |   82724    |   82631    |
|       from small pool |     464    |     557    |   78693    |   78229    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  161417    |  160860    |
|       from large pool |      93    |     178    |   82724    |   82631    |
|       from small pool |     464    |     557    |   78693    |   78229    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0800422430038452
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3574137687683105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46985873579978943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4406193196773529
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5068 GiB |   5060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5048 GiB |   5041 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5068 GiB |   5060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5048 GiB |   5041 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5068 GiB |   5060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5048 GiB |   5041 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  163449    |  162892    |
|       from large pool |      93    |     178    |   83699    |   83606    |
|       from small pool |     464    |     557    |   79750    |   79286    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  163449    |  162892    |
|       from large pool |      93    |     178    |   83699    |   83606    |
|       from small pool |     464    |     557    |   79750    |   79286    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.446282297372818
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4453347325325012
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8741986751556396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5293667912483215
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5128 GiB |   5120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5108 GiB |   5101 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5128 GiB |   5120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5108 GiB |   5101 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5128 GiB |   5120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5108 GiB |   5101 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  165481    |  164924    |
|       from large pool |      93    |     178    |   84674    |   84581    |
|       from small pool |     464    |     557    |   80807    |   80343    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  165481    |  164924    |
|       from large pool |      93    |     178    |   84674    |   84581    |
|       from small pool |     464    |     557    |   80807    |   80343    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5353571176528931
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5791845321655273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5059974789619446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4314745366573334
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5188 GiB |   5181 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5168 GiB |   5161 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5188 GiB |   5181 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5168 GiB |   5161 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5188 GiB |   5181 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5168 GiB |   5161 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  167513    |  166956    |
|       from large pool |      93    |     178    |   85649    |   85556    |
|       from small pool |     464    |     557    |   81864    |   81400    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  167513    |  166956    |
|       from large pool |      93    |     178    |   85649    |   85556    |
|       from small pool |     464    |     557    |   81864    |   81400    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6558837294578552
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42855778336524963
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.206753730773926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6051461696624756
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5248 GiB |   5241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5228 GiB |   5221 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5248 GiB |   5241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5228 GiB |   5221 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5248 GiB |   5241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5228 GiB |   5221 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  169545    |  168988    |
|       from large pool |      93    |     178    |   86625    |   86532    |
|       from small pool |     464    |     557    |   82920    |   82456    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  169545    |  168988    |
|       from large pool |      93    |     178    |   86625    |   86532    |
|       from small pool |     464    |     557    |   82920    |   82456    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3908587694168091
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5420536398887634
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3993499279022217
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5309 GiB |   5301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5288 GiB |   5281 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5309 GiB |   5301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5288 GiB |   5281 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5309 GiB |   5301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5288 GiB |   5281 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  171554    |  170997    |
|       from large pool |      93    |     178    |   87596    |   87503    |
|       from small pool |     464    |     557    |   83958    |   83494    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  171554    |  170997    |
|       from large pool |      93    |     178    |   87596    |   87503    |
|       from small pool |     464    |     557    |   83958    |   83494    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.305393695831299
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7225639224052429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.537074863910675
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44736871123313904
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5369 GiB |   5361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5348 GiB |   5341 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5369 GiB |   5361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5348 GiB |   5341 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5369 GiB |   5361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5348 GiB |   5341 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  173586    |  173029    |
|       from large pool |      93    |     178    |   88568    |   88475    |
|       from small pool |     464    |     557    |   85018    |   84554    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  173586    |  173029    |
|       from large pool |      93    |     178    |   88568    |   88475    |
|       from small pool |     464    |     557    |   85018    |   84554    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38459938764572144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7890965938568115
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.414558082818985
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.603987991809845
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5429 GiB |   5422 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5408 GiB |   5401 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5429 GiB |   5422 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5408 GiB |   5401 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5429 GiB |   5422 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5408 GiB |   5401 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  175618    |  175061    |
|       from large pool |      93    |     178    |   89544    |   89451    |
|       from small pool |     464    |     557    |   86074    |   85610    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  175618    |  175061    |
|       from large pool |      93    |     178    |   89544    |   89451    |
|       from small pool |     464    |     557    |   86074    |   85610    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46700191497802734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4694973826408386
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5489 GiB |   5482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5468 GiB |   5461 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5489 GiB |   5482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5468 GiB |   5461 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5489 GiB |   5482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5468 GiB |   5461 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  177604    |  177047    |
|       from large pool |      93    |     178    |   90512    |   90419    |
|       from small pool |     464    |     557    |   87092    |   86628    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  177604    |  177047    |
|       from large pool |      93    |     178    |   90512    |   90419    |
|       from small pool |     464    |     557    |   87092    |   86628    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5276029109954834
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.850875973701477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.771341323852539
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.464836061000824
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5550 GiB |   5542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5528 GiB |   5521 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5550 GiB |   5542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5528 GiB |   5521 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5550 GiB |   5542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5528 GiB |   5521 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  179636    |  179079    |
|       from large pool |      93    |     178    |   91487    |   91394    |
|       from small pool |     464    |     557    |   88149    |   87685    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  179636    |  179079    |
|       from large pool |      93    |     178    |   91487    |   91394    |
|       from small pool |     464    |     557    |   88149    |   87685    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3977920413017273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2948168516159058
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44135576486587524
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9448678493499756
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5610 GiB |   5602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5588 GiB |   5581 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5610 GiB |   5602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5588 GiB |   5581 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5610 GiB |   5602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5588 GiB |   5581 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  181668    |  181111    |
|       from large pool |      93    |     178    |   92459    |   92366    |
|       from small pool |     464    |     557    |   89209    |   88745    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  181668    |  181111    |
|       from large pool |      93    |     178    |   92459    |   92366    |
|       from small pool |     464    |     557    |   89209    |   88745    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5373835563659668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9716783761978149
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4940139055252075
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5670 GiB |   5663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5648 GiB |   5641 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5670 GiB |   5663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5648 GiB |   5641 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5670 GiB |   5663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5648 GiB |   5641 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  183677    |  183120    |
|       from large pool |      93    |     178    |   93427    |   93334    |
|       from small pool |     464    |     557    |   90250    |   89786    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  183677    |  183120    |
|       from large pool |      93    |     178    |   93427    |   93334    |
|       from small pool |     464    |     557    |   90250    |   89786    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.019716739654541
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4043095111846924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6526936292648315
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4361291527748108
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5730 GiB |   5723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5708 GiB |   5701 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5730 GiB |   5723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5708 GiB |   5701 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5730 GiB |   5723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5708 GiB |   5701 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  185709    |  185152    |
|       from large pool |      93    |     178    |   94402    |   94309    |
|       from small pool |     464    |     557    |   91307    |   90843    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  185709    |  185152    |
|       from large pool |      93    |     178    |   94402    |   94309    |
|       from small pool |     464    |     557    |   91307    |   90843    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6763297915458679
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.846520721912384
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5822674632072449
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5791 GiB |   5783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5768 GiB |   5761 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5791 GiB |   5783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5768 GiB |   5761 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5791 GiB |   5783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5768 GiB |   5761 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  187718    |  187161    |
|       from large pool |      93    |     178    |   95374    |   95281    |
|       from small pool |     464    |     557    |   92344    |   91880    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  187718    |  187161    |
|       from large pool |      93    |     178    |   95374    |   95281    |
|       from small pool |     464    |     557    |   92344    |   91880    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5073311924934387
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6249715685844421
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4491252601146698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41228458285331726
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5851 GiB |   5843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5829 GiB |   5821 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5851 GiB |   5843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5829 GiB |   5821 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5851 GiB |   5843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5829 GiB |   5821 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  189750    |  189193    |
|       from large pool |      93    |     178    |   96345    |   96252    |
|       from small pool |     464    |     557    |   93405    |   92941    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  189750    |  189193    |
|       from large pool |      93    |     178    |   96345    |   96252    |
|       from small pool |     464    |     557    |   93405    |   92941    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9837915897369385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43238136172294617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3756480813026428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6602489352226257
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5911 GiB |   5904 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5889 GiB |   5881 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5911 GiB |   5904 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5889 GiB |   5881 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5911 GiB |   5904 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5889 GiB |   5881 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  191782    |  191225    |
|       from large pool |      93    |     178    |   97315    |   97222    |
|       from small pool |     464    |     557    |   94467    |   94003    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  191782    |  191225    |
|       from large pool |      93    |     178    |   97315    |   97222    |
|       from small pool |     464    |     557    |   94467    |   94003    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43490418791770935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4389401078224182
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5971 GiB |   5964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5949 GiB |   5941 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5971 GiB |   5964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5949 GiB |   5941 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5971 GiB |   5964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5949 GiB |   5941 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  193768    |  193211    |
|       from large pool |      93    |     178    |   98282    |   98189    |
|       from small pool |     464    |     557    |   95486    |   95022    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  193768    |  193211    |
|       from large pool |      93    |     178    |   98282    |   98189    |
|       from small pool |     464    |     557    |   95486    |   95022    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.278047800064087
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7019065022468567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.877516031265259
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5246642231941223
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6032 GiB |   6024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6009 GiB |   6001 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6032 GiB |   6024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6009 GiB |   6001 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6032 GiB |   6024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6009 GiB |   6001 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  195800    |  195243    |
|       from large pool |      93    |     178    |   99258    |   99165    |
|       from small pool |     464    |     557    |   96542    |   96078    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  195800    |  195243    |
|       from large pool |      93    |     178    |   99258    |   99165    |
|       from small pool |     464    |     557    |   96542    |   96078    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3866238594055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5449886918067932
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6539317965507507
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6092 GiB |   6084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6069 GiB |   6061 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6092 GiB |   6084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6069 GiB |   6061 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6092 GiB |   6084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6069 GiB |   6061 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  197809    |  197252    |
|       from large pool |      93    |     178    |  100230    |  100137    |
|       from small pool |     464    |     557    |   97579    |   97115    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  197809    |  197252    |
|       from large pool |      93    |     178    |  100230    |  100137    |
|       from small pool |     464    |     557    |   97579    |   97115    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4264691472053528
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45463478565216064
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45638638734817505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4559684693813324
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6152 GiB |   6145 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6129 GiB |   6121 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6152 GiB |   6145 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6129 GiB |   6121 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6152 GiB |   6145 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6129 GiB |   6121 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  199841    |  199284    |
|       from large pool |      93    |     178    |  101201    |  101108    |
|       from small pool |     464    |     557    |   98640    |   98176    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  199841    |  199284    |
|       from large pool |      93    |     178    |  101201    |  101108    |
|       from small pool |     464    |     557    |   98640    |   98176    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47985419631004333
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6698529720306396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1541709899902344
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3551671504974365
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6212 GiB |   6205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6189 GiB |   6181 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6212 GiB |   6205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6189 GiB |   6181 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6212 GiB |   6205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6189 GiB |   6181 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  201873    |  201316    |
|       from large pool |      93    |     178    |  102176    |  102083    |
|       from small pool |     464    |     557    |   99697    |   99233    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  201873    |  201316    |
|       from large pool |      93    |     178    |  102176    |  102083    |
|       from small pool |     464    |     557    |   99697    |   99233    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42673611640930176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.969355583190918
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.86638605594635
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41490432620048523
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6273 GiB |   6265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6249 GiB |   6241 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6273 GiB |   6265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6249 GiB |   6241 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6273 GiB |   6265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6249 GiB |   6241 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  203905    |  203348    |
|       from large pool |      93    |     178    |  103152    |  103059    |
|       from small pool |     464    |     557    |  100753    |  100289    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  203905    |  203348    |
|       from large pool |      93    |     178    |  103152    |  103059    |
|       from small pool |     464    |     557    |  100753    |  100289    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.436746597290039
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5215848684310913
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6333 GiB |   6325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6309 GiB |   6301 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6333 GiB |   6325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6309 GiB |   6301 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6333 GiB |   6325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6309 GiB |   6301 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  205891    |  205334    |
|       from large pool |      93    |     178    |  104120    |  104027    |
|       from small pool |     464    |     557    |  101771    |  101307    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  205891    |  205334    |
|       from large pool |      93    |     178    |  104120    |  104027    |
|       from small pool |     464    |     557    |  101771    |  101307    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6882298588752747
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |   7358 GiB |   7353 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7330 GiB |   7325 GiB |
|       from small pool |      9 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |   7358 GiB |   7353 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7330 GiB |   7325 GiB |
|       from small pool |      9 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |   7358 GiB |   7353 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7330 GiB |   7325 GiB |
|       from small pool |      8 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  13690 MiB |   7876 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  13620 MiB |   7820 MiB |
|       from small pool |     14 MiB |     42 MiB |     70 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  233682    |  233247    |
|       from large pool |      69    |     178    |  122613    |  122544    |
|       from small pool |     366    |     557    |  111069    |  110703    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  233682    |  233247    |
|       from large pool |      69    |     178    |  122613    |  122544    |
|       from small pool |     366    |     557    |  111069    |  110703    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8051015734672546
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8529430627822876
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.214339017868042
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5116938352584839
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7419 GiB |   7411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7390 GiB |   7383 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7419 GiB |   7411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7390 GiB |   7383 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7419 GiB |   7411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7390 GiB |   7383 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  235714    |  235157    |
|       from large pool |      93    |     178    |  123585    |  123492    |
|       from small pool |     464    |     557    |  112129    |  111665    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  235714    |  235157    |
|       from large pool |      93    |     178    |  123585    |  123492    |
|       from small pool |     464    |     557    |  112129    |  111665    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5819724798202515
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4383721649646759
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41861456632614136
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3880025148391724
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7479 GiB |   7471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7450 GiB |   7443 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7479 GiB |   7471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7450 GiB |   7443 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7479 GiB |   7471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7450 GiB |   7443 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  237746    |  237189    |
|       from large pool |      93    |     178    |  124558    |  124465    |
|       from small pool |     464    |     557    |  113188    |  112724    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  237746    |  237189    |
|       from large pool |      93    |     178    |  124558    |  124465    |
|       from small pool |     464    |     557    |  113188    |  112724    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7734600305557251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5285988450050354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6681726574897766
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7539 GiB |   7532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7510 GiB |   7503 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7539 GiB |   7532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7510 GiB |   7503 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7539 GiB |   7532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7510 GiB |   7503 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  239755    |  239198    |
|       from large pool |      93    |     178    |  125526    |  125433    |
|       from small pool |     464    |     557    |  114229    |  113765    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  239755    |  239198    |
|       from large pool |      93    |     178    |  125526    |  125433    |
|       from small pool |     464    |     557    |  114229    |  113765    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4541483521461487
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9507399797439575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39212068915367126
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7599 GiB |   7592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7570 GiB |   7563 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7599 GiB |   7592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7570 GiB |   7563 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7599 GiB |   7592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7570 GiB |   7563 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  241764    |  241207    |
|       from large pool |      93    |     178    |  126498    |  126405    |
|       from small pool |     464    |     557    |  115266    |  114802    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  241764    |  241207    |
|       from large pool |      93    |     178    |  126498    |  126405    |
|       from small pool |     464    |     557    |  115266    |  114802    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3957740068435669
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7045068740844727
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3592888116836548
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.640126645565033
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7660 GiB |   7652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7630 GiB |   7623 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7660 GiB |   7652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7630 GiB |   7623 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7660 GiB |   7652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7630 GiB |   7623 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  243796    |  243239    |
|       from large pool |      93    |     178    |  127468    |  127375    |
|       from small pool |     464    |     557    |  116328    |  115864    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  243796    |  243239    |
|       from large pool |      93    |     178    |  127468    |  127375    |
|       from small pool |     464    |     557    |  116328    |  115864    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45678287744522095
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8674015998840332
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3970751464366913
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5010831356048584
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7720 GiB |   7712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7690 GiB |   7683 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7720 GiB |   7712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7690 GiB |   7683 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7720 GiB |   7712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7690 GiB |   7683 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  245828    |  245271    |
|       from large pool |      93    |     178    |  128444    |  128351    |
|       from small pool |     464    |     557    |  117384    |  116920    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  245828    |  245271    |
|       from large pool |      93    |     178    |  128444    |  128351    |
|       from small pool |     464    |     557    |  117384    |  116920    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37873467803001404
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7549389600753784
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.209031105041504
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7780 GiB |   7773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7750 GiB |   7743 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7780 GiB |   7773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7750 GiB |   7743 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7780 GiB |   7773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7750 GiB |   7743 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  247837    |  247280    |
|       from large pool |      93    |     178    |  129416    |  129323    |
|       from small pool |     464    |     557    |  118421    |  117957    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  247837    |  247280    |
|       from large pool |      93    |     178    |  129416    |  129323    |
|       from small pool |     464    |     557    |  118421    |  117957    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6678506731987
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41784077882766724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4937847852706909
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4121454954147339
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7840 GiB |   7833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7810 GiB |   7803 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7840 GiB |   7833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7810 GiB |   7803 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7840 GiB |   7833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7810 GiB |   7803 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  249869    |  249312    |
|       from large pool |      93    |     178    |  130391    |  130298    |
|       from small pool |     464    |     557    |  119478    |  119014    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  249869    |  249312    |
|       from large pool |      93    |     178    |  130391    |  130298    |
|       from small pool |     464    |     557    |  119478    |  119014    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35888829827308655
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4921519160270691
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7901 GiB |   7893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7870 GiB |   7863 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7901 GiB |   7893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7870 GiB |   7863 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7901 GiB |   7893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7870 GiB |   7863 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  251855    |  251298    |
|       from large pool |      93    |     178    |  131359    |  131266    |
|       from small pool |     464    |     557    |  120496    |  120032    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  251855    |  251298    |
|       from large pool |      93    |     178    |  131359    |  131266    |
|       from small pool |     464    |     557    |  120496    |  120032    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8699957728385925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5450640916824341
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3905563950538635
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5765966773033142
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7961 GiB |   7954 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7930 GiB |   7923 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7961 GiB |   7954 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7930 GiB |   7923 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7961 GiB |   7953 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7930 GiB |   7923 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  253887    |  253330    |
|       from large pool |      93    |     178    |  132335    |  132242    |
|       from small pool |     464    |     557    |  121552    |  121088    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  253887    |  253330    |
|       from large pool |      93    |     178    |  132335    |  132242    |
|       from small pool |     464    |     557    |  121552    |  121088    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43139874935150146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3643650412559509
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8021 GiB |   8014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7990 GiB |   7983 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8021 GiB |   8014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7990 GiB |   7983 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8021 GiB |   8014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7990 GiB |   7983 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  255873    |  255316    |
|       from large pool |      93    |     178    |  133303    |  133210    |
|       from small pool |     464    |     557    |  122570    |  122106    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  255873    |  255316    |
|       from large pool |      93    |     178    |  133303    |  133210    |
|       from small pool |     464    |     557    |  122570    |  122106    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7877963781356812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3885669708251953
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.3744027614593506
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8081 GiB |   8074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8050 GiB |   8043 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8081 GiB |   8074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8050 GiB |   8043 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8081 GiB |   8074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8050 GiB |   8043 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  257882    |  257325    |
|       from large pool |      93    |     178    |  134275    |  134182    |
|       from small pool |     464    |     557    |  123607    |  123143    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  257882    |  257325    |
|       from large pool |      93    |     178    |  134275    |  134182    |
|       from small pool |     464    |     557    |  123607    |  123143    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9635235071182251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9398651123046875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3759452998638153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6498486995697021
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8142 GiB |   8134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8110 GiB |   8103 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8142 GiB |   8134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8110 GiB |   8103 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8142 GiB |   8134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8110 GiB |   8103 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  259914    |  259357    |
|       from large pool |      93    |     178    |  135251    |  135158    |
|       from small pool |     464    |     557    |  124663    |  124199    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  259914    |  259357    |
|       from large pool |      93    |     178    |  135251    |  135158    |
|       from small pool |     464    |     557    |  124663    |  124199    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42940425872802734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4148862063884735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7516554594039917
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8202 GiB |   8195 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8170 GiB |   8163 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8202 GiB |   8195 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8170 GiB |   8163 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8202 GiB |   8194 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8170 GiB |   8163 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  261923    |  261366    |
|       from large pool |      93    |     178    |  136223    |  136130    |
|       from small pool |     464    |     557    |  125700    |  125236    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  261923    |  261366    |
|       from large pool |      93    |     178    |  136223    |  136130    |
|       from small pool |     464    |     557    |  125700    |  125236    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35976043343544006
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34368252754211426
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7625540494918823
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8262 GiB |   8255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8230 GiB |   8223 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8262 GiB |   8255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8230 GiB |   8223 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8262 GiB |   8255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8230 GiB |   8223 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  263932    |  263375    |
|       from large pool |      93    |     178    |  137194    |  137101    |
|       from small pool |     464    |     557    |  126738    |  126274    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  263932    |  263375    |
|       from large pool |      93    |     178    |  137194    |  137101    |
|       from small pool |     464    |     557    |  126738    |  126274    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1395182609558105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.423069477081299
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9135857224464417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1172702312469482
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8322 GiB |   8315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8291 GiB |   8283 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8322 GiB |   8315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8291 GiB |   8283 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8322 GiB |   8315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8291 GiB |   8283 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  265964    |  265407    |
|       from large pool |      93    |     178    |  138162    |  138069    |
|       from small pool |     464    |     557    |  127802    |  127338    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  265964    |  265407    |
|       from large pool |      93    |     178    |  138162    |  138069    |
|       from small pool |     464    |     557    |  127802    |  127338    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4248979389667511
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9466566443443298
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8383 GiB |   8375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8351 GiB |   8343 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8383 GiB |   8375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8351 GiB |   8343 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8383 GiB |   8375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8351 GiB |   8343 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  267950    |  267393    |
|       from large pool |      93    |     178    |  139130    |  139037    |
|       from small pool |     464    |     557    |  128820    |  128356    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  267950    |  267393    |
|       from large pool |      93    |     178    |  139130    |  139037    |
|       from small pool |     464    |     557    |  128820    |  128356    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4133960008621216
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.23195743560791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3307774066925049
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8443 GiB |   8435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8411 GiB |   8403 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8443 GiB |   8435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8411 GiB |   8403 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8443 GiB |   8435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8411 GiB |   8403 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  269959    |  269402    |
|       from large pool |      93    |     178    |  140101    |  140008    |
|       from small pool |     464    |     557    |  129858    |  129394    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  269959    |  269402    |
|       from large pool |      93    |     178    |  140101    |  140008    |
|       from small pool |     464    |     557    |  129858    |  129394    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7032762765884399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1340081691741943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.390132337808609
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5579783916473389
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8503 GiB |   8496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8471 GiB |   8463 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8503 GiB |   8496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8471 GiB |   8463 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8503 GiB |   8496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8471 GiB |   8463 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  271991    |  271434    |
|       from large pool |      93    |     178    |  141077    |  140984    |
|       from small pool |     464    |     557    |  130914    |  130450    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  271991    |  271434    |
|       from large pool |      93    |     178    |  141077    |  140984    |
|       from small pool |     464    |     557    |  130914    |  130450    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0716018676757812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.802668571472168
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38565701246261597
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8563 GiB |   8556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8531 GiB |   8523 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8563 GiB |   8556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8531 GiB |   8523 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8563 GiB |   8556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8531 GiB |   8523 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  274000    |  273443    |
|       from large pool |      93    |     178    |  142049    |  141956    |
|       from small pool |     464    |     557    |  131951    |  131487    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  274000    |  273443    |
|       from large pool |      93    |     178    |  142049    |  141956    |
|       from small pool |     464    |     557    |  131951    |  131487    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32250872254371643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47355711460113525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.661649763584137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5043798685073853
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8624 GiB |   8616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8591 GiB |   8583 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8624 GiB |   8616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8591 GiB |   8583 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8624 GiB |   8616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8591 GiB |   8583 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  276032    |  275475    |
|       from large pool |      93    |     178    |  143024    |  142931    |
|       from small pool |     464    |     557    |  133008    |  132544    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  276032    |  275475    |
|       from large pool |      93    |     178    |  143024    |  142931    |
|       from small pool |     464    |     557    |  133008    |  132544    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4497036635875702
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.438198983669281
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5030548572540283
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8684 GiB |   8677 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8651 GiB |   8643 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8684 GiB |   8677 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8651 GiB |   8643 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8684 GiB |   8677 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8651 GiB |   8643 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  278041    |  277484    |
|       from large pool |      93    |     178    |  143996    |  143903    |
|       from small pool |     464    |     557    |  134045    |  133581    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  278041    |  277484    |
|       from large pool |      93    |     178    |  143996    |  143903    |
|       from small pool |     464    |     557    |  134045    |  133581    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0335768461227417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2954051494598389
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44945961236953735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41032615303993225
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8744 GiB |   8737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8711 GiB |   8703 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8744 GiB |   8737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8711 GiB |   8703 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8744 GiB |   8737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8711 GiB |   8703 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  280073    |  279516    |
|       from large pool |      93    |     178    |  144971    |  144878    |
|       from small pool |     464    |     557    |  135102    |  134638    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  280073    |  279516    |
|       from large pool |      93    |     178    |  144971    |  144878    |
|       from small pool |     464    |     557    |  135102    |  134638    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44713613390922546
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4125525653362274
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8212732076644897
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5073781609535217
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8804 GiB |   8797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8771 GiB |   8763 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8804 GiB |   8797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8771 GiB |   8763 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8804 GiB |   8797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8771 GiB |   8763 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  282105    |  281548    |
|       from large pool |      93    |     178    |  145946    |  145853    |
|       from small pool |     464    |     557    |  136159    |  135695    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  282105    |  281548    |
|       from large pool |      93    |     178    |  145946    |  145853    |
|       from small pool |     464    |     557    |  136159    |  135695    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5154852271080017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5469192266464233
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4909832775592804
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3931466341018677
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8865 GiB |   8857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8831 GiB |   8823 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8865 GiB |   8857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8831 GiB |   8823 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8865 GiB |   8857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8831 GiB |   8823 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  284137    |  283580    |
|       from large pool |      93    |     178    |  146921    |  146828    |
|       from small pool |     464    |     557    |  137216    |  136752    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  284137    |  283580    |
|       from large pool |      93    |     178    |  146921    |  146828    |
|       from small pool |     464    |     557    |  137216    |  136752    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.621256947517395
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39793649315834045
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1539275646209717
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5704979300498962
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8925 GiB |   8918 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8891 GiB |   8883 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8925 GiB |   8918 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8891 GiB |   8883 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8925 GiB |   8918 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8891 GiB |   8883 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  286169    |  285612    |
|       from large pool |      93    |     178    |  147897    |  147804    |
|       from small pool |     464    |     557    |  138272    |  137808    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  286169    |  285612    |
|       from large pool |      93    |     178    |  147897    |  147804    |
|       from small pool |     464    |     557    |  138272    |  137808    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3635222911834717
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.516581118106842
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.403873085975647
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8985 GiB |   8978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8951 GiB |   8943 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8985 GiB |   8978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8951 GiB |   8943 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8985 GiB |   8978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8951 GiB |   8943 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  288178    |  287621    |
|       from large pool |      93    |     178    |  148868    |  148775    |
|       from small pool |     464    |     557    |  139310    |  138846    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  288178    |  287621    |
|       from large pool |      93    |     178    |  148868    |  148775    |
|       from small pool |     464    |     557    |  139310    |  138846    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.208215236663818
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6724585890769958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5222636461257935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4144033193588257
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9046 GiB |   9038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9011 GiB |   9003 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9046 GiB |   9038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9011 GiB |   9003 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9045 GiB |   9038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9011 GiB |   9003 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  290210    |  289653    |
|       from large pool |      93    |     178    |  149840    |  149747    |
|       from small pool |     464    |     557    |  140370    |  139906    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  290210    |  289653    |
|       from large pool |      93    |     178    |  149840    |  149747    |
|       from small pool |     464    |     557    |  140370    |  139906    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35863155126571655
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.746972918510437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3903963267803192
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5846830606460571
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9106 GiB |   9098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9071 GiB |   9063 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9106 GiB |   9098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9071 GiB |   9063 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9106 GiB |   9098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9071 GiB |   9063 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  292242    |  291685    |
|       from large pool |      93    |     178    |  150816    |  150723    |
|       from small pool |     464    |     557    |  141426    |  140962    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  292242    |  291685    |
|       from large pool |      93    |     178    |  150816    |  150723    |
|       from small pool |     464    |     557    |  141426    |  140962    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43731755018234253
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4497511386871338
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9166 GiB |   9159 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9131 GiB |   9123 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9166 GiB |   9159 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9131 GiB |   9123 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9166 GiB |   9159 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9131 GiB |   9123 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  294228    |  293671    |
|       from large pool |      93    |     178    |  151784    |  151691    |
|       from small pool |     464    |     557    |  142444    |  141980    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  294228    |  293671    |
|       from large pool |      93    |     178    |  151784    |  151691    |
|       from small pool |     464    |     557    |  142444    |  141980    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.481804609298706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7918583154678345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.672724723815918
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42840874195098877
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9226 GiB |   9219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9191 GiB |   9184 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9226 GiB |   9219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9191 GiB |   9184 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9226 GiB |   9219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9191 GiB |   9184 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  296260    |  295703    |
|       from large pool |      93    |     178    |  152759    |  152666    |
|       from small pool |     464    |     557    |  143501    |  143037    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  296260    |  295703    |
|       from large pool |      93    |     178    |  152759    |  152666    |
|       from small pool |     464    |     557    |  143501    |  143037    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36995062232017517
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1104559898376465
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41665565967559814
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9020617604255676
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9287 GiB |   9279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9251 GiB |   9244 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9287 GiB |   9279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9251 GiB |   9244 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9287 GiB |   9279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9251 GiB |   9244 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  298292    |  297735    |
|       from large pool |      93    |     178    |  153731    |  153638    |
|       from small pool |     464    |     557    |  144561    |  144097    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  298292    |  297735    |
|       from large pool |      93    |     178    |  153731    |  153638    |
|       from small pool |     464    |     557    |  144561    |  144097    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5116944313049316
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9252290725708008
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.414633870124817
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9347 GiB |   9339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9311 GiB |   9304 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9347 GiB |   9339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9311 GiB |   9304 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9347 GiB |   9339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9311 GiB |   9304 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  300301    |  299744    |
|       from large pool |      93    |     178    |  154699    |  154606    |
|       from small pool |     464    |     557    |  145602    |  145138    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  300301    |  299744    |
|       from large pool |      93    |     178    |  154699    |  154606    |
|       from small pool |     464    |     557    |  145602    |  145138    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9859626293182373
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3803067207336426
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5922043323516846
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.402712345123291
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9407 GiB |   9400 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9371 GiB |   9364 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9407 GiB |   9400 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9371 GiB |   9364 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9407 GiB |   9400 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9371 GiB |   9364 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  302333    |  301776    |
|       from large pool |      93    |     178    |  155674    |  155581    |
|       from small pool |     464    |     557    |  146659    |  146195    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  302333    |  301776    |
|       from large pool |      93    |     178    |  155674    |  155581    |
|       from small pool |     464    |     557    |  146659    |  146195    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6224695444107056
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.794919490814209
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5667665600776672
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9467 GiB |   9460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9431 GiB |   9424 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9467 GiB |   9460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9431 GiB |   9424 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9467 GiB |   9460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9431 GiB |   9424 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  304342    |  303785    |
|       from large pool |      93    |     178    |  156646    |  156553    |
|       from small pool |     464    |     557    |  147696    |  147232    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  304342    |  303785    |
|       from large pool |      93    |     178    |  156646    |  156553    |
|       from small pool |     464    |     557    |  147696    |  147232    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4867575764656067
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5816335678100586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4143410921096802
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44441157579421997
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9528 GiB |   9520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9491 GiB |   9484 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9528 GiB |   9520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9491 GiB |   9484 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9528 GiB |   9520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9491 GiB |   9484 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  306374    |  305817    |
|       from large pool |      93    |     178    |  157617    |  157524    |
|       from small pool |     464    |     557    |  148757    |  148293    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  306374    |  305817    |
|       from large pool |      93    |     178    |  157617    |  157524    |
|       from small pool |     464    |     557    |  148757    |  148293    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8031931519508362
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40109309554100037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3602941930294037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.627627432346344
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9588 GiB |   9580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9551 GiB |   9544 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9588 GiB |   9580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9551 GiB |   9544 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9588 GiB |   9580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9551 GiB |   9544 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  308406    |  307849    |
|       from large pool |      93    |     178    |  158587    |  158494    |
|       from small pool |     464    |     557    |  149819    |  149355    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  308406    |  307849    |
|       from large pool |      93    |     178    |  158587    |  158494    |
|       from small pool |     464    |     557    |  149819    |  149355    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3945261240005493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4165565073490143
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9648 GiB |   9641 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9611 GiB |   9604 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9648 GiB |   9641 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9611 GiB |   9604 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9648 GiB |   9641 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9611 GiB |   9604 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  310392    |  309835    |
|       from large pool |      93    |     178    |  159554    |  159461    |
|       from small pool |     464    |     557    |  150838    |  150374    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  310392    |  309835    |
|       from large pool |      93    |     178    |  159554    |  159461    |
|       from small pool |     464    |     557    |  150838    |  150374    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.199267625808716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6530634164810181
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.8289592266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5036813020706177
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9708 GiB |   9701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9671 GiB |   9664 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9708 GiB |   9701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9671 GiB |   9664 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9708 GiB |   9701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9671 GiB |   9664 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  312424    |  311867    |
|       from large pool |      93    |     178    |  160530    |  160437    |
|       from small pool |     464    |     557    |  151894    |  151430    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  312424    |  311867    |
|       from large pool |      93    |     178    |  160530    |  160437    |
|       from small pool |     464    |     557    |  151894    |  151430    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3602833151817322
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5181873440742493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6069742441177368
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9769 GiB |   9761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9731 GiB |   9724 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9769 GiB |   9761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9731 GiB |   9724 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9769 GiB |   9761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9731 GiB |   9724 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  314433    |  313876    |
|       from large pool |      93    |     178    |  161502    |  161409    |
|       from small pool |     464    |     557    |  152931    |  152467    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  314433    |  313876    |
|       from large pool |      93    |     178    |  161502    |  161409    |
|       from small pool |     464    |     557    |  152931    |  152467    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4211292862892151
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40407049655914307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4450536072254181
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4276082515716553
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9829 GiB |   9821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9791 GiB |   9784 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9829 GiB |   9821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9791 GiB |   9784 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9829 GiB |   9821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9791 GiB |   9784 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  316465    |  315908    |
|       from large pool |      93    |     178    |  162473    |  162380    |
|       from small pool |     464    |     557    |  153992    |  153528    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  316465    |  315908    |
|       from large pool |      93    |     178    |  162473    |  162380    |
|       from small pool |     464    |     557    |  153992    |  153528    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4543696343898773
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6541560292243958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1092151403427124
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3023735284805298
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9889 GiB |   9882 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9851 GiB |   9844 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9889 GiB |   9882 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9851 GiB |   9844 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9889 GiB |   9882 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9851 GiB |   9844 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  318497    |  317940    |
|       from large pool |      93    |     178    |  163448    |  163355    |
|       from small pool |     464    |     557    |  155049    |  154585    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  318497    |  317940    |
|       from large pool |      93    |     178    |  163448    |  163355    |
|       from small pool |     464    |     557    |  155049    |  154585    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39061033725738525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9333477020263672
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7632112503051758
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39761194586753845
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9949 GiB |   9942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9911 GiB |   9904 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9949 GiB |   9942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9911 GiB |   9904 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9949 GiB |   9942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9911 GiB |   9904 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  320529    |  319972    |
|       from large pool |      93    |     178    |  164424    |  164331    |
|       from small pool |     464    |     557    |  156105    |  155641    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  320529    |  319972    |
|       from large pool |      93    |     178    |  164424    |  164331    |
|       from small pool |     464    |     557    |  156105    |  155641    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.3332133293151855
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4968581199645996
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  10010 GiB |  10002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9971 GiB |   9964 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  10010 GiB |  10002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9971 GiB |   9964 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  10010 GiB |  10002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9971 GiB |   9964 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  322515    |  321958    |
|       from large pool |      93    |     178    |  165392    |  165299    |
|       from small pool |     464    |     557    |  157123    |  156659    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  322515    |  321958    |
|       from large pool |      93    |     178    |  165392    |  165299    |
|       from small pool |     464    |     557    |  157123    |  156659    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6446283459663391
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  11035 GiB |  11030 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  10993 GiB |  10987 GiB |
|       from small pool |      9 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  11035 GiB |  11030 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  10993 GiB |  10987 GiB |
|       from small pool |      9 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  11035 GiB |  11030 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  10993 GiB |  10987 GiB |
|       from small pool |      8 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  17838 MiB |  12024 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  17740 MiB |  11940 MiB |
|       from small pool |     14 MiB |     42 MiB |     98 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  350306    |  349871    |
|       from large pool |      69    |     178    |  183885    |  183816    |
|       from small pool |     366    |     557    |  166421    |  166055    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  350306    |  349871    |
|       from large pool |      69    |     178    |  183885    |  183816    |
|       from small pool |     366    |     557    |  166421    |  166055    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7930572628974915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8106309175491333
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.154629945755005
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4358925819396973
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11095 GiB |  11088 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11053 GiB |  11045 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11095 GiB |  11088 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11053 GiB |  11045 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11095 GiB |  11088 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11053 GiB |  11045 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  352338    |  351781    |
|       from large pool |      93    |     178    |  184857    |  184764    |
|       from small pool |     464    |     557    |  167481    |  167017    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  352338    |  351781    |
|       from large pool |      93    |     178    |  184857    |  184764    |
|       from small pool |     464    |     557    |  167481    |  167017    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5403582453727722
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42518410086631775
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3946791887283325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.337820291519165
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11156 GiB |  11148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11113 GiB |  11105 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11156 GiB |  11148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11113 GiB |  11105 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11156 GiB |  11148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11113 GiB |  11105 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  354370    |  353813    |
|       from large pool |      93    |     178    |  185830    |  185737    |
|       from small pool |     464    |     557    |  168540    |  168076    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  354370    |  353813    |
|       from large pool |      93    |     178    |  185830    |  185737    |
|       from small pool |     464    |     557    |  168540    |  168076    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7283328771591187
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5086467266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6587628722190857
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11216 GiB |  11208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11173 GiB |  11165 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11216 GiB |  11208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11173 GiB |  11165 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11216 GiB |  11208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11173 GiB |  11165 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  356379    |  355822    |
|       from large pool |      93    |     178    |  186798    |  186705    |
|       from small pool |     464    |     557    |  169581    |  169117    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  356379    |  355822    |
|       from large pool |      93    |     178    |  186798    |  186705    |
|       from small pool |     464    |     557    |  169581    |  169117    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43243226408958435
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8997114896774292
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3564055263996124
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11276 GiB |  11269 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11233 GiB |  11225 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11276 GiB |  11269 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11233 GiB |  11225 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11276 GiB |  11269 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11233 GiB |  11225 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  358388    |  357831    |
|       from large pool |      93    |     178    |  187770    |  187677    |
|       from small pool |     464    |     557    |  170618    |  170154    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  358388    |  357831    |
|       from large pool |      93    |     178    |  187770    |  187677    |
|       from small pool |     464    |     557    |  170618    |  170154    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3781545162200928
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6633870601654053
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34436315298080444
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6021005511283875
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11336 GiB |  11329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11293 GiB |  11285 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11336 GiB |  11329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11293 GiB |  11285 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11336 GiB |  11329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11293 GiB |  11285 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  360420    |  359863    |
|       from large pool |      93    |     178    |  188740    |  188647    |
|       from small pool |     464    |     557    |  171680    |  171216    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  360420    |  359863    |
|       from large pool |      93    |     178    |  188740    |  188647    |
|       from small pool |     464    |     557    |  171680    |  171216    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4337024390697479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8381946086883545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3798515796661377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46760791540145874
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11397 GiB |  11389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11353 GiB |  11345 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11397 GiB |  11389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11353 GiB |  11345 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11397 GiB |  11389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11353 GiB |  11345 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  362452    |  361895    |
|       from large pool |      93    |     178    |  189716    |  189623    |
|       from small pool |     464    |     557    |  172736    |  172272    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  362452    |  361895    |
|       from large pool |      93    |     178    |  189716    |  189623    |
|       from small pool |     464    |     557    |  172736    |  172272    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36306190490722656
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7336841821670532
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1666553020477295
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11457 GiB |  11449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11413 GiB |  11405 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11457 GiB |  11449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11413 GiB |  11405 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11457 GiB |  11449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11413 GiB |  11405 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  364461    |  363904    |
|       from large pool |      93    |     178    |  190688    |  190595    |
|       from small pool |     464    |     557    |  173773    |  173309    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  364461    |  363904    |
|       from large pool |      93    |     178    |  190688    |  190595    |
|       from small pool |     464    |     557    |  173773    |  173309    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6589175462722778
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40363696217536926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4622725248336792
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3715578317642212
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11517 GiB |  11510 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11473 GiB |  11465 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11517 GiB |  11510 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11473 GiB |  11465 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11517 GiB |  11510 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11473 GiB |  11465 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  366493    |  365936    |
|       from large pool |      93    |     178    |  191663    |  191570    |
|       from small pool |     464    |     557    |  174830    |  174366    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  366493    |  365936    |
|       from large pool |      93    |     178    |  191663    |  191570    |
|       from small pool |     464    |     557    |  174830    |  174366    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3419116735458374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46878868341445923
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11577 GiB |  11570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11533 GiB |  11525 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11577 GiB |  11570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11533 GiB |  11525 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11577 GiB |  11570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11533 GiB |  11525 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  368479    |  367922    |
|       from large pool |      93    |     178    |  192631    |  192538    |
|       from small pool |     464    |     557    |  175848    |  175384    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  368479    |  367922    |
|       from large pool |      93    |     178    |  192631    |  192538    |
|       from small pool |     464    |     557    |  175848    |  175384    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8391717672348022
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5013014674186707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37441208958625793
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5385311841964722
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11638 GiB |  11630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11593 GiB |  11586 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11638 GiB |  11630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11593 GiB |  11586 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11638 GiB |  11630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11593 GiB |  11586 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  370511    |  369954    |
|       from large pool |      93    |     178    |  193607    |  193514    |
|       from small pool |     464    |     557    |  176904    |  176440    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  370511    |  369954    |
|       from large pool |      93    |     178    |  193607    |  193514    |
|       from small pool |     464    |     557    |  176904    |  176440    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3904067277908325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35047394037246704
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11698 GiB |  11690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11653 GiB |  11646 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11698 GiB |  11690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11653 GiB |  11646 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11698 GiB |  11690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11653 GiB |  11646 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  372497    |  371940    |
|       from large pool |      93    |     178    |  194575    |  194482    |
|       from small pool |     464    |     557    |  177922    |  177458    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  372497    |  371940    |
|       from large pool |      93    |     178    |  194575    |  194482    |
|       from small pool |     464    |     557    |  177922    |  177458    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.732211947441101
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3668222427368164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.326054096221924
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11758 GiB |  11751 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11713 GiB |  11706 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11758 GiB |  11751 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11713 GiB |  11706 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11758 GiB |  11751 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11713 GiB |  11706 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  374506    |  373949    |
|       from large pool |      93    |     178    |  195547    |  195454    |
|       from small pool |     464    |     557    |  178959    |  178495    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  374506    |  373949    |
|       from large pool |      93    |     178    |  195547    |  195454    |
|       from small pool |     464    |     557    |  178959    |  178495    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9112567901611328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8813654184341431
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35766473412513733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6242033839225769
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11818 GiB |  11811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11773 GiB |  11766 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11818 GiB |  11811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11773 GiB |  11766 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11818 GiB |  11811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11773 GiB |  11766 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  376538    |  375981    |
|       from large pool |      93    |     178    |  196523    |  196430    |
|       from small pool |     464    |     557    |  180015    |  179551    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  376538    |  375981    |
|       from large pool |      93    |     178    |  196523    |  196430    |
|       from small pool |     464    |     557    |  180015    |  179551    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4178542494773865
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39821115136146545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7165666818618774
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11879 GiB |  11871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11833 GiB |  11826 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11879 GiB |  11871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11833 GiB |  11826 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11879 GiB |  11871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11833 GiB |  11826 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  378547    |  377990    |
|       from large pool |      93    |     178    |  197495    |  197402    |
|       from small pool |     464    |     557    |  181052    |  180588    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  378547    |  377990    |
|       from large pool |      93    |     178    |  197495    |  197402    |
|       from small pool |     464    |     557    |  181052    |  180588    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34212782979011536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284926116466522
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7136108875274658
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11939 GiB |  11931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11893 GiB |  11886 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11939 GiB |  11931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11893 GiB |  11886 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11939 GiB |  11931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11893 GiB |  11886 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  380556    |  379999    |
|       from large pool |      93    |     178    |  198466    |  198373    |
|       from small pool |     464    |     557    |  182090    |  181626    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  380556    |  379999    |
|       from large pool |      93    |     178    |  198466    |  198373    |
|       from small pool |     464    |     557    |  182090    |  181626    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9933941960334778
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.3595523834228516
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8102750778198242
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0816224813461304
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11999 GiB |  11992 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11953 GiB |  11946 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11999 GiB |  11992 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11953 GiB |  11946 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11999 GiB |  11992 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11953 GiB |  11946 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  382588    |  382031    |
|       from large pool |      93    |     178    |  199434    |  199341    |
|       from small pool |     464    |     557    |  183154    |  182690    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  382588    |  382031    |
|       from large pool |      93    |     178    |  199434    |  199341    |
|       from small pool |     464    |     557    |  183154    |  182690    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.413299024105072
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9135479927062988
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12059 GiB |  12052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12013 GiB |  12006 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12059 GiB |  12052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12013 GiB |  12006 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12059 GiB |  12052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12013 GiB |  12006 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  384574    |  384017    |
|       from large pool |      93    |     178    |  200402    |  200309    |
|       from small pool |     464    |     557    |  184172    |  183708    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  384574    |  384017    |
|       from large pool |      93    |     178    |  200402    |  200309    |
|       from small pool |     464    |     557    |  184172    |  183708    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4067084491252899
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.174579620361328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2894893884658813
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12120 GiB |  12112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12073 GiB |  12066 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12120 GiB |  12112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12073 GiB |  12066 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12120 GiB |  12112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12073 GiB |  12066 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  386583    |  386026    |
|       from large pool |      93    |     178    |  201373    |  201280    |
|       from small pool |     464    |     557    |  185210    |  184746    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  386583    |  386026    |
|       from large pool |      93    |     178    |  201373    |  201280    |
|       from small pool |     464    |     557    |  185210    |  184746    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6825628876686096
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.094824194908142
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36362388730049133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5129873752593994
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12180 GiB |  12172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12133 GiB |  12126 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12180 GiB |  12172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12133 GiB |  12126 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12180 GiB |  12172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12133 GiB |  12126 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  388615    |  388058    |
|       from large pool |      93    |     178    |  202349    |  202256    |
|       from small pool |     464    |     557    |  186266    |  185802    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  388615    |  388058    |
|       from large pool |      93    |     178    |  202349    |  202256    |
|       from small pool |     464    |     557    |  186266    |  185802    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.030917763710022
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7728220224380493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37418532371520996
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12240 GiB |  12233 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12193 GiB |  12186 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12240 GiB |  12233 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12193 GiB |  12186 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12240 GiB |  12233 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12193 GiB |  12186 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  390624    |  390067    |
|       from large pool |      93    |     178    |  203321    |  203228    |
|       from small pool |     464    |     557    |  187303    |  186839    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  390624    |  390067    |
|       from large pool |      93    |     178    |  203321    |  203228    |
|       from small pool |     464    |     557    |  187303    |  186839    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30440935492515564
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46403172612190247
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6374162435531616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47682198882102966
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12300 GiB |  12293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12253 GiB |  12246 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12300 GiB |  12293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12253 GiB |  12246 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12300 GiB |  12293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12253 GiB |  12246 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  392656    |  392099    |
|       from large pool |      93    |     178    |  204296    |  204203    |
|       from small pool |     464    |     557    |  188360    |  187896    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  392656    |  392099    |
|       from large pool |      93    |     178    |  204296    |  204203    |
|       from small pool |     464    |     557    |  188360    |  187896    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4160236716270447
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41514167189598083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4792505204677582
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12361 GiB |  12353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12313 GiB |  12306 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12361 GiB |  12353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12313 GiB |  12306 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12361 GiB |  12353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12313 GiB |  12306 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  394665    |  394108    |
|       from large pool |      93    |     178    |  205268    |  205175    |
|       from small pool |     464    |     557    |  189397    |  188933    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  394665    |  394108    |
|       from large pool |      93    |     178    |  205268    |  205175    |
|       from small pool |     464    |     557    |  189397    |  188933    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9984489679336548
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2547656297683716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42159074544906616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3940301835536957
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12421 GiB |  12413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12373 GiB |  12366 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12421 GiB |  12413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12373 GiB |  12366 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12421 GiB |  12413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12373 GiB |  12366 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  396697    |  396140    |
|       from large pool |      93    |     178    |  206243    |  206150    |
|       from small pool |     464    |     557    |  190454    |  189990    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  396697    |  396140    |
|       from large pool |      93    |     178    |  206243    |  206150    |
|       from small pool |     464    |     557    |  190454    |  189990    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43876731395721436
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3962877094745636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7742434144020081
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48457634449005127
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12481 GiB |  12474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12433 GiB |  12426 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12481 GiB |  12474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12433 GiB |  12426 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12481 GiB |  12474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12433 GiB |  12426 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  398729    |  398172    |
|       from large pool |      93    |     178    |  207218    |  207125    |
|       from small pool |     464    |     557    |  191511    |  191047    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  398729    |  398172    |
|       from large pool |      93    |     178    |  207218    |  207125    |
|       from small pool |     464    |     557    |  191511    |  191047    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4956094026565552
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5226385593414307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4763917326927185
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3738737106323242
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12541 GiB |  12534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12493 GiB |  12486 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12541 GiB |  12534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12493 GiB |  12486 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12541 GiB |  12534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12493 GiB |  12486 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  400761    |  400204    |
|       from large pool |      93    |     178    |  208193    |  208100    |
|       from small pool |     464    |     557    |  192568    |  192104    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  400761    |  400204    |
|       from large pool |      93    |     178    |  208193    |  208100    |
|       from small pool |     464    |     557    |  192568    |  192104    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5782414078712463
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3818342983722687
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.098876714706421
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5317774415016174
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12602 GiB |  12594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12553 GiB |  12546 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12602 GiB |  12594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12553 GiB |  12546 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12602 GiB |  12594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12553 GiB |  12546 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  402793    |  402236    |
|       from large pool |      93    |     178    |  209169    |  209076    |
|       from small pool |     464    |     557    |  193624    |  193160    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  402793    |  402236    |
|       from large pool |      93    |     178    |  209169    |  209076    |
|       from small pool |     464    |     557    |  193624    |  193160    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34576982259750366
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49367421865463257
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38496139645576477
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12662 GiB |  12654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12613 GiB |  12606 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12662 GiB |  12654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12613 GiB |  12606 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12662 GiB |  12654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12613 GiB |  12606 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  404802    |  404245    |
|       from large pool |      93    |     178    |  210140    |  210047    |
|       from small pool |     464    |     557    |  194662    |  194198    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  404802    |  404245    |
|       from large pool |      93    |     178    |  210140    |  210047    |
|       from small pool |     464    |     557    |  194662    |  194198    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.151196479797363
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6276695728302002
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5083506107330322
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4003390669822693
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12722 GiB |  12715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12673 GiB |  12666 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12722 GiB |  12715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12673 GiB |  12666 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12722 GiB |  12715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12673 GiB |  12666 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  406834    |  406277    |
|       from large pool |      93    |     178    |  211112    |  211019    |
|       from small pool |     464    |     557    |  195722    |  195258    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  406834    |  406277    |
|       from large pool |      93    |     178    |  211112    |  211019    |
|       from small pool |     464    |     557    |  195722    |  195258    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34301993250846863
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.722851037979126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37242257595062256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5657562613487244
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12782 GiB |  12775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12733 GiB |  12726 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12782 GiB |  12775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12733 GiB |  12726 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12782 GiB |  12775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12733 GiB |  12726 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  408866    |  408309    |
|       from large pool |      93    |     178    |  212088    |  211995    |
|       from small pool |     464    |     557    |  196778    |  196314    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  408866    |  408309    |
|       from large pool |      93    |     178    |  212088    |  211995    |
|       from small pool |     464    |     557    |  196778    |  196314    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41457399725914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43614786863327026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12843 GiB |  12835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12793 GiB |  12786 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12843 GiB |  12835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12793 GiB |  12786 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12843 GiB |  12835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12793 GiB |  12786 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  410852    |  410295    |
|       from large pool |      93    |     178    |  213056    |  212963    |
|       from small pool |     464    |     557    |  197796    |  197332    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  410852    |  410295    |
|       from large pool |      93    |     178    |  213056    |  212963    |
|       from small pool |     464    |     557    |  197796    |  197332    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4422942399978638
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7304792404174805
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.612187385559082
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4083971083164215
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12903 GiB |  12896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12853 GiB |  12846 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12903 GiB |  12896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12853 GiB |  12846 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12903 GiB |  12896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12853 GiB |  12846 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  412884    |  412327    |
|       from large pool |      93    |     178    |  214031    |  213938    |
|       from small pool |     464    |     557    |  198853    |  198389    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  412884    |  412327    |
|       from large pool |      93    |     178    |  214031    |  213938    |
|       from small pool |     464    |     557    |  198853    |  198389    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35246723890304565
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9530659914016724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40092340111732483
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8486791849136353
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12963 GiB |  12956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12914 GiB |  12906 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12963 GiB |  12956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12914 GiB |  12906 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12963 GiB |  12956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12914 GiB |  12906 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  414916    |  414359    |
|       from large pool |      93    |     178    |  215003    |  214910    |
|       from small pool |     464    |     557    |  199913    |  199449    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  414916    |  414359    |
|       from large pool |      93    |     178    |  215003    |  214910    |
|       from small pool |     464    |     557    |  199913    |  199449    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.490337997674942
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8784583210945129
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2507680654525757
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13023 GiB |  13016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12974 GiB |  12966 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13023 GiB |  13016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12974 GiB |  12966 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13023 GiB |  13016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12974 GiB |  12966 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  416925    |  416368    |
|       from large pool |      93    |     178    |  215971    |  215878    |
|       from small pool |     464    |     557    |  200954    |  200490    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  416925    |  416368    |
|       from large pool |      93    |     178    |  215971    |  215878    |
|       from small pool |     464    |     557    |  200954    |  200490    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9552468061447144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3652568459510803
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5493290424346924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3815479874610901
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13084 GiB |  13076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13034 GiB |  13026 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13084 GiB |  13076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13034 GiB |  13026 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13084 GiB |  13076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13034 GiB |  13026 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  418957    |  418400    |
|       from large pool |      93    |     178    |  216946    |  216853    |
|       from small pool |     464    |     557    |  202011    |  201547    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  418957    |  418400    |
|       from large pool |      93    |     178    |  216946    |  216853    |
|       from small pool |     464    |     557    |  202011    |  201547    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5802987217903137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7484342455863953
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5494769811630249
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13144 GiB |  13137 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13094 GiB |  13086 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13144 GiB |  13137 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13094 GiB |  13086 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13144 GiB |  13137 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13094 GiB |  13086 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  420966    |  420409    |
|       from large pool |      93    |     178    |  217918    |  217825    |
|       from small pool |     464    |     557    |  203048    |  202584    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  420966    |  420409    |
|       from large pool |      93    |     178    |  217918    |  217825    |
|       from small pool |     464    |     557    |  203048    |  202584    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4643653333187103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5457404851913452
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3989465534687042
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42997774481773376
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13204 GiB |  13197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13154 GiB |  13146 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13204 GiB |  13197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13154 GiB |  13146 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13204 GiB |  13197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13154 GiB |  13146 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  422998    |  422441    |
|       from large pool |      93    |     178    |  218889    |  218796    |
|       from small pool |     464    |     557    |  204109    |  203645    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  422998    |  422441    |
|       from large pool |      93    |     178    |  218889    |  218796    |
|       from small pool |     464    |     557    |  204109    |  203645    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7423388957977295
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38405466079711914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3448895215988159
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5970014333724976
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13264 GiB |  13257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13214 GiB |  13206 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13264 GiB |  13257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13214 GiB |  13206 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13264 GiB |  13257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13214 GiB |  13206 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  425030    |  424473    |
|       from large pool |      93    |     178    |  219859    |  219766    |
|       from small pool |     464    |     557    |  205171    |  204707    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  425030    |  424473    |
|       from large pool |      93    |     178    |  219859    |  219766    |
|       from small pool |     464    |     557    |  205171    |  204707    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.376468688249588
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40056467056274414
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13325 GiB |  13317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13274 GiB |  13266 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13325 GiB |  13317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13274 GiB |  13266 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13325 GiB |  13317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13274 GiB |  13266 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  427016    |  426459    |
|       from large pool |      93    |     178    |  220826    |  220733    |
|       from small pool |     464    |     557    |  206190    |  205726    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  427016    |  426459    |
|       from large pool |      93    |     178    |  220826    |  220733    |
|       from small pool |     464    |     557    |  206190    |  205726    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1499416828155518
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6170884370803833
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.7615437507629395
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4902063310146332
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13385 GiB |  13378 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13334 GiB |  13326 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13385 GiB |  13378 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13334 GiB |  13326 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13385 GiB |  13378 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13334 GiB |  13326 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  429048    |  428491    |
|       from large pool |      93    |     178    |  221802    |  221709    |
|       from small pool |     464    |     557    |  207246    |  206782    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  429048    |  428491    |
|       from large pool |      93    |     178    |  221802    |  221709    |
|       from small pool |     464    |     557    |  207246    |  206782    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.342864990234375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5018545985221863
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5526416301727295
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13445 GiB |  13438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13394 GiB |  13386 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13445 GiB |  13438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13394 GiB |  13386 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13445 GiB |  13438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13394 GiB |  13386 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  431057    |  430500    |
|       from large pool |      93    |     178    |  222774    |  222681    |
|       from small pool |     464    |     557    |  208283    |  207819    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  431057    |  430500    |
|       from large pool |      93    |     178    |  222774    |  222681    |
|       from small pool |     464    |     557    |  208283    |  207819    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3963841199874878
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3859878480434418
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43436458706855774
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40195322036743164
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13505 GiB |  13498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13454 GiB |  13446 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13505 GiB |  13498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13454 GiB |  13446 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13505 GiB |  13498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13454 GiB |  13446 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  433089    |  432532    |
|       from large pool |      93    |     178    |  223745    |  223652    |
|       from small pool |     464    |     557    |  209344    |  208880    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  433089    |  432532    |
|       from large pool |      93    |     178    |  223745    |  223652    |
|       from small pool |     464    |     557    |  209344    |  208880    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4347972571849823
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6304241418838501
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0596929788589478
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2464430332183838
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13566 GiB |  13558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13514 GiB |  13506 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13566 GiB |  13558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13514 GiB |  13506 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13566 GiB |  13558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13514 GiB |  13506 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  435121    |  434564    |
|       from large pool |      93    |     178    |  224720    |  224627    |
|       from small pool |     464    |     557    |  210401    |  209937    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  435121    |  434564    |
|       from large pool |      93    |     178    |  224720    |  224627    |
|       from small pool |     464    |     557    |  210401    |  209937    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35329416394233704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8949295878410339
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.693165898323059
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38602107763290405
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13626 GiB |  13619 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13574 GiB |  13566 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13626 GiB |  13619 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13574 GiB |  13566 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13626 GiB |  13619 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13574 GiB |  13566 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  437153    |  436596    |
|       from large pool |      93    |     178    |  225696    |  225603    |
|       from small pool |     464    |     557    |  211457    |  210993    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  437153    |  436596    |
|       from large pool |      93    |     178    |  225696    |  225603    |
|       from small pool |     464    |     557    |  211457    |  210993    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.273541450500488
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47628358006477356
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13686 GiB |  13679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13634 GiB |  13626 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13686 GiB |  13679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13634 GiB |  13626 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13686 GiB |  13679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13634 GiB |  13626 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  439139    |  438582    |
|       from large pool |      93    |     178    |  226664    |  226571    |
|       from small pool |     464    |     557    |  212475    |  212011    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  439139    |  438582    |
|       from large pool |      93    |     178    |  226664    |  226571    |
|       from small pool |     464    |     557    |  212475    |  212011    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6043571829795837
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  14712 GiB |  14706 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14655 GiB |  14650 GiB |
|       from small pool |      9 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  14712 GiB |  14706 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14655 GiB |  14650 GiB |
|       from small pool |      9 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  14712 GiB |  14706 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14655 GiB |  14650 GiB |
|       from small pool |      8 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  21986 MiB |  16172 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  21860 MiB |  16060 MiB |
|       from small pool |     14 MiB |     42 MiB |    126 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  466930    |  466495    |
|       from large pool |      69    |     178    |  245157    |  245088    |
|       from small pool |     366    |     557    |  221773    |  221407    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  466930    |  466495    |
|       from large pool |      69    |     178    |  245157    |  245088    |
|       from small pool |     366    |     557    |  221773    |  221407    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7696083784103394
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7738329172134399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1072099208831787
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4392237663269043
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14772 GiB |  14765 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14715 GiB |  14708 GiB |
|       from small pool |     13 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14772 GiB |  14765 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14715 GiB |  14708 GiB |
|       from small pool |     13 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14772 GiB |  14765 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14715 GiB |  14708 GiB |
|       from small pool |     13 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  468962    |  468405    |
|       from large pool |      93    |     178    |  246129    |  246036    |
|       from small pool |     464    |     557    |  222833    |  222369    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  468962    |  468405    |
|       from large pool |      93    |     178    |  246129    |  246036    |
|       from small pool |     464    |     557    |  222833    |  222369    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5005015730857849
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3845720589160919
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3539958596229553
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3030188083648682
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14832 GiB |  14825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14775 GiB |  14768 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14832 GiB |  14825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14775 GiB |  14768 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14832 GiB |  14825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14775 GiB |  14768 GiB |
|       from small pool |     13 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  470994    |  470437    |
|       from large pool |      93    |     178    |  247102    |  247009    |
|       from small pool |     464    |     557    |  223892    |  223428    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  470994    |  470437    |
|       from large pool |      93    |     178    |  247102    |  247009    |
|       from small pool |     464    |     557    |  223892    |  223428    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7387155294418335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48472341895103455
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6403278708457947
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14893 GiB |  14885 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14835 GiB |  14828 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14893 GiB |  14885 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14835 GiB |  14828 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14893 GiB |  14885 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14835 GiB |  14828 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  473003    |  472446    |
|       from large pool |      93    |     178    |  248070    |  247977    |
|       from small pool |     464    |     557    |  224933    |  224469    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  473003    |  472446    |
|       from large pool |      93    |     178    |  248070    |  247977    |
|       from small pool |     464    |     557    |  224933    |  224469    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.413040429353714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8626539707183838
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324313223361969
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14953 GiB |  14945 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14895 GiB |  14888 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14953 GiB |  14945 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14895 GiB |  14888 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14953 GiB |  14945 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14895 GiB |  14888 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  475012    |  474455    |
|       from large pool |      93    |     178    |  249042    |  248949    |
|       from small pool |     464    |     557    |  225970    |  225506    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  475012    |  474455    |
|       from large pool |      93    |     178    |  249042    |  248949    |
|       from small pool |     464    |     557    |  225970    |  225506    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35225561261177063
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6438730955123901
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32586467266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.574292778968811
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15013 GiB |  15006 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14955 GiB |  14948 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15013 GiB |  15006 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14955 GiB |  14948 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15013 GiB |  15006 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14955 GiB |  14948 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  477044    |  476487    |
|       from large pool |      93    |     178    |  250012    |  249919    |
|       from small pool |     464    |     557    |  227032    |  226568    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  477044    |  476487    |
|       from large pool |      93    |     178    |  250012    |  249919    |
|       from small pool |     464    |     557    |  227032    |  226568    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41302573680877686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8201944231987
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36107563972473145
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4429234266281128
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15073 GiB |  15066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15015 GiB |  15008 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15073 GiB |  15066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15015 GiB |  15008 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15073 GiB |  15066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15015 GiB |  15008 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  479076    |  478519    |
|       from large pool |      93    |     178    |  250988    |  250895    |
|       from small pool |     464    |     557    |  228088    |  227624    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  479076    |  478519    |
|       from large pool |      93    |     178    |  250988    |  250895    |
|       from small pool |     464    |     557    |  228088    |  227624    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3480510413646698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7084197998046875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1274973154067993
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15134 GiB |  15126 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15075 GiB |  15068 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15134 GiB |  15126 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15075 GiB |  15068 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15134 GiB |  15126 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15075 GiB |  15068 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  481085    |  480528    |
|       from large pool |      93    |     178    |  251960    |  251867    |
|       from small pool |     464    |     557    |  229125    |  228661    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  481085    |  480528    |
|       from large pool |      93    |     178    |  251960    |  251867    |
|       from small pool |     464    |     557    |  229125    |  228661    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6368315815925598
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3884425163269043
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41889122128486633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3325780630111694
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15194 GiB |  15186 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15135 GiB |  15128 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15194 GiB |  15186 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15135 GiB |  15128 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15194 GiB |  15186 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15135 GiB |  15128 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  483117    |  482560    |
|       from large pool |      93    |     178    |  252935    |  252842    |
|       from small pool |     464    |     557    |  230182    |  229718    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  483117    |  482560    |
|       from large pool |      93    |     178    |  252935    |  252842    |
|       from small pool |     464    |     557    |  230182    |  229718    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32780951261520386
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44647303223609924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15254 GiB |  15247 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15195 GiB |  15188 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15254 GiB |  15247 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15195 GiB |  15188 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15254 GiB |  15247 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15195 GiB |  15188 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  485103    |  484546    |
|       from large pool |      93    |     178    |  253903    |  253810    |
|       from small pool |     464    |     557    |  231200    |  230736    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  485103    |  484546    |
|       from large pool |      93    |     178    |  253903    |  253810    |
|       from small pool |     464    |     557    |  231200    |  230736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.807952344417572
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4614025950431824
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3634142279624939
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.507057785987854
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15314 GiB |  15307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15255 GiB |  15248 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15314 GiB |  15307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15255 GiB |  15248 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15314 GiB |  15307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15255 GiB |  15248 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  487135    |  486578    |
|       from large pool |      93    |     178    |  254879    |  254786    |
|       from small pool |     464    |     557    |  232256    |  231792    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  487135    |  486578    |
|       from large pool |      93    |     178    |  254879    |  254786    |
|       from small pool |     464    |     557    |  232256    |  231792    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35348328948020935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3369205892086029
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15375 GiB |  15367 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15315 GiB |  15308 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15375 GiB |  15367 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15315 GiB |  15308 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15375 GiB |  15367 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15315 GiB |  15308 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  489121    |  488564    |
|       from large pool |      93    |     178    |  255847    |  255754    |
|       from small pool |     464    |     557    |  233274    |  232810    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  489121    |  488564    |
|       from large pool |      93    |     178    |  255847    |  255754    |
|       from small pool |     464    |     557    |  233274    |  232810    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6761924028396606
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34206584095954895
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.289836883544922
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15435 GiB |  15427 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15376 GiB |  15368 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15435 GiB |  15427 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15376 GiB |  15368 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15435 GiB |  15427 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15376 GiB |  15368 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  491130    |  490573    |
|       from large pool |      93    |     178    |  256819    |  256726    |
|       from small pool |     464    |     557    |  234311    |  233847    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  491130    |  490573    |
|       from large pool |      93    |     178    |  256819    |  256726    |
|       from small pool |     464    |     557    |  234311    |  233847    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8633443713188171
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8268972635269165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33858802914619446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5944257974624634
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15495 GiB |  15488 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15436 GiB |  15428 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15495 GiB |  15488 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15436 GiB |  15428 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15495 GiB |  15488 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15436 GiB |  15428 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  493162    |  492605    |
|       from large pool |      93    |     178    |  257795    |  257702    |
|       from small pool |     464    |     557    |  235367    |  234903    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  493162    |  492605    |
|       from large pool |      93    |     178    |  257795    |  257702    |
|       from small pool |     464    |     557    |  235367    |  234903    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39823782444000244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.382181316614151
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6845089793205261
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15555 GiB |  15548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15496 GiB |  15488 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15555 GiB |  15548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15496 GiB |  15488 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15555 GiB |  15548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15496 GiB |  15488 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  495171    |  494614    |
|       from large pool |      93    |     178    |  258767    |  258674    |
|       from small pool |     464    |     557    |  236404    |  235940    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  495171    |  494614    |
|       from large pool |      93    |     178    |  258767    |  258674    |
|       from small pool |     464    |     557    |  236404    |  235940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32874244451522827
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3081795275211334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6619094610214233
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15616 GiB |  15608 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15556 GiB |  15548 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15616 GiB |  15608 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15556 GiB |  15548 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15616 GiB |  15608 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15556 GiB |  15548 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  497180    |  496623    |
|       from large pool |      93    |     178    |  259738    |  259645    |
|       from small pool |     464    |     557    |  237442    |  236978    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  497180    |  496623    |
|       from large pool |      93    |     178    |  259738    |  259645    |
|       from small pool |     464    |     557    |  237442    |  236978    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8459346890449524
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.321760416030884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7155598998069763
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0504289865493774
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15676 GiB |  15668 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15616 GiB |  15608 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15676 GiB |  15668 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15616 GiB |  15608 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15676 GiB |  15668 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15616 GiB |  15608 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  499212    |  498655    |
|       from large pool |      93    |     178    |  260706    |  260613    |
|       from small pool |     464    |     557    |  238506    |  238042    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  499212    |  498655    |
|       from large pool |      93    |     178    |  260706    |  260613    |
|       from small pool |     464    |     557    |  238506    |  238042    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40089112520217896
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8821102380752563
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15736 GiB |  15729 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15676 GiB |  15668 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15736 GiB |  15729 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15676 GiB |  15668 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15736 GiB |  15729 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15676 GiB |  15668 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  501198    |  500641    |
|       from large pool |      93    |     178    |  261674    |  261581    |
|       from small pool |     464    |     557    |  239524    |  239060    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  501198    |  500641    |
|       from large pool |      93    |     178    |  261674    |  261581    |
|       from small pool |     464    |     557    |  239524    |  239060    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3742945194244385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.1395344734191895
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2572300434112549
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15796 GiB |  15789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15736 GiB |  15728 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15796 GiB |  15789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15736 GiB |  15728 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15796 GiB |  15789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15736 GiB |  15728 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  503207    |  502650    |
|       from large pool |      93    |     178    |  262645    |  262552    |
|       from small pool |     464    |     557    |  240562    |  240098    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  503207    |  502650    |
|       from large pool |      93    |     178    |  262645    |  262552    |
|       from small pool |     464    |     557    |  240562    |  240098    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6645398736000061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0516414642333984
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3420185446739197
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4718320369720459
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15857 GiB |  15849 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15796 GiB |  15788 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15857 GiB |  15849 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15796 GiB |  15788 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15857 GiB |  15849 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15796 GiB |  15788 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  505239    |  504682    |
|       from large pool |      93    |     178    |  263621    |  263528    |
|       from small pool |     464    |     557    |  241618    |  241154    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  505239    |  504682    |
|       from large pool |      93    |     178    |  263621    |  263528    |
|       from small pool |     464    |     557    |  241618    |  241154    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9858909249305725
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7448924779891968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3587813079357147
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15917 GiB |  15909 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15856 GiB |  15848 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15917 GiB |  15909 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15856 GiB |  15848 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15917 GiB |  15909 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15856 GiB |  15848 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  507248    |  506691    |
|       from large pool |      93    |     178    |  264593    |  264500    |
|       from small pool |     464    |     557    |  242655    |  242191    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  507248    |  506691    |
|       from large pool |      93    |     178    |  264593    |  264500    |
|       from small pool |     464    |     557    |  242655    |  242191    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2892478406429291
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.446908563375473
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6241509914398193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.452237606048584
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15977 GiB |  15970 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15916 GiB |  15908 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15977 GiB |  15970 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15916 GiB |  15908 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15977 GiB |  15970 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15916 GiB |  15908 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  509280    |  508723    |
|       from large pool |      93    |     178    |  265568    |  265475    |
|       from small pool |     464    |     557    |  243712    |  243248    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  509280    |  508723    |
|       from large pool |      93    |     178    |  265568    |  265475    |
|       from small pool |     464    |     557    |  243712    |  243248    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38668879866600037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39500245451927185
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4571174681186676
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16037 GiB |  16030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15976 GiB |  15968 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16037 GiB |  16030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15976 GiB |  15968 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16037 GiB |  16030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15976 GiB |  15968 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  511289    |  510732    |
|       from large pool |      93    |     178    |  266540    |  266447    |
|       from small pool |     464    |     557    |  244749    |  244285    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  511289    |  510732    |
|       from large pool |      93    |     178    |  266540    |  266447    |
|       from small pool |     464    |     557    |  244749    |  244285    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9703024625778198
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2268974781036377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38222089409828186
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3834834098815918
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16098 GiB |  16090 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16036 GiB |  16028 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16098 GiB |  16090 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16036 GiB |  16028 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16098 GiB |  16090 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16036 GiB |  16028 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  513321    |  512764    |
|       from large pool |      93    |     178    |  267515    |  267422    |
|       from small pool |     464    |     557    |  245806    |  245342    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  513321    |  512764    |
|       from large pool |      93    |     178    |  267515    |  267422    |
|       from small pool |     464    |     557    |  245806    |  245342    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4158337712287903
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38689056038856506
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7324391007423401
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4568125903606415
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16158 GiB |  16150 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16096 GiB |  16088 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16158 GiB |  16150 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16096 GiB |  16088 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16158 GiB |  16150 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16096 GiB |  16088 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  515353    |  514796    |
|       from large pool |      93    |     178    |  268490    |  268397    |
|       from small pool |     464    |     557    |  246863    |  246399    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  515353    |  514796    |
|       from large pool |      93    |     178    |  268490    |  268397    |
|       from small pool |     464    |     557    |  246863    |  246399    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46983617544174194
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5018084049224854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45918580889701843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34954211115837097
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16218 GiB |  16211 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16156 GiB |  16148 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16218 GiB |  16211 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16156 GiB |  16148 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16218 GiB |  16211 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16156 GiB |  16148 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  517385    |  516828    |
|       from large pool |      93    |     178    |  269465    |  269372    |
|       from small pool |     464    |     557    |  247920    |  247456    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  517385    |  516828    |
|       from large pool |      93    |     178    |  269465    |  269372    |
|       from small pool |     464    |     557    |  247920    |  247456    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5389177799224854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3717734217643738
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0475189685821533
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49729806184768677
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16278 GiB |  16271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16216 GiB |  16208 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16278 GiB |  16271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16216 GiB |  16208 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16278 GiB |  16271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16216 GiB |  16208 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  519417    |  518860    |
|       from large pool |      93    |     178    |  270441    |  270348    |
|       from small pool |     464    |     557    |  248976    |  248512    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  519417    |  518860    |
|       from large pool |      93    |     178    |  270441    |  270348    |
|       from small pool |     464    |     557    |  248976    |  248512    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33280983567237854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4671946167945862
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34541434049606323
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16339 GiB |  16331 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16276 GiB |  16268 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16339 GiB |  16331 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16276 GiB |  16268 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16339 GiB |  16331 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16276 GiB |  16268 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  521426    |  520869    |
|       from large pool |      93    |     178    |  271412    |  271319    |
|       from small pool |     464    |     557    |  250014    |  249550    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  521426    |  520869    |
|       from large pool |      93    |     178    |  271412    |  271319    |
|       from small pool |     464    |     557    |  250014    |  249550    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.116434574127197
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5871601700782776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4871812164783478
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3709505498409271
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16399 GiB |  16391 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16336 GiB |  16329 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16399 GiB |  16391 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16336 GiB |  16329 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16399 GiB |  16391 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16336 GiB |  16329 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  523458    |  522901    |
|       from large pool |      93    |     178    |  272384    |  272291    |
|       from small pool |     464    |     557    |  251074    |  250610    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  523458    |  522901    |
|       from large pool |      93    |     178    |  272384    |  272291    |
|       from small pool |     464    |     557    |  251074    |  250610    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3285726010799408
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7077078819274902
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3541874587535858
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.540101170539856
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16459 GiB |  16452 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16396 GiB |  16389 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16459 GiB |  16452 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16396 GiB |  16389 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16459 GiB |  16452 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16396 GiB |  16389 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  525490    |  524933    |
|       from large pool |      93    |     178    |  273360    |  273267    |
|       from small pool |     464    |     557    |  252130    |  251666    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  525490    |  524933    |
|       from large pool |      93    |     178    |  273360    |  273267    |
|       from small pool |     464    |     557    |  252130    |  251666    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39517709612846375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4215240776538849
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16519 GiB |  16512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16456 GiB |  16449 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16519 GiB |  16512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16456 GiB |  16449 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16519 GiB |  16512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16456 GiB |  16449 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  527476    |  526919    |
|       from large pool |      93    |     178    |  274328    |  274235    |
|       from small pool |     464    |     557    |  253148    |  252684    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  527476    |  526919    |
|       from large pool |      93    |     178    |  274328    |  274235    |
|       from small pool |     464    |     557    |  253148    |  252684    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4052671194076538
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6727595329284668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5740201473236084
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3823288679122925
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16580 GiB |  16572 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16516 GiB |  16509 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16580 GiB |  16572 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16516 GiB |  16509 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16580 GiB |  16572 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16516 GiB |  16509 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  529508    |  528951    |
|       from large pool |      93    |     178    |  275303    |  275210    |
|       from small pool |     464    |     557    |  254205    |  253741    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  529508    |  528951    |
|       from large pool |      93    |     178    |  275303    |  275210    |
|       from small pool |     464    |     557    |  254205    |  253741    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33647620677948
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8517757058143616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38571423292160034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7971600890159607
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16640 GiB |  16632 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16576 GiB |  16569 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16640 GiB |  16632 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16576 GiB |  16569 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16640 GiB |  16632 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16576 GiB |  16569 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  531540    |  530983    |
|       from large pool |      93    |     178    |  276275    |  276182    |
|       from small pool |     464    |     557    |  255265    |  254801    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  531540    |  530983    |
|       from large pool |      93    |     178    |  276275    |  276182    |
|       from small pool |     464    |     557    |  255265    |  254801    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47017186880111694
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8344438076019287
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.068676471710205
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16700 GiB |  16693 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16636 GiB |  16629 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16700 GiB |  16693 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16636 GiB |  16629 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16700 GiB |  16693 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16636 GiB |  16629 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  533549    |  532992    |
|       from large pool |      93    |     178    |  277243    |  277150    |
|       from small pool |     464    |     557    |  256306    |  255842    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  533549    |  532992    |
|       from large pool |      93    |     178    |  277243    |  277150    |
|       from small pool |     464    |     557    |  256306    |  255842    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9240391254425049
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35040900111198425
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.511786937713623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36324790120124817
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16760 GiB |  16753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16696 GiB |  16689 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16760 GiB |  16753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16696 GiB |  16689 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16760 GiB |  16753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16696 GiB |  16689 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  535581    |  535024    |
|       from large pool |      93    |     178    |  278218    |  278125    |
|       from small pool |     464    |     557    |  257363    |  256899    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  535581    |  535024    |
|       from large pool |      93    |     178    |  278218    |  278125    |
|       from small pool |     464    |     557    |  257363    |  256899    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5441670417785645
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7062374949455261
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5278030037879944
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16821 GiB |  16813 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16756 GiB |  16749 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16821 GiB |  16813 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16756 GiB |  16749 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16821 GiB |  16813 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16756 GiB |  16749 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  537590    |  537033    |
|       from large pool |      93    |     178    |  279190    |  279097    |
|       from small pool |     464    |     557    |  258400    |  257936    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  537590    |  537033    |
|       from large pool |      93    |     178    |  279190    |  279097    |
|       from small pool |     464    |     557    |  258400    |  257936    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43699127435684204
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5143771767616272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3693526089191437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3911777138710022
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16881 GiB |  16873 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16816 GiB |  16809 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16881 GiB |  16873 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16816 GiB |  16809 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16881 GiB |  16873 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16816 GiB |  16809 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  539622    |  539065    |
|       from large pool |      93    |     178    |  280161    |  280068    |
|       from small pool |     464    |     557    |  259461    |  258997    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  539622    |  539065    |
|       from large pool |      93    |     178    |  280161    |  280068    |
|       from small pool |     464    |     557    |  259461    |  258997    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.763845682144165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35922425985336304
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3260841965675354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.566985011100769
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16941 GiB |  16934 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16876 GiB |  16869 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16941 GiB |  16934 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16876 GiB |  16869 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16941 GiB |  16934 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16876 GiB |  16869 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  541654    |  541097    |
|       from large pool |      93    |     178    |  281131    |  281038    |
|       from small pool |     464    |     557    |  260523    |  260059    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  541654    |  541097    |
|       from large pool |      93    |     178    |  281131    |  281038    |
|       from small pool |     464    |     557    |  260523    |  260059    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3556440770626068
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3841143846511841
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17001 GiB |  16994 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16936 GiB |  16929 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17001 GiB |  16994 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16936 GiB |  16929 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17001 GiB |  16994 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16936 GiB |  16929 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  543640    |  543083    |
|       from large pool |      93    |     178    |  282098    |  282005    |
|       from small pool |     464    |     557    |  261542    |  261078    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  543640    |  543083    |
|       from large pool |      93    |     178    |  282098    |  282005    |
|       from small pool |     464    |     557    |  261542    |  261078    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1170198917388916
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5884301662445068
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.694685697555542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4767865240573883
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17062 GiB |  17054 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16996 GiB |  16989 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17062 GiB |  17054 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16996 GiB |  16989 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17062 GiB |  17054 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16996 GiB |  16989 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  545672    |  545115    |
|       from large pool |      93    |     178    |  283074    |  282981    |
|       from small pool |     464    |     557    |  262598    |  262134    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  545672    |  545115    |
|       from large pool |      93    |     178    |  283074    |  282981    |
|       from small pool |     464    |     557    |  262598    |  262134    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.328854501247406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4874052405357361
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.501418948173523
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17122 GiB |  17114 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17056 GiB |  17049 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17122 GiB |  17114 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17056 GiB |  17049 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17122 GiB |  17114 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17056 GiB |  17049 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  547681    |  547124    |
|       from large pool |      93    |     178    |  284046    |  283953    |
|       from small pool |     464    |     557    |  263635    |  263171    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  547681    |  547124    |
|       from large pool |      93    |     178    |  284046    |  283953    |
|       from small pool |     464    |     557    |  263635    |  263171    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35631272196769714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3638763725757599
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.415113240480423
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3737080991268158
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17182 GiB |  17175 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17116 GiB |  17109 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17182 GiB |  17175 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17116 GiB |  17109 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17182 GiB |  17175 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17116 GiB |  17109 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  549713    |  549156    |
|       from large pool |      93    |     178    |  285017    |  284924    |
|       from small pool |     464    |     557    |  264696    |  264232    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  549713    |  549156    |
|       from large pool |      93    |     178    |  285017    |  284924    |
|       from small pool |     464    |     557    |  264696    |  264232    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41739779710769653
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5961752533912659
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.011290192604065
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.192165732383728
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17242 GiB |  17235 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17176 GiB |  17169 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17242 GiB |  17235 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17176 GiB |  17169 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17242 GiB |  17235 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17176 GiB |  17169 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  551745    |  551188    |
|       from large pool |      93    |     178    |  285992    |  285899    |
|       from small pool |     464    |     557    |  265753    |  265289    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  551745    |  551188    |
|       from large pool |      93    |     178    |  285992    |  285899    |
|       from small pool |     464    |     557    |  265753    |  265289    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3219052255153656
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8539865016937256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6443272829055786
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3701934218406677
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17303 GiB |  17295 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17236 GiB |  17229 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17303 GiB |  17295 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17236 GiB |  17229 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17303 GiB |  17295 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17236 GiB |  17229 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  553777    |  553220    |
|       from large pool |      93    |     178    |  286968    |  286875    |
|       from small pool |     464    |     557    |  266809    |  266345    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  553777    |  553220    |
|       from large pool |      93    |     178    |  286968    |  286875    |
|       from small pool |     464    |     557    |  266809    |  266345    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.238527774810791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45275771617889404
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17363 GiB |  17355 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17296 GiB |  17289 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17363 GiB |  17355 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17296 GiB |  17289 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17363 GiB |  17355 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17296 GiB |  17289 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  555763    |  555206    |
|       from large pool |      93    |     178    |  287936    |  287843    |
|       from small pool |     464    |     557    |  267827    |  267363    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  555763    |  555206    |
|       from large pool |      93    |     178    |  287936    |  287843    |
|       from small pool |     464    |     557    |  267827    |  267363    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.564845860004425
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  18388 GiB |  18383 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18318 GiB |  18312 GiB |
|       from small pool |      9 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  18388 GiB |  18383 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18318 GiB |  18312 GiB |
|       from small pool |      9 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  18388 GiB |  18383 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18318 GiB |  18312 GiB |
|       from small pool |      8 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  26134 MiB |  20320 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  25980 MiB |  20180 MiB |
|       from small pool |     14 MiB |     42 MiB |    154 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  583554    |  583119    |
|       from large pool |      69    |     178    |  306429    |  306360    |
|       from small pool |     366    |     557    |  277125    |  276759    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  583554    |  583119    |
|       from large pool |      69    |     178    |  306429    |  306360    |
|       from small pool |     366    |     557    |  277125    |  276759    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7437087893486023
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7437713742256165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0666611194610596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4547584056854248
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18449 GiB |  18441 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18378 GiB |  18370 GiB |
|       from small pool |     13 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18449 GiB |  18441 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18378 GiB |  18370 GiB |
|       from small pool |     13 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18449 GiB |  18441 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18378 GiB |  18370 GiB |
|       from small pool |     13 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  585586    |  585029    |
|       from large pool |      93    |     178    |  307401    |  307308    |
|       from small pool |     464    |     557    |  278185    |  277721    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  585586    |  585029    |
|       from large pool |      93    |     178    |  307401    |  307308    |
|       from small pool |     464    |     557    |  278185    |  277721    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4739750623703003
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3508828282356262
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3234092891216278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2739440202713013
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18509 GiB |  18502 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18438 GiB |  18430 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18509 GiB |  18502 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18438 GiB |  18430 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18509 GiB |  18502 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18438 GiB |  18430 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  587618    |  587061    |
|       from large pool |      93    |     178    |  308374    |  308281    |
|       from small pool |     464    |     557    |  279244    |  278780    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  587618    |  587061    |
|       from large pool |      93    |     178    |  308374    |  308281    |
|       from small pool |     464    |     557    |  279244    |  278780    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7835104465484619
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647943675518036
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6195951104164124
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18569 GiB |  18562 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18498 GiB |  18490 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18569 GiB |  18562 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18498 GiB |  18490 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18569 GiB |  18562 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18498 GiB |  18490 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  589627    |  589070    |
|       from large pool |      93    |     178    |  309342    |  309249    |
|       from small pool |     464    |     557    |  280285    |  279821    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  589627    |  589070    |
|       from large pool |      93    |     178    |  309342    |  309249    |
|       from small pool |     464    |     557    |  280285    |  279821    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3989918529987335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.83207368850708
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30287811160087585
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18629 GiB |  18622 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18558 GiB |  18550 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18629 GiB |  18622 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18558 GiB |  18550 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18629 GiB |  18622 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18558 GiB |  18550 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  591636    |  591079    |
|       from large pool |      93    |     178    |  310314    |  310221    |
|       from small pool |     464    |     557    |  281322    |  280858    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  591636    |  591079    |
|       from large pool |      93    |     178    |  310314    |  310221    |
|       from small pool |     464    |     557    |  281322    |  280858    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32705992460250854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6540850400924683
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32307741045951843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.553713858127594
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18690 GiB |  18682 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18618 GiB |  18610 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18690 GiB |  18682 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18618 GiB |  18610 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18690 GiB |  18682 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18618 GiB |  18610 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  593668    |  593111    |
|       from large pool |      93    |     178    |  311284    |  311191    |
|       from small pool |     464    |     557    |  282384    |  281920    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  593668    |  593111    |
|       from large pool |      93    |     178    |  311284    |  311191    |
|       from small pool |     464    |     557    |  282384    |  281920    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3983871340751648
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8048974275588989
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34606677293777466
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42535436153411865
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18750 GiB |  18743 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18678 GiB |  18671 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18750 GiB |  18743 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18678 GiB |  18671 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18750 GiB |  18743 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18678 GiB |  18671 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  595700    |  595143    |
|       from large pool |      93    |     178    |  312260    |  312167    |
|       from small pool |     464    |     557    |  283440    |  282976    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  595700    |  595143    |
|       from large pool |      93    |     178    |  312260    |  312167    |
|       from small pool |     464    |     557    |  283440    |  282976    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33705025911331177
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6835212707519531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.089398980140686
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18810 GiB |  18803 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18738 GiB |  18731 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18810 GiB |  18803 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18738 GiB |  18731 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18810 GiB |  18803 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18738 GiB |  18731 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  597709    |  597152    |
|       from large pool |      93    |     178    |  313232    |  313139    |
|       from small pool |     464    |     557    |  284477    |  284013    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  597709    |  597152    |
|       from large pool |      93    |     178    |  313232    |  313139    |
|       from small pool |     464    |     557    |  284477    |  284013    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6109908223152161
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37597376108169556
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38276466727256775
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2975618839263916
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18870 GiB |  18863 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18798 GiB |  18791 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18870 GiB |  18863 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18798 GiB |  18791 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18870 GiB |  18863 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18798 GiB |  18791 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  599741    |  599184    |
|       from large pool |      93    |     178    |  314207    |  314114    |
|       from small pool |     464    |     557    |  285534    |  285070    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  599741    |  599184    |
|       from large pool |      93    |     178    |  314207    |  314114    |
|       from small pool |     464    |     557    |  285534    |  285070    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3183952271938324
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4295913279056549
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18931 GiB |  18923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18858 GiB |  18851 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18931 GiB |  18923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18858 GiB |  18851 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18931 GiB |  18923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18858 GiB |  18851 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  601727    |  601170    |
|       from large pool |      93    |     178    |  315175    |  315082    |
|       from small pool |     464    |     557    |  286552    |  286088    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  601727    |  601170    |
|       from large pool |      93    |     178    |  315175    |  315082    |
|       from small pool |     464    |     557    |  286552    |  286088    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7786715626716614
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43221718072891235
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3559081554412842
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48468106985092163
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18991 GiB |  18984 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18918 GiB |  18911 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18991 GiB |  18984 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18918 GiB |  18911 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18991 GiB |  18984 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18918 GiB |  18911 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  603759    |  603202    |
|       from large pool |      93    |     178    |  316151    |  316058    |
|       from small pool |     464    |     557    |  287608    |  287144    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  603759    |  603202    |
|       from large pool |      93    |     178    |  316151    |  316058    |
|       from small pool |     464    |     557    |  287608    |  287144    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32916566729545593
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3274155557155609
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19051 GiB |  19044 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18978 GiB |  18971 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19051 GiB |  19044 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18978 GiB |  18971 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19051 GiB |  19044 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18978 GiB |  18971 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  605745    |  605188    |
|       from large pool |      93    |     178    |  317119    |  317026    |
|       from small pool |     464    |     557    |  288626    |  288162    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  605745    |  605188    |
|       from large pool |      93    |     178    |  317119    |  317026    |
|       from small pool |     464    |     557    |  288626    |  288162    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.625609278678894
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32250678539276123
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.256333589553833
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19111 GiB |  19104 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19038 GiB |  19031 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19111 GiB |  19104 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19038 GiB |  19031 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19111 GiB |  19104 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19038 GiB |  19031 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  607754    |  607197    |
|       from large pool |      93    |     178    |  318091    |  317998    |
|       from small pool |     464    |     557    |  289663    |  289199    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  607754    |  607197    |
|       from large pool |      93    |     178    |  318091    |  317998    |
|       from small pool |     464    |     557    |  289663    |  289199    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8248248100280762
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7831247448921204
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32505783438682556
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5658968687057495
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19172 GiB |  19164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19098 GiB |  19091 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19172 GiB |  19164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19098 GiB |  19091 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19172 GiB |  19164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19098 GiB |  19091 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  609786    |  609229    |
|       from large pool |      93    |     178    |  319067    |  318974    |
|       from small pool |     464    |     557    |  290719    |  290255    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  609786    |  609229    |
|       from large pool |      93    |     178    |  319067    |  318974    |
|       from small pool |     464    |     557    |  290719    |  290255    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37843772768974304
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37125566601753235
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.657664954662323
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19232 GiB |  19225 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19158 GiB |  19151 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19232 GiB |  19225 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19158 GiB |  19151 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19232 GiB |  19225 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19158 GiB |  19151 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  611795    |  611238    |
|       from large pool |      93    |     178    |  320039    |  319946    |
|       from small pool |     464    |     557    |  291756    |  291292    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  611795    |  611238    |
|       from large pool |      93    |     178    |  320039    |  319946    |
|       from small pool |     464    |     557    |  291756    |  291292    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3204960823059082
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3045646548271179
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.614041805267334
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19292 GiB |  19285 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19218 GiB |  19211 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19292 GiB |  19285 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19218 GiB |  19211 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19292 GiB |  19285 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19218 GiB |  19211 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  613804    |  613247    |
|       from large pool |      93    |     178    |  321010    |  320917    |
|       from small pool |     464    |     557    |  292794    |  292330    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  613804    |  613247    |
|       from large pool |      93    |     178    |  321010    |  320917    |
|       from small pool |     464    |     557    |  292794    |  292330    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7644869685173035
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2923824787139893
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6829583048820496
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0228385925292969
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19352 GiB |  19345 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19278 GiB |  19271 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19352 GiB |  19345 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19278 GiB |  19271 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19352 GiB |  19345 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19278 GiB |  19271 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  615836    |  615279    |
|       from large pool |      93    |     178    |  321978    |  321885    |
|       from small pool |     464    |     557    |  293858    |  293394    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  615836    |  615279    |
|       from large pool |      93    |     178    |  321978    |  321885    |
|       from small pool |     464    |     557    |  293858    |  293394    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38931605219841003
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8528540134429932
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19413 GiB |  19405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19338 GiB |  19331 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19413 GiB |  19405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19338 GiB |  19331 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19413 GiB |  19405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19338 GiB |  19331 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  617822    |  617265    |
|       from large pool |      93    |     178    |  322946    |  322853    |
|       from small pool |     464    |     557    |  294876    |  294412    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  617822    |  617265    |
|       from large pool |      93    |     178    |  322946    |  322853    |
|       from small pool |     464    |     557    |  294876    |  294412    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3485627770423889
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.111616611480713
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2297002077102661
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19473 GiB |  19465 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19398 GiB |  19391 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19473 GiB |  19465 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19398 GiB |  19391 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19473 GiB |  19465 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19398 GiB |  19391 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  619831    |  619274    |
|       from large pool |      93    |     178    |  323917    |  323824    |
|       from small pool |     464    |     557    |  295914    |  295450    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  619831    |  619274    |
|       from large pool |      93    |     178    |  323917    |  323824    |
|       from small pool |     464    |     557    |  295914    |  295450    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6492116451263428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.008128046989441
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284187912940979
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4428568184375763
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19533 GiB |  19526 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19458 GiB |  19451 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19533 GiB |  19526 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19458 GiB |  19451 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19533 GiB |  19526 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19458 GiB |  19451 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  621863    |  621306    |
|       from large pool |      93    |     178    |  324893    |  324800    |
|       from small pool |     464    |     557    |  296970    |  296506    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  621863    |  621306    |
|       from large pool |      93    |     178    |  324893    |  324800    |
|       from small pool |     464    |     557    |  296970    |  296506    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9412129521369934
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7195854187011719
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34543299674987793
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19593 GiB |  19586 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19518 GiB |  19511 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19593 GiB |  19586 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19518 GiB |  19511 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19593 GiB |  19586 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19518 GiB |  19511 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  623872    |  623315    |
|       from large pool |      93    |     178    |  325865    |  325772    |
|       from small pool |     464    |     557    |  298007    |  297543    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  623872    |  623315    |
|       from large pool |      93    |     178    |  325865    |  325772    |
|       from small pool |     464    |     557    |  298007    |  297543    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2819531559944153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4309505522251129
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6133702993392944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43492189049720764
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19654 GiB |  19646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19578 GiB |  19571 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19654 GiB |  19646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19578 GiB |  19571 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19654 GiB |  19646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19578 GiB |  19571 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  625904    |  625347    |
|       from large pool |      93    |     178    |  326840    |  326747    |
|       from small pool |     464    |     557    |  299064    |  298600    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  625904    |  625347    |
|       from large pool |      93    |     178    |  326840    |  326747    |
|       from small pool |     464    |     557    |  299064    |  298600    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3658623695373535
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37986767292022705
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44018375873565674
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19714 GiB |  19707 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19638 GiB |  19631 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19714 GiB |  19707 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19638 GiB |  19631 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19714 GiB |  19707 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19638 GiB |  19631 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  627913    |  627356    |
|       from large pool |      93    |     178    |  327812    |  327719    |
|       from small pool |     464    |     557    |  300101    |  299637    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  627913    |  627356    |
|       from large pool |      93    |     178    |  327812    |  327719    |
|       from small pool |     464    |     557    |  300101    |  299637    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9464237093925476
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2035741806030273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3545955717563629
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3758346438407898
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19774 GiB |  19767 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19698 GiB |  19691 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19774 GiB |  19767 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19698 GiB |  19691 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19774 GiB |  19767 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19698 GiB |  19691 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  629945    |  629388    |
|       from large pool |      93    |     178    |  328787    |  328694    |
|       from small pool |     464    |     557    |  301158    |  300694    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  629945    |  629388    |
|       from large pool |      93    |     178    |  328787    |  328694    |
|       from small pool |     464    |     557    |  301158    |  300694    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39175179600715637
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3806363046169281
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6995801329612732
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43269583582878113
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19835 GiB |  19827 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19758 GiB |  19751 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19835 GiB |  19827 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19758 GiB |  19751 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19834 GiB |  19827 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19758 GiB |  19751 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  631977    |  631420    |
|       from large pool |      93    |     178    |  329762    |  329669    |
|       from small pool |     464    |     557    |  302215    |  301751    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  631977    |  631420    |
|       from large pool |      93    |     178    |  329762    |  329669    |
|       from small pool |     464    |     557    |  302215    |  301751    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44496119022369385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4859105348587036
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4437786638736725
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284643292427063
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19895 GiB |  19887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19818 GiB |  19811 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19895 GiB |  19887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19818 GiB |  19811 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19895 GiB |  19887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19818 GiB |  19811 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  634009    |  633452    |
|       from large pool |      93    |     178    |  330737    |  330644    |
|       from small pool |     464    |     557    |  303272    |  302808    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  634009    |  633452    |
|       from large pool |      93    |     178    |  330737    |  330644    |
|       from small pool |     464    |     557    |  303272    |  302808    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5112730264663696
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36504316329956055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0017402172088623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47355973720550537
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19955 GiB |  19948 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19878 GiB |  19871 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19955 GiB |  19948 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19878 GiB |  19871 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19955 GiB |  19948 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19878 GiB |  19871 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  636041    |  635484    |
|       from large pool |      93    |     178    |  331713    |  331620    |
|       from small pool |     464    |     557    |  304328    |  303864    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  636041    |  635484    |
|       from large pool |      93    |     178    |  331713    |  331620    |
|       from small pool |     464    |     557    |  304328    |  303864    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32535889744758606
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4425390660762787
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3178510069847107
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20015 GiB |  20008 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19938 GiB |  19931 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20015 GiB |  20008 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19938 GiB |  19931 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20015 GiB |  20008 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19938 GiB |  19931 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  638050    |  637493    |
|       from large pool |      93    |     178    |  332684    |  332591    |
|       from small pool |     464    |     557    |  305366    |  304902    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  638050    |  637493    |
|       from large pool |      93    |     178    |  332684    |  332591    |
|       from small pool |     464    |     557    |  305366    |  304902    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.0886030197143555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5539808869361877
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4657462239265442
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35042551159858704
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20076 GiB |  20068 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19998 GiB |  19991 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20076 GiB |  20068 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19998 GiB |  19991 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20076 GiB |  20068 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19998 GiB |  19991 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  640082    |  639525    |
|       from large pool |      93    |     178    |  333656    |  333563    |
|       from small pool |     464    |     557    |  306426    |  305962    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  640082    |  639525    |
|       from large pool |      93    |     178    |  333656    |  333563    |
|       from small pool |     464    |     557    |  306426    |  305962    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.318915456533432
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6950581073760986
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34033575654029846
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5144366025924683
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20136 GiB |  20128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20059 GiB |  20051 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20136 GiB |  20128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20059 GiB |  20051 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20136 GiB |  20128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20059 GiB |  20051 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  642114    |  641557    |
|       from large pool |      93    |     178    |  334632    |  334539    |
|       from small pool |     464    |     557    |  307482    |  307018    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  642114    |  641557    |
|       from large pool |      93    |     178    |  334632    |  334539    |
|       from small pool |     464    |     557    |  307482    |  307018    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3827149271965027
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4091763198375702
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20196 GiB |  20189 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20119 GiB |  20111 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20196 GiB |  20189 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20119 GiB |  20111 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20196 GiB |  20189 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20119 GiB |  20111 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  644100    |  643543    |
|       from large pool |      93    |     178    |  335600    |  335507    |
|       from small pool |     464    |     557    |  308500    |  308036    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  644100    |  643543    |
|       from large pool |      93    |     178    |  335600    |  335507    |
|       from small pool |     464    |     557    |  308500    |  308036    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3682557344436646
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6217763423919678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.543980598449707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35708898305892944
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20256 GiB |  20249 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20179 GiB |  20171 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20256 GiB |  20249 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20179 GiB |  20171 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20256 GiB |  20249 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20179 GiB |  20171 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  646132    |  645575    |
|       from large pool |      93    |     178    |  336575    |  336482    |
|       from small pool |     464    |     557    |  309557    |  309093    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  646132    |  645575    |
|       from large pool |      93    |     178    |  336575    |  336482    |
|       from small pool |     464    |     557    |  309557    |  309093    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3252008557319641
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8107115626335144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37360048294067383
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7553129196166992
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20317 GiB |  20309 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20239 GiB |  20231 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20317 GiB |  20309 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20239 GiB |  20231 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20317 GiB |  20309 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20239 GiB |  20231 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  648164    |  647607    |
|       from large pool |      93    |     178    |  337547    |  337454    |
|       from small pool |     464    |     557    |  310617    |  310153    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  648164    |  647607    |
|       from large pool |      93    |     178    |  337547    |  337454    |
|       from small pool |     464    |     557    |  310617    |  310153    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4545861482620239
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7977326512336731
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9332625269889832
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20377 GiB |  20369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20299 GiB |  20291 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20377 GiB |  20369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20299 GiB |  20291 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20377 GiB |  20369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20299 GiB |  20291 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  650173    |  649616    |
|       from large pool |      93    |     178    |  338515    |  338422    |
|       from small pool |     464    |     557    |  311658    |  311194    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  650173    |  649616    |
|       from large pool |      93    |     178    |  338515    |  338422    |
|       from small pool |     464    |     557    |  311658    |  311194    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8923819065093994
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339046835899353
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4856336712837219
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3496454358100891
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20437 GiB |  20430 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20359 GiB |  20351 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20437 GiB |  20430 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20359 GiB |  20351 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20437 GiB |  20430 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20359 GiB |  20351 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  652205    |  651648    |
|       from large pool |      93    |     178    |  339490    |  339397    |
|       from small pool |     464    |     557    |  312715    |  312251    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  652205    |  651648    |
|       from large pool |      93    |     178    |  339490    |  339397    |
|       from small pool |     464    |     557    |  312715    |  312251    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5165325999259949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6721661686897278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5066771507263184
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20497 GiB |  20490 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20419 GiB |  20411 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20497 GiB |  20490 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20419 GiB |  20411 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20497 GiB |  20490 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20419 GiB |  20411 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  654214    |  653657    |
|       from large pool |      93    |     178    |  340462    |  340369    |
|       from small pool |     464    |     557    |  313752    |  313288    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  654214    |  653657    |
|       from large pool |      93    |     178    |  340462    |  340369    |
|       from small pool |     464    |     557    |  313752    |  313288    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41250136494636536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4908815622329712
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3487595319747925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3607846796512604
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20558 GiB |  20550 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20479 GiB |  20471 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20558 GiB |  20550 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20479 GiB |  20471 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20558 GiB |  20550 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20479 GiB |  20471 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  656246    |  655689    |
|       from large pool |      93    |     178    |  341433    |  341340    |
|       from small pool |     464    |     557    |  314813    |  314349    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  656246    |  655689    |
|       from large pool |      93    |     178    |  341433    |  341340    |
|       from small pool |     464    |     557    |  314813    |  314349    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8139474987983704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33619898557662964
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3233568072319031
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5422070026397705
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20618 GiB |  20610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20539 GiB |  20531 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20618 GiB |  20610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20539 GiB |  20531 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20618 GiB |  20610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20539 GiB |  20531 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  658278    |  657721    |
|       from large pool |      93    |     178    |  342403    |  342310    |
|       from small pool |     464    |     557    |  315875    |  315411    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  658278    |  657721    |
|       from large pool |      93    |     178    |  342403    |  342310    |
|       from small pool |     464    |     557    |  315875    |  315411    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33855047821998596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3711854815483093
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20678 GiB |  20671 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20599 GiB |  20591 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20678 GiB |  20671 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20599 GiB |  20591 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20678 GiB |  20671 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20599 GiB |  20591 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  660264    |  659707    |
|       from large pool |      93    |     178    |  343370    |  343277    |
|       from small pool |     464    |     557    |  316894    |  316430    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  660264    |  659707    |
|       from large pool |      93    |     178    |  343370    |  343277    |
|       from small pool |     464    |     557    |  316894    |  316430    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.088186502456665
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5678302049636841
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.637929677963257
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46539825201034546
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20738 GiB |  20731 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20659 GiB |  20651 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20738 GiB |  20731 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20659 GiB |  20651 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20738 GiB |  20731 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20659 GiB |  20651 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  662296    |  661739    |
|       from large pool |      93    |     178    |  344346    |  344253    |
|       from small pool |     464    |     557    |  317950    |  317486    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  662296    |  661739    |
|       from large pool |      93    |     178    |  344346    |  344253    |
|       from small pool |     464    |     557    |  317950    |  317486    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31939923763275146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47557511925697327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46110841631889343
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20799 GiB |  20791 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20719 GiB |  20711 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20799 GiB |  20791 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20719 GiB |  20711 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20799 GiB |  20791 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20719 GiB |  20711 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  664305    |  663748    |
|       from large pool |      93    |     178    |  345318    |  345225    |
|       from small pool |     464    |     557    |  318987    |  318523    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  664305    |  663748    |
|       from large pool |      93    |     178    |  345318    |  345225    |
|       from small pool |     464    |     557    |  318987    |  318523    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3283836245536804
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35422033071517944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39511236548423767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35176724195480347
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20859 GiB |  20851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20779 GiB |  20771 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20859 GiB |  20851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20779 GiB |  20771 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20859 GiB |  20851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20779 GiB |  20771 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  666337    |  665780    |
|       from large pool |      93    |     178    |  346289    |  346196    |
|       from small pool |     464    |     557    |  320048    |  319584    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  666337    |  665780    |
|       from large pool |      93    |     178    |  346289    |  346196    |
|       from small pool |     464    |     557    |  320048    |  319584    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4055427610874176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5598140954971313
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9668205976486206
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1445995569229126
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20919 GiB |  20912 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20839 GiB |  20831 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20919 GiB |  20912 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20839 GiB |  20831 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20919 GiB |  20912 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20839 GiB |  20831 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  668369    |  667812    |
|       from large pool |      93    |     178    |  347264    |  347171    |
|       from small pool |     464    |     557    |  321105    |  320641    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  668369    |  667812    |
|       from large pool |      93    |     178    |  347264    |  347171    |
|       from small pool |     464    |     557    |  321105    |  320641    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3026847243309021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8137850761413574
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6032146215438843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35565489530563354
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20979 GiB |  20972 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20899 GiB |  20891 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20979 GiB |  20972 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20899 GiB |  20891 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20979 GiB |  20972 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20899 GiB |  20891 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  670401    |  669844    |
|       from large pool |      93    |     178    |  348240    |  348147    |
|       from small pool |     464    |     557    |  322161    |  321697    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  670401    |  669844    |
|       from large pool |      93    |     178    |  348240    |  348147    |
|       from small pool |     464    |     557    |  322161    |  321697    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.211021900177002
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43184077739715576
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  21040 GiB |  21032 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20959 GiB |  20951 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  21040 GiB |  21032 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20959 GiB |  20951 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  21040 GiB |  21032 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20959 GiB |  20951 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  672387    |  671830    |
|       from large pool |      93    |     178    |  349208    |  349115    |
|       from small pool |     464    |     557    |  323179    |  322715    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  672387    |  671830    |
|       from large pool |      93    |     178    |  349208    |  349115    |
|       from small pool |     464    |     557    |  323179    |  322715    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5301486849784851
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  22065 GiB |  22060 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  21980 GiB |  21975 GiB |
|       from small pool |      9 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  22065 GiB |  22060 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  21980 GiB |  21975 GiB |
|       from small pool |      9 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  22065 GiB |  22060 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  21980 GiB |  21975 GiB |
|       from small pool |      8 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  30282 MiB |  24468 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  30100 MiB |  24300 MiB |
|       from small pool |     14 MiB |     42 MiB |    182 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  700178    |  699743    |
|       from large pool |      69    |     178    |  367701    |  367632    |
|       from small pool |     366    |     557    |  332477    |  332111    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  700178    |  699743    |
|       from large pool |      69    |     178    |  367701    |  367632    |
|       from small pool |     366    |     557    |  332477    |  332111    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.723175048828125
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.718856155872345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.028942108154297
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4304053783416748
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22125 GiB |  22118 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22040 GiB |  22033 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22125 GiB |  22118 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22040 GiB |  22033 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22125 GiB |  22118 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22040 GiB |  22033 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  702210    |  701653    |
|       from large pool |      93    |     178    |  368673    |  368580    |
|       from small pool |     464    |     557    |  333537    |  333073    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  702210    |  701653    |
|       from large pool |      93    |     178    |  368673    |  368580    |
|       from small pool |     464    |     557    |  333537    |  333073    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45900553464889526
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33748161792755127
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31310099363327026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2421724796295166
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22186 GiB |  22178 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22100 GiB |  22093 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22186 GiB |  22178 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22100 GiB |  22093 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22186 GiB |  22178 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22100 GiB |  22093 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  704242    |  703685    |
|       from large pool |      93    |     178    |  369646    |  369553    |
|       from small pool |     464    |     557    |  334596    |  334132    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  704242    |  703685    |
|       from large pool |      93    |     178    |  369646    |  369553    |
|       from small pool |     464    |     557    |  334596    |  334132    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8151156306266785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4519675076007843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6022875308990479
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22246 GiB |  22238 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22160 GiB |  22153 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22246 GiB |  22238 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22160 GiB |  22153 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22246 GiB |  22238 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22160 GiB |  22153 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  706251    |  705694    |
|       from large pool |      93    |     178    |  370614    |  370521    |
|       from small pool |     464    |     557    |  335637    |  335173    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  706251    |  705694    |
|       from large pool |      93    |     178    |  370614    |  370521    |
|       from small pool |     464    |     557    |  335637    |  335173    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38473716378211975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8026916980743408
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.287600040435791
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22306 GiB |  22299 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22220 GiB |  22213 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22306 GiB |  22299 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22220 GiB |  22213 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22306 GiB |  22299 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22220 GiB |  22213 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  708260    |  707703    |
|       from large pool |      93    |     178    |  371586    |  371493    |
|       from small pool |     464    |     557    |  336674    |  336210    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  708260    |  707703    |
|       from large pool |      93    |     178    |  371586    |  371493    |
|       from small pool |     464    |     557    |  336674    |  336210    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30573081970214844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.652103841304779
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3306933641433716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5344435572624207
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22366 GiB |  22359 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22280 GiB |  22273 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22366 GiB |  22359 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22280 GiB |  22273 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22366 GiB |  22359 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22280 GiB |  22273 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  710292    |  709735    |
|       from large pool |      93    |     178    |  372556    |  372463    |
|       from small pool |     464    |     557    |  337736    |  337272    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  710292    |  709735    |
|       from large pool |      93    |     178    |  372556    |  372463    |
|       from small pool |     464    |     557    |  337736    |  337272    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38471439480781555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7849844098091125
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33515018224716187
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40964803099632263
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22427 GiB |  22419 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22340 GiB |  22333 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22427 GiB |  22419 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22340 GiB |  22333 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22427 GiB |  22419 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22340 GiB |  22333 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  712324    |  711767    |
|       from large pool |      93    |     178    |  373532    |  373439    |
|       from small pool |     464    |     557    |  338792    |  338328    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  712324    |  711767    |
|       from large pool |      93    |     178    |  373532    |  373439    |
|       from small pool |     464    |     557    |  338792    |  338328    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3287726640701294
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6621514558792114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0514967441558838
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22487 GiB |  22479 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22400 GiB |  22393 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22487 GiB |  22479 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22400 GiB |  22393 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22487 GiB |  22479 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22400 GiB |  22393 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  714333    |  713776    |
|       from large pool |      93    |     178    |  374504    |  374411    |
|       from small pool |     464    |     557    |  339829    |  339365    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  714333    |  713776    |
|       from large pool |      93    |     178    |  374504    |  374411    |
|       from small pool |     464    |     557    |  339829    |  339365    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5896925330162048
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36614593863487244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36037692427635193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2676422595977783
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22547 GiB |  22540 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22461 GiB |  22453 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22547 GiB |  22540 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22461 GiB |  22453 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22547 GiB |  22540 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22461 GiB |  22453 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  716365    |  715808    |
|       from large pool |      93    |     178    |  375479    |  375386    |
|       from small pool |     464    |     557    |  340886    |  340422    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  716365    |  715808    |
|       from large pool |      93    |     178    |  375479    |  375386    |
|       from small pool |     464    |     557    |  340886    |  340422    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3083057403564453
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41466179490089417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22607 GiB |  22600 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22521 GiB |  22513 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22607 GiB |  22600 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22521 GiB |  22513 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22607 GiB |  22600 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22521 GiB |  22513 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  718351    |  717794    |
|       from large pool |      93    |     178    |  376447    |  376354    |
|       from small pool |     464    |     557    |  341904    |  341440    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  718351    |  717794    |
|       from large pool |      93    |     178    |  376447    |  376354    |
|       from small pool |     464    |     557    |  341904    |  341440    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7532024383544922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41358983516693115
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3455303907394409
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4698421061038971
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22668 GiB |  22660 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22581 GiB |  22573 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22668 GiB |  22660 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22581 GiB |  22573 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22668 GiB |  22660 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22581 GiB |  22573 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  720383    |  719826    |
|       from large pool |      93    |     178    |  377423    |  377330    |
|       from small pool |     464    |     557    |  342960    |  342496    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  720383    |  719826    |
|       from large pool |      93    |     178    |  377423    |  377330    |
|       from small pool |     464    |     557    |  342960    |  342496    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3146267831325531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3215275704860687
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22728 GiB |  22720 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22641 GiB |  22633 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22728 GiB |  22720 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22641 GiB |  22633 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22728 GiB |  22720 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22641 GiB |  22633 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  722369    |  721812    |
|       from large pool |      93    |     178    |  378391    |  378298    |
|       from small pool |     464    |     557    |  343978    |  343514    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  722369    |  721812    |
|       from large pool |      93    |     178    |  378391    |  378298    |
|       from small pool |     464    |     557    |  343978    |  343514    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5843149423599243
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3101251423358917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.220048666000366
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22788 GiB |  22781 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22701 GiB |  22693 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22788 GiB |  22781 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22701 GiB |  22693 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22788 GiB |  22781 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22701 GiB |  22693 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  724378    |  723821    |
|       from large pool |      93    |     178    |  379363    |  379270    |
|       from small pool |     464    |     557    |  345015    |  344551    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  724378    |  723821    |
|       from large pool |      93    |     178    |  379363    |  379270    |
|       from small pool |     464    |     557    |  345015    |  344551    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7976096272468567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7521964311599731
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31254225969314575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5406280159950256
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22848 GiB |  22841 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22761 GiB |  22753 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22848 GiB |  22841 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22761 GiB |  22753 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22848 GiB |  22841 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22761 GiB |  22753 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  726410    |  725853    |
|       from large pool |      93    |     178    |  380339    |  380246    |
|       from small pool |     464    |     557    |  346071    |  345607    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  726410    |  725853    |
|       from large pool |      93    |     178    |  380339    |  380246    |
|       from small pool |     464    |     557    |  346071    |  345607    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36393192410469055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3654620349407196
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.636022686958313
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22909 GiB |  22901 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22821 GiB |  22813 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22909 GiB |  22901 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22821 GiB |  22813 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22909 GiB |  22901 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22821 GiB |  22813 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  728419    |  727862    |
|       from large pool |      93    |     178    |  381311    |  381218    |
|       from small pool |     464    |     557    |  347108    |  346644    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  728419    |  727862    |
|       from large pool |      93    |     178    |  381311    |  381218    |
|       from small pool |     464    |     557    |  347108    |  346644    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3111319839954376
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3127814531326294
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5739250183105469
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22969 GiB |  22961 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22881 GiB |  22873 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22969 GiB |  22961 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22881 GiB |  22873 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22969 GiB |  22961 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22881 GiB |  22873 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  730428    |  729871    |
|       from large pool |      93    |     178    |  382282    |  382189    |
|       from small pool |     464    |     557    |  348146    |  347682    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  730428    |  729871    |
|       from large pool |      93    |     178    |  382282    |  382189    |
|       from small pool |     464    |     557    |  348146    |  347682    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.735058069229126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2600882053375244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6824032664299011
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9979923367500305
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23029 GiB |  23022 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22941 GiB |  22933 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23029 GiB |  23022 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22941 GiB |  22933 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23029 GiB |  23022 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22941 GiB |  22933 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  732460    |  731903    |
|       from large pool |      93    |     178    |  383250    |  383157    |
|       from small pool |     464    |     557    |  349210    |  348746    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  732460    |  731903    |
|       from large pool |      93    |     178    |  383250    |  383157    |
|       from small pool |     464    |     557    |  349210    |  348746    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3777829110622406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.826256513595581
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23089 GiB |  23082 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23001 GiB |  22993 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23089 GiB |  23082 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23001 GiB |  22993 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23089 GiB |  23082 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23001 GiB |  22993 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  734446    |  733889    |
|       from large pool |      93    |     178    |  384218    |  384125    |
|       from small pool |     464    |     557    |  350228    |  349764    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  734446    |  733889    |
|       from large pool |      93    |     178    |  384218    |  384125    |
|       from small pool |     464    |     557    |  350228    |  349764    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3405210077762604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.080611228942871
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2025891542434692
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23150 GiB |  23142 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23061 GiB |  23053 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23150 GiB |  23142 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23061 GiB |  23053 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23150 GiB |  23142 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23061 GiB |  23053 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  736455    |  735898    |
|       from large pool |      93    |     178    |  385189    |  385096    |
|       from small pool |     464    |     557    |  351266    |  350802    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  736455    |  735898    |
|       from large pool |      93    |     178    |  385189    |  385096    |
|       from small pool |     464    |     557    |  351266    |  350802    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6337785124778748
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9671251177787781
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3173796534538269
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4255298674106598
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23210 GiB |  23202 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23121 GiB |  23113 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23210 GiB |  23202 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23121 GiB |  23113 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23210 GiB |  23202 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23121 GiB |  23113 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  738487    |  737930    |
|       from large pool |      93    |     178    |  386165    |  386072    |
|       from small pool |     464    |     557    |  352322    |  351858    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  738487    |  737930    |
|       from large pool |      93    |     178    |  386165    |  386072    |
|       from small pool |     464    |     557    |  352322    |  351858    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9008482694625854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.69732666015625
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33567777276039124
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23270 GiB |  23263 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23181 GiB |  23173 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23270 GiB |  23263 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23181 GiB |  23173 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23270 GiB |  23263 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23181 GiB |  23173 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  740496    |  739939    |
|       from large pool |      93    |     178    |  387137    |  387044    |
|       from small pool |     464    |     557    |  353359    |  352895    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  740496    |  739939    |
|       from large pool |      93    |     178    |  387137    |  387044    |
|       from small pool |     464    |     557    |  353359    |  352895    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27587974071502686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4161907136440277
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5964747071266174
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42475447058677673
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23330 GiB |  23323 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23241 GiB |  23233 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23330 GiB |  23323 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23241 GiB |  23233 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23330 GiB |  23323 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23241 GiB |  23233 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  742528    |  741971    |
|       from large pool |      93    |     178    |  388112    |  388019    |
|       from small pool |     464    |     557    |  354416    |  353952    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  742528    |  741971    |
|       from large pool |      93    |     178    |  388112    |  388019    |
|       from small pool |     464    |     557    |  354416    |  353952    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35216233134269714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36862891912460327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42884722352027893
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23391 GiB |  23383 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23301 GiB |  23293 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23391 GiB |  23383 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23301 GiB |  23293 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23391 GiB |  23383 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23301 GiB |  23293 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  744537    |  743980    |
|       from large pool |      93    |     178    |  389084    |  388991    |
|       from small pool |     464    |     557    |  355453    |  354989    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  744537    |  743980    |
|       from large pool |      93    |     178    |  389084    |  388991    |
|       from small pool |     464    |     557    |  355453    |  354989    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.924312174320221
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1783323287963867
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34544917941093445
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3645091652870178
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23451 GiB |  23444 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23361 GiB |  23353 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23451 GiB |  23444 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23361 GiB |  23353 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23451 GiB |  23443 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23361 GiB |  23353 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  746569    |  746012    |
|       from large pool |      93    |     178    |  390059    |  389966    |
|       from small pool |     464    |     557    |  356510    |  356046    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  746569    |  746012    |
|       from large pool |      93    |     178    |  390059    |  389966    |
|       from small pool |     464    |     557    |  356510    |  356046    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3730444312095642
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3705114424228668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6758893728256226
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41454723477363586
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23511 GiB |  23504 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23421 GiB |  23414 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23511 GiB |  23504 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23421 GiB |  23414 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23511 GiB |  23504 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23421 GiB |  23414 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  748601    |  748044    |
|       from large pool |      93    |     178    |  391034    |  390941    |
|       from small pool |     464    |     557    |  357567    |  357103    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  748601    |  748044    |
|       from large pool |      93    |     178    |  391034    |  390941    |
|       from small pool |     464    |     557    |  357567    |  357103    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4214242398738861
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4737102687358856
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4317299723625183
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3111536204814911
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23571 GiB |  23564 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23481 GiB |  23474 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23571 GiB |  23564 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23481 GiB |  23474 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23571 GiB |  23564 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23481 GiB |  23474 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     750 K  |     750 K  |
|       from large pool |      93    |     178    |     392 K  |     391 K  |
|       from small pool |     464    |     557    |     358 K  |     358 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     750 K  |     750 K  |
|       from large pool |      93    |     178    |     392 K  |     391 K  |
|       from small pool |     464    |     557    |     358 K  |     358 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49499887228012085
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35472050309181213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.961248755455017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45868903398513794
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23632 GiB |  23624 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23541 GiB |  23534 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23632 GiB |  23624 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23541 GiB |  23534 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23632 GiB |  23624 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23541 GiB |  23534 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     752 K  |     752 K  |
|       from large pool |      93    |     178    |     392 K  |     392 K  |
|       from small pool |     464    |     557    |     359 K  |     359 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     752 K  |     752 K  |
|       from large pool |      93    |     178    |     392 K  |     392 K  |
|       from small pool |     464    |     557    |     359 K  |     359 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3169795572757721
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4208192527294159
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3132786750793457
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23692 GiB |  23685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23601 GiB |  23594 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23692 GiB |  23685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23601 GiB |  23594 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23692 GiB |  23685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23601 GiB |  23594 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     754 K  |     754 K  |
|       from large pool |      93    |     178    |     393 K  |     393 K  |
|       from small pool |     464    |     557    |     360 K  |     360 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     754 K  |     754 K  |
|       from large pool |      93    |     178    |     393 K  |     393 K  |
|       from small pool |     464    |     557    |     360 K  |     360 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.057366371154785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5287954807281494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4487692713737488
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33699437975883484
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23752 GiB |  23745 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23661 GiB |  23654 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23752 GiB |  23745 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23661 GiB |  23654 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23752 GiB |  23745 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23661 GiB |  23654 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     756 K  |     756 K  |
|       from large pool |      93    |     178    |     394 K  |     394 K  |
|       from small pool |     464    |     557    |     361 K  |     361 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     756 K  |     756 K  |
|       from large pool |      93    |     178    |     394 K  |     394 K  |
|       from small pool |     464    |     557    |     361 K  |     361 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3130371570587158
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6779537200927734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3303520083427429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4945813715457916
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23813 GiB |  23805 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23721 GiB |  23714 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23813 GiB |  23805 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23721 GiB |  23714 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23812 GiB |  23805 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23721 GiB |  23714 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     758 K  |     758 K  |
|       from large pool |      93    |     178    |     395 K  |     395 K  |
|       from small pool |     464    |     557    |     362 K  |     362 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     758 K  |     758 K  |
|       from large pool |      93    |     178    |     395 K  |     395 K  |
|       from small pool |     464    |     557    |     362 K  |     362 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37621408700942993
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3988354504108429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23873 GiB |  23865 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23781 GiB |  23774 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23873 GiB |  23865 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23781 GiB |  23774 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23873 GiB |  23865 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23781 GiB |  23774 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     760 K  |     760 K  |
|       from large pool |      93    |     178    |     396 K  |     396 K  |
|       from small pool |     464    |     557    |     363 K  |     363 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     760 K  |     760 K  |
|       from large pool |      93    |     178    |     396 K  |     396 K  |
|       from small pool |     464    |     557    |     363 K  |     363 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.330076813697815
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.579289197921753
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5126287937164307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3340296745300293
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23933 GiB |  23926 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23841 GiB |  23834 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23933 GiB |  23926 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23841 GiB |  23834 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23933 GiB |  23926 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23841 GiB |  23834 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     762 K  |     762 K  |
|       from large pool |      93    |     178    |     397 K  |     397 K  |
|       from small pool |     464    |     557    |     364 K  |     364 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     762 K  |     762 K  |
|       from large pool |      93    |     178    |     397 K  |     397 K  |
|       from small pool |     464    |     557    |     364 K  |     364 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3169589936733246
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7846478223800659
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3635338246822357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.725496232509613
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23993 GiB |  23986 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23901 GiB |  23894 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23993 GiB |  23986 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23901 GiB |  23894 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23993 GiB |  23986 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23901 GiB |  23894 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     764 K  |     764 K  |
|       from large pool |      93    |     178    |     398 K  |     398 K  |
|       from small pool |     464    |     557    |     365 K  |     365 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     764 K  |     764 K  |
|       from large pool |      93    |     178    |     398 K  |     398 K  |
|       from small pool |     464    |     557    |     365 K  |     365 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44399502873420715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7699281573295593
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8696199655532837
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24054 GiB |  24046 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23961 GiB |  23954 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24054 GiB |  24046 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23961 GiB |  23954 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24053 GiB |  24046 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23961 GiB |  23954 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     766 K  |     766 K  |
|       from large pool |      93    |     178    |     399 K  |     399 K  |
|       from small pool |     464    |     557    |     367 K  |     366 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     766 K  |     766 K  |
|       from large pool |      93    |     178    |     399 K  |     399 K  |
|       from small pool |     464    |     557    |     367 K  |     366 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8602725863456726
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3302028179168701
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4687436521053314
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33963802456855774
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24114 GiB |  24106 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24021 GiB |  24014 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24114 GiB |  24106 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24021 GiB |  24014 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24114 GiB |  24106 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24021 GiB |  24014 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     768 K  |     768 K  |
|       from large pool |      93    |     178    |     400 K  |     400 K  |
|       from small pool |     464    |     557    |     368 K  |     367 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     768 K  |     768 K  |
|       from large pool |      93    |     178    |     400 K  |     400 K  |
|       from small pool |     464    |     557    |     368 K  |     367 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4965958893299103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6479334235191345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48864591121673584
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24174 GiB |  24167 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24081 GiB |  24074 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24174 GiB |  24167 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24081 GiB |  24074 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24174 GiB |  24167 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24081 GiB |  24074 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     770 K  |     770 K  |
|       from large pool |      93    |     178    |     401 K  |     401 K  |
|       from small pool |     464    |     557    |     369 K  |     368 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     770 K  |     770 K  |
|       from large pool |      93    |     178    |     401 K  |     401 K  |
|       from small pool |     464    |     557    |     369 K  |     368 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39237332344055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47472578287124634
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33520302176475525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3509271442890167
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24234 GiB |  24227 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24141 GiB |  24134 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24234 GiB |  24227 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24141 GiB |  24134 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24234 GiB |  24227 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24141 GiB |  24134 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     772 K  |     772 K  |
|       from large pool |      93    |     178    |     402 K  |     402 K  |
|       from small pool |     464    |     557    |     370 K  |     369 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     772 K  |     772 K  |
|       from large pool |      93    |     178    |     402 K  |     402 K  |
|       from small pool |     464    |     557    |     370 K  |     369 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8338758945465088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31649288535118103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33143237233161926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5244999527931213
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24295 GiB |  24287 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24201 GiB |  24194 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24295 GiB |  24287 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24201 GiB |  24194 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24294 GiB |  24287 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24201 GiB |  24194 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     774 K  |     774 K  |
|       from large pool |      93    |     178    |     403 K  |     403 K  |
|       from small pool |     464    |     557    |     371 K  |     370 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     774 K  |     774 K  |
|       from large pool |      93    |     178    |     403 K  |     403 K  |
|       from small pool |     464    |     557    |     371 K  |     370 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324046790599823
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36128175258636475
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24355 GiB |  24347 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24261 GiB |  24254 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24355 GiB |  24347 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24261 GiB |  24254 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24355 GiB |  24347 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24261 GiB |  24254 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     776 K  |     776 K  |
|       from large pool |      93    |     178    |     404 K  |     404 K  |
|       from small pool |     464    |     557    |     372 K  |     371 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     776 K  |     776 K  |
|       from large pool |      93    |     178    |     404 K  |     404 K  |
|       from small pool |     464    |     557    |     372 K  |     371 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0560989379882812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.553006112575531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.594550609588623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45530781149864197
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24415 GiB |  24408 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24321 GiB |  24314 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24415 GiB |  24408 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24321 GiB |  24314 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24415 GiB |  24408 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24321 GiB |  24314 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     778 K  |     778 K  |
|       from large pool |      93    |     178    |     405 K  |     405 K  |
|       from small pool |     464    |     557    |     373 K  |     372 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     778 K  |     778 K  |
|       from large pool |      93    |     178    |     405 K  |     405 K  |
|       from small pool |     464    |     557    |     373 K  |     372 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3091706931591034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647732377052307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43392854928970337
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24475 GiB |  24468 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24381 GiB |  24374 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24475 GiB |  24468 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24381 GiB |  24374 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24475 GiB |  24468 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24381 GiB |  24374 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     780 K  |     780 K  |
|       from large pool |      93    |     178    |     406 K  |     406 K  |
|       from small pool |     464    |     557    |     374 K  |     373 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     780 K  |     780 K  |
|       from large pool |      93    |     178    |     406 K  |     406 K  |
|       from small pool |     464    |     557    |     374 K  |     373 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.321036696434021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34806233644485474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37958210706710815
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3358091115951538
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24535 GiB |  24528 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24441 GiB |  24434 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24535 GiB |  24528 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24441 GiB |  24434 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24535 GiB |  24528 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24441 GiB |  24434 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     782 K  |     782 K  |
|       from large pool |      93    |     178    |     407 K  |     407 K  |
|       from small pool |     464    |     557    |     375 K  |     374 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     782 K  |     782 K  |
|       from large pool |      93    |     178    |     407 K  |     407 K  |
|       from small pool |     464    |     557    |     375 K  |     374 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3980853259563446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.526502251625061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9276179671287537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1062926054000854
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24596 GiB |  24588 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24501 GiB |  24494 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24596 GiB |  24588 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24501 GiB |  24494 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24596 GiB |  24588 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24501 GiB |  24494 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     784 K  |     784 K  |
|       from large pool |      93    |     178    |     408 K  |     408 K  |
|       from small pool |     464    |     557    |     376 K  |     375 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     784 K  |     784 K  |
|       from large pool |      93    |     178    |     408 K  |     408 K  |
|       from small pool |     464    |     557    |     376 K  |     375 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2902069091796875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7763500809669495
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5605475902557373
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3448650538921356
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24656 GiB |  24649 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24561 GiB |  24554 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24656 GiB |  24649 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24561 GiB |  24554 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24656 GiB |  24649 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24561 GiB |  24554 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     787 K  |     786 K  |
|       from large pool |      93    |     178    |     409 K  |     409 K  |
|       from small pool |     464    |     557    |     377 K  |     377 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     787 K  |     786 K  |
|       from large pool |      93    |     178    |     409 K  |     409 K  |
|       from small pool |     464    |     557    |     377 K  |     377 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.180288791656494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4129044711589813
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24716 GiB |  24709 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24621 GiB |  24614 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24716 GiB |  24709 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24621 GiB |  24614 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24716 GiB |  24709 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24621 GiB |  24614 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     789 K  |     788 K  |
|       from large pool |      93    |     178    |     410 K  |     410 K  |
|       from small pool |     464    |     557    |     378 K  |     378 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     789 K  |     788 K  |
|       from large pool |      93    |     178    |     410 K  |     410 K  |
|       from small pool |     464    |     557    |     378 K  |     378 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5026814937591553
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  25742 GiB |  25736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25643 GiB |  25637 GiB |
|       from small pool |      9 MiB |     36 MiB |     98 GiB |     98 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  25742 GiB |  25736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25643 GiB |  25637 GiB |
|       from small pool |      9 MiB |     36 MiB |     98 GiB |     98 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  25742 GiB |  25736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25643 GiB |  25637 GiB |
|       from small pool |      8 MiB |     36 MiB |     98 GiB |     98 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  34430 MiB |  28616 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  34220 MiB |  28420 MiB |
|       from small pool |     14 MiB |     42 MiB |    210 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |     816 K  |     816 K  |
|       from large pool |      69    |     178    |     428 K  |     428 K  |
|       from small pool |     366    |     557    |     387 K  |     387 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |     816 K  |     816 K  |
|       from large pool |      69    |     178    |     428 K  |     428 K  |
|       from small pool |     366    |     557    |     387 K  |     387 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7098458409309387
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6970778703689575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.993215560913086
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.361167550086975
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  25802 GiB |  25795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25703 GiB |  25696 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  25802 GiB |  25795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25703 GiB |  25696 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  25802 GiB |  25795 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25703 GiB |  25695 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     818 K  |     818 K  |
|       from large pool |      93    |     178    |     429 K  |     429 K  |
|       from small pool |     464    |     557    |     388 K  |     388 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     818 K  |     818 K  |
|       from large pool |      93    |     178    |     429 K  |     429 K  |
|       from small pool |     464    |     557    |     388 K  |     388 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4433552026748657
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3333328068256378
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3102828562259674
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2063350677490234
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  25862 GiB |  25855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25763 GiB |  25756 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  25862 GiB |  25855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25763 GiB |  25756 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  25862 GiB |  25855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25763 GiB |  25756 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     820 K  |     820 K  |
|       from large pool |      93    |     178    |     430 K  |     430 K  |
|       from small pool |     464    |     557    |     389 K  |     389 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     820 K  |     820 K  |
|       from large pool |      93    |     178    |     430 K  |     430 K  |
|       from small pool |     464    |     557    |     389 K  |     389 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8118047714233398
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4439007639884949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5893954634666443
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  25923 GiB |  25915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25823 GiB |  25816 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  25923 GiB |  25915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25823 GiB |  25816 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  25923 GiB |  25915 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25823 GiB |  25816 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     822 K  |     822 K  |
|       from large pool |      93    |     178    |     431 K  |     431 K  |
|       from small pool |     464    |     557    |     390 K  |     390 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     822 K  |     822 K  |
|       from large pool |      93    |     178    |     431 K  |     431 K  |
|       from small pool |     464    |     557    |     390 K  |     390 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3698454797267914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7727218866348267
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27374371886253357
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  25983 GiB |  25975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25883 GiB |  25876 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  25983 GiB |  25975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25883 GiB |  25876 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  25983 GiB |  25975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25883 GiB |  25876 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     824 K  |     824 K  |
|       from large pool |      93    |     178    |     432 K  |     432 K  |
|       from small pool |     464    |     557    |     392 K  |     391 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     824 K  |     824 K  |
|       from large pool |      93    |     178    |     432 K  |     432 K  |
|       from small pool |     464    |     557    |     392 K  |     391 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2851434350013733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6276633143424988
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3264438509941101
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5133658647537231
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26043 GiB |  26036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25943 GiB |  25936 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26043 GiB |  26036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25943 GiB |  25936 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26043 GiB |  26036 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25943 GiB |  25936 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     826 K  |     826 K  |
|       from large pool |      93    |     178    |     433 K  |     433 K  |
|       from small pool |     464    |     557    |     393 K  |     392 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     826 K  |     826 K  |
|       from large pool |      93    |     178    |     433 K  |     433 K  |
|       from small pool |     464    |     557    |     393 K  |     392 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37052497267723083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7600528001785278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324270099401474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39370864629745483
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26103 GiB |  26096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26003 GiB |  25996 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26103 GiB |  26096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26003 GiB |  25996 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26103 GiB |  26096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26003 GiB |  25996 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     828 K  |     828 K  |
|       from large pool |      93    |     178    |     434 K  |     434 K  |
|       from small pool |     464    |     557    |     394 K  |     393 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     828 K  |     828 K  |
|       from large pool |      93    |     178    |     434 K  |     434 K  |
|       from small pool |     464    |     557    |     394 K  |     393 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3186584711074829
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6454132795333862
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0152084827423096
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26164 GiB |  26156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26063 GiB |  26056 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26164 GiB |  26156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26063 GiB |  26056 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26164 GiB |  26156 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26063 GiB |  26056 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     830 K  |     830 K  |
|       from large pool |      93    |     178    |     435 K  |     435 K  |
|       from small pool |     464    |     557    |     395 K  |     394 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     830 K  |     830 K  |
|       from large pool |      93    |     178    |     435 K  |     435 K  |
|       from small pool |     464    |     557    |     395 K  |     394 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.575340986251831
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3553259074687958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34137189388275146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2435381412506104
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26224 GiB |  26216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26123 GiB |  26116 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26224 GiB |  26216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26123 GiB |  26116 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26224 GiB |  26216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26123 GiB |  26116 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     832 K  |     832 K  |
|       from large pool |      93    |     178    |     436 K  |     436 K  |
|       from small pool |     464    |     557    |     396 K  |     395 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     832 K  |     832 K  |
|       from large pool |      93    |     178    |     436 K  |     436 K  |
|       from small pool |     464    |     557    |     396 K  |     395 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29306724667549133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4008773863315582
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26284 GiB |  26277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26183 GiB |  26176 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26284 GiB |  26277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26183 GiB |  26176 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26284 GiB |  26277 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26183 GiB |  26176 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     834 K  |     834 K  |
|       from large pool |      93    |     178    |     437 K  |     437 K  |
|       from small pool |     464    |     557    |     397 K  |     396 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     834 K  |     834 K  |
|       from large pool |      93    |     178    |     437 K  |     437 K  |
|       from small pool |     464    |     557    |     397 K  |     396 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.731844425201416
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4023657441139221
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284552991390228
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45803284645080566
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26344 GiB |  26337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26243 GiB |  26236 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26344 GiB |  26337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26243 GiB |  26236 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26344 GiB |  26337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26243 GiB |  26236 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     837 K  |     836 K  |
|       from large pool |      93    |     178    |     438 K  |     438 K  |
|       from small pool |     464    |     557    |     398 K  |     397 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     837 K  |     836 K  |
|       from large pool |      93    |     178    |     438 K  |     438 K  |
|       from small pool |     464    |     557    |     398 K  |     397 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30404379963874817
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31538671255111694
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26405 GiB |  26397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26303 GiB |  26296 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26405 GiB |  26397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26303 GiB |  26296 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26405 GiB |  26397 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26303 GiB |  26296 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     838 K  |     838 K  |
|       from large pool |      93    |     178    |     439 K  |     439 K  |
|       from small pool |     464    |     557    |     399 K  |     398 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     838 K  |     838 K  |
|       from large pool |      93    |     178    |     439 K  |     439 K  |
|       from small pool |     464    |     557    |     399 K  |     398 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5533117055892944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3011203706264496
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1825239658355713
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26465 GiB |  26457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26363 GiB |  26356 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26465 GiB |  26457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26363 GiB |  26356 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26465 GiB |  26457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26363 GiB |  26356 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     841 K  |     840 K  |
|       from large pool |      93    |     178    |     440 K  |     440 K  |
|       from small pool |     464    |     557    |     400 K  |     399 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     841 K  |     840 K  |
|       from large pool |      93    |     178    |     440 K  |     440 K  |
|       from small pool |     464    |     557    |     400 K  |     399 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7800406217575073
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7315957546234131
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29639318585395813
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5183584690093994
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26525 GiB |  26518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26423 GiB |  26416 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26525 GiB |  26518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26423 GiB |  26416 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26525 GiB |  26518 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26423 GiB |  26416 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     843 K  |     842 K  |
|       from large pool |      93    |     178    |     441 K  |     441 K  |
|       from small pool |     464    |     557    |     401 K  |     400 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     843 K  |     842 K  |
|       from large pool |      93    |     178    |     441 K  |     441 K  |
|       from small pool |     464    |     557    |     401 K  |     400 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3537620007991791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3583802580833435
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6166451573371887
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26585 GiB |  26578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26483 GiB |  26476 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26585 GiB |  26578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26483 GiB |  26476 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26585 GiB |  26578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26483 GiB |  26476 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     845 K  |     844 K  |
|       from large pool |      93    |     178    |     442 K  |     442 K  |
|       from small pool |     464    |     557    |     402 K  |     401 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     845 K  |     844 K  |
|       from large pool |      93    |     178    |     442 K  |     442 K  |
|       from small pool |     464    |     557    |     402 K  |     401 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2961908280849457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3096919357776642
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5434669256210327
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26646 GiB |  26638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26543 GiB |  26536 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26646 GiB |  26638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26543 GiB |  26536 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26646 GiB |  26638 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26543 GiB |  26536 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     847 K  |     846 K  |
|       from large pool |      93    |     178    |     443 K  |     443 K  |
|       from small pool |     464    |     557    |     403 K  |     403 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     847 K  |     846 K  |
|       from large pool |      93    |     178    |     443 K  |     443 K  |
|       from small pool |     464    |     557    |     403 K  |     403 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7250176072120667
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2225394248962402
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6801353096961975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.975432276725769
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26706 GiB |  26698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26603 GiB |  26596 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26706 GiB |  26698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26603 GiB |  26596 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26706 GiB |  26698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26603 GiB |  26596 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     849 K  |     848 K  |
|       from large pool |      93    |     178    |     444 K  |     444 K  |
|       from small pool |     464    |     557    |     404 K  |     404 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     849 K  |     848 K  |
|       from large pool |      93    |     178    |     444 K  |     444 K  |
|       from small pool |     464    |     557    |     404 K  |     404 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36429905891418457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8020622134208679
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26766 GiB |  26759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26663 GiB |  26656 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26766 GiB |  26759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26663 GiB |  26656 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26766 GiB |  26759 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26663 GiB |  26656 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     851 K  |     850 K  |
|       from large pool |      93    |     178    |     445 K  |     445 K  |
|       from small pool |     464    |     557    |     405 K  |     405 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     851 K  |     850 K  |
|       from large pool |      93    |     178    |     445 K  |     445 K  |
|       from small pool |     464    |     557    |     405 K  |     405 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33765748143196106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.044615268707275
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.174917459487915
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26826 GiB |  26819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26723 GiB |  26716 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26826 GiB |  26819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26723 GiB |  26716 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26826 GiB |  26819 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26723 GiB |  26716 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     853 K  |     852 K  |
|       from large pool |      93    |     178    |     446 K  |     446 K  |
|       from small pool |     464    |     557    |     406 K  |     406 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     853 K  |     852 K  |
|       from large pool |      93    |     178    |     446 K  |     446 K  |
|       from small pool |     464    |     557    |     406 K  |     406 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6165820956230164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9317919611930847
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30421990156173706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41483116149902344
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26887 GiB |  26879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26783 GiB |  26776 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26887 GiB |  26879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26783 GiB |  26776 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26887 GiB |  26879 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26783 GiB |  26776 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     855 K  |     854 K  |
|       from large pool |      93    |     178    |     447 K  |     447 K  |
|       from small pool |     464    |     557    |     407 K  |     407 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     855 K  |     854 K  |
|       from large pool |      93    |     178    |     447 K  |     447 K  |
|       from small pool |     464    |     557    |     407 K  |     407 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8679857850074768
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6773892045021057
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277986943721771
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26947 GiB |  26939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26843 GiB |  26836 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26947 GiB |  26939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26843 GiB |  26836 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26947 GiB |  26939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26843 GiB |  26836 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     857 K  |     856 K  |
|       from large pool |      93    |     178    |     448 K  |     448 K  |
|       from small pool |     464    |     557    |     408 K  |     408 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     857 K  |     856 K  |
|       from large pool |      93    |     178    |     448 K  |     448 K  |
|       from small pool |     464    |     557    |     408 K  |     408 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26407402753829956
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3954724073410034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5719655156135559
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41636985540390015
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27007 GiB |  27000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26903 GiB |  26896 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27007 GiB |  27000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26903 GiB |  26896 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27007 GiB |  27000 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26903 GiB |  26896 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     859 K  |     858 K  |
|       from large pool |      93    |     178    |     449 K  |     449 K  |
|       from small pool |     464    |     557    |     409 K  |     409 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     859 K  |     858 K  |
|       from large pool |      93    |     178    |     449 K  |     449 K  |
|       from small pool |     464    |     557    |     409 K  |     409 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34038442373275757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35828423500061035
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4188620150089264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27067 GiB |  27060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26963 GiB |  26956 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27067 GiB |  27060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26963 GiB |  26956 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27067 GiB |  27060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26963 GiB |  26956 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     861 K  |     860 K  |
|       from large pool |      93    |     178    |     450 K  |     450 K  |
|       from small pool |     464    |     557    |     410 K  |     410 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     861 K  |     860 K  |
|       from large pool |      93    |     178    |     450 K  |     450 K  |
|       from small pool |     464    |     557    |     410 K  |     410 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9020735025405884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1499011516571045
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3417537212371826
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34626662731170654
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27128 GiB |  27120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27023 GiB |  27016 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27128 GiB |  27120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27023 GiB |  27016 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27128 GiB |  27120 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27023 GiB |  27016 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     863 K  |     862 K  |
|       from large pool |      93    |     178    |     451 K  |     451 K  |
|       from small pool |     464    |     557    |     411 K  |     411 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     863 K  |     862 K  |
|       from large pool |      93    |     178    |     451 K  |     451 K  |
|       from small pool |     464    |     557    |     411 K  |     411 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35472482442855835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35314419865608215
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6580479145050049
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3996224105358124
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27188 GiB |  27180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27083 GiB |  27076 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27188 GiB |  27180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27083 GiB |  27076 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27188 GiB |  27180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27083 GiB |  27076 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     865 K  |     864 K  |
|       from large pool |      93    |     178    |     452 K  |     452 K  |
|       from small pool |     464    |     557    |     412 K  |     412 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     865 K  |     864 K  |
|       from large pool |      93    |     178    |     452 K  |     452 K  |
|       from small pool |     464    |     557    |     412 K  |     412 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4013262093067169
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46032166481018066
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42160987854003906
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2922847867012024
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27248 GiB |  27241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27144 GiB |  27136 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27248 GiB |  27241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27144 GiB |  27136 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27248 GiB |  27241 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27144 GiB |  27136 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     867 K  |     866 K  |
|       from large pool |      93    |     178    |     453 K  |     453 K  |
|       from small pool |     464    |     557    |     413 K  |     413 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     867 K  |     866 K  |
|       from large pool |      93    |     178    |     453 K  |     453 K  |
|       from small pool |     464    |     557    |     413 K  |     413 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48536011576652527
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3375800549983978
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9268697500228882
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44759947061538696
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27308 GiB |  27301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27204 GiB |  27196 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27308 GiB |  27301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27204 GiB |  27196 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27308 GiB |  27301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27204 GiB |  27196 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     869 K  |     868 K  |
|       from large pool |      93    |     178    |     454 K  |     454 K  |
|       from small pool |     464    |     557    |     415 K  |     414 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     869 K  |     868 K  |
|       from large pool |      93    |     178    |     454 K  |     454 K  |
|       from small pool |     464    |     557    |     415 K  |     414 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30262506008148193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.401305228471756
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3150266408920288
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27369 GiB |  27361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27264 GiB |  27256 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27369 GiB |  27361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27264 GiB |  27256 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27369 GiB |  27361 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27264 GiB |  27256 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     871 K  |     870 K  |
|       from large pool |      93    |     178    |     455 K  |     455 K  |
|       from small pool |     464    |     557    |     416 K  |     415 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     871 K  |     870 K  |
|       from large pool |      93    |     178    |     455 K  |     455 K  |
|       from small pool |     464    |     557    |     416 K  |     415 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.020753860473633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.509464681148529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43568670749664307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31719741225242615
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27429 GiB |  27421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27324 GiB |  27316 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27429 GiB |  27421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27324 GiB |  27316 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27429 GiB |  27421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27324 GiB |  27316 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     873 K  |     872 K  |
|       from large pool |      93    |     178    |     456 K  |     456 K  |
|       from small pool |     464    |     557    |     417 K  |     416 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     873 K  |     872 K  |
|       from large pool |      93    |     178    |     456 K  |     456 K  |
|       from small pool |     464    |     557    |     417 K  |     416 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30639827251434326
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6550703048706055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3199657201766968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4804512858390808
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27489 GiB |  27482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27384 GiB |  27376 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27489 GiB |  27482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27384 GiB |  27376 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27489 GiB |  27482 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27384 GiB |  27376 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     875 K  |     874 K  |
|       from large pool |      93    |     178    |     457 K  |     457 K  |
|       from small pool |     464    |     557    |     418 K  |     417 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     875 K  |     874 K  |
|       from large pool |      93    |     178    |     457 K  |     457 K  |
|       from small pool |     464    |     557    |     418 K  |     417 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3688831031322479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3875214755535126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27549 GiB |  27542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27444 GiB |  27436 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27549 GiB |  27542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27444 GiB |  27436 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27549 GiB |  27542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27444 GiB |  27436 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     877 K  |     876 K  |
|       from large pool |      93    |     178    |     458 K  |     458 K  |
|       from small pool |     464    |     557    |     419 K  |     418 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     877 K  |     876 K  |
|       from large pool |      93    |     178    |     458 K  |     458 K  |
|       from small pool |     464    |     557    |     419 K  |     418 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2929304838180542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.545644760131836
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4781038761138916
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30991798639297485
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27610 GiB |  27602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27504 GiB |  27496 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27610 GiB |  27602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27504 GiB |  27496 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27610 GiB |  27602 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27504 GiB |  27496 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     879 K  |     878 K  |
|       from large pool |      93    |     178    |     459 K  |     459 K  |
|       from small pool |     464    |     557    |     420 K  |     419 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     879 K  |     878 K  |
|       from large pool |      93    |     178    |     459 K  |     459 K  |
|       from small pool |     464    |     557    |     420 K  |     419 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3069058656692505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7484599947929382
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3521009385585785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7055948972702026
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27670 GiB |  27663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27564 GiB |  27556 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27670 GiB |  27663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27564 GiB |  27556 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27670 GiB |  27663 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27564 GiB |  27556 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     881 K  |     880 K  |
|       from large pool |      93    |     178    |     460 K  |     459 K  |
|       from small pool |     464    |     557    |     421 K  |     420 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     881 K  |     880 K  |
|       from large pool |      93    |     178    |     460 K  |     459 K  |
|       from small pool |     464    |     557    |     421 K  |     420 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43298038840293884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7503966093063354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8610623478889465
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27730 GiB |  27723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27624 GiB |  27616 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27730 GiB |  27723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27624 GiB |  27616 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27730 GiB |  27723 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27624 GiB |  27616 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     883 K  |     882 K  |
|       from large pool |      93    |     178    |     461 K  |     460 K  |
|       from small pool |     464    |     557    |     422 K  |     421 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     883 K  |     882 K  |
|       from large pool |      93    |     178    |     461 K  |     460 K  |
|       from small pool |     464    |     557    |     422 K  |     421 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8302368521690369
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3196645975112915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45290619134902954
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3298962116241455
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27790 GiB |  27783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27684 GiB |  27676 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27790 GiB |  27783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27684 GiB |  27676 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27790 GiB |  27783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27684 GiB |  27676 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     885 K  |     884 K  |
|       from large pool |      93    |     178    |     462 K  |     461 K  |
|       from small pool |     464    |     557    |     423 K  |     422 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     885 K  |     884 K  |
|       from large pool |      93    |     178    |     462 K  |     461 K  |
|       from small pool |     464    |     557    |     423 K  |     422 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4801141321659088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.632495105266571
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47458669543266296
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27851 GiB |  27843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27744 GiB |  27736 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27851 GiB |  27843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27744 GiB |  27736 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27851 GiB |  27843 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27744 GiB |  27736 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     887 K  |     886 K  |
|       from large pool |      93    |     178    |     463 K  |     462 K  |
|       from small pool |     464    |     557    |     424 K  |     423 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     887 K  |     886 K  |
|       from large pool |      93    |     178    |     463 K  |     462 K  |
|       from small pool |     464    |     557    |     424 K  |     423 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.374237596988678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4621663987636566
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31554439663887024
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34858933091163635
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27911 GiB |  27904 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27804 GiB |  27796 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27911 GiB |  27904 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27804 GiB |  27796 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27911 GiB |  27903 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27804 GiB |  27796 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     889 K  |     888 K  |
|       from large pool |      93    |     178    |     463 K  |     463 K  |
|       from small pool |     464    |     557    |     425 K  |     425 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     889 K  |     888 K  |
|       from large pool |      93    |     178    |     463 K  |     463 K  |
|       from small pool |     464    |     557    |     425 K  |     425 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8112183809280396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2961934208869934
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277743458747864
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.512164831161499
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27971 GiB |  27964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27864 GiB |  27856 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27971 GiB |  27964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27864 GiB |  27856 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27971 GiB |  27964 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27864 GiB |  27856 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     891 K  |     890 K  |
|       from large pool |      93    |     178    |     464 K  |     464 K  |
|       from small pool |     464    |     557    |     426 K  |     426 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     891 K  |     890 K  |
|       from large pool |      93    |     178    |     464 K  |     464 K  |
|       from small pool |     464    |     557    |     426 K  |     426 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30690136551856995
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35072124004364014
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28031 GiB |  28024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27924 GiB |  27916 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28031 GiB |  28024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27924 GiB |  27916 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28031 GiB |  28024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27924 GiB |  27916 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     893 K  |     892 K  |
|       from large pool |      93    |     178    |     465 K  |     465 K  |
|       from small pool |     464    |     557    |     427 K  |     427 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     893 K  |     892 K  |
|       from large pool |      93    |     178    |     465 K  |     465 K  |
|       from small pool |     464    |     557    |     427 K  |     427 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.020768642425537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5399312376976013
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5637624263763428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44393324851989746
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28092 GiB |  28084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27984 GiB |  27976 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28092 GiB |  28084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27984 GiB |  27976 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28092 GiB |  28084 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27984 GiB |  27976 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     895 K  |     894 K  |
|       from large pool |      93    |     178    |     466 K  |     466 K  |
|       from small pool |     464    |     557    |     428 K  |     428 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     895 K  |     894 K  |
|       from large pool |      93    |     178    |     466 K  |     466 K  |
|       from small pool |     464    |     557    |     428 K  |     428 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2937313914299011
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4522640109062195
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.417385071516037
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28152 GiB |  28145 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28044 GiB |  28036 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28152 GiB |  28145 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28044 GiB |  28036 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28152 GiB |  28144 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28044 GiB |  28036 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     897 K  |     896 K  |
|       from large pool |      93    |     178    |     467 K  |     467 K  |
|       from small pool |     464    |     557    |     429 K  |     429 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     897 K  |     896 K  |
|       from large pool |      93    |     178    |     467 K  |     467 K  |
|       from small pool |     464    |     557    |     429 K  |     429 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3195478916168213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3309571444988251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3678264617919922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32141485810279846
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28212 GiB |  28205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28104 GiB |  28096 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28212 GiB |  28205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28104 GiB |  28096 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28212 GiB |  28205 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28104 GiB |  28096 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     899 K  |     899 K  |
|       from large pool |      93    |     178    |     468 K  |     468 K  |
|       from small pool |     464    |     557    |     430 K  |     430 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     899 K  |     899 K  |
|       from large pool |      93    |     178    |     468 K  |     468 K  |
|       from small pool |     464    |     557    |     430 K  |     430 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3885186016559601
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4946769177913666
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8951320648193359
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.077818751335144
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28272 GiB |  28265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28164 GiB |  28157 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28272 GiB |  28265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28164 GiB |  28157 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28272 GiB |  28265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28164 GiB |  28157 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     901 K  |     901 K  |
|       from large pool |      93    |     178    |     469 K  |     469 K  |
|       from small pool |     464    |     557    |     431 K  |     431 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     901 K  |     901 K  |
|       from large pool |      93    |     178    |     469 K  |     469 K  |
|       from small pool |     464    |     557    |     431 K  |     431 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2774108350276947
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.744400680065155
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5157862901687622
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33590614795684814
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28333 GiB |  28325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28224 GiB |  28217 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28333 GiB |  28325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28224 GiB |  28217 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28333 GiB |  28325 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28224 GiB |  28217 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     903 K  |     903 K  |
|       from large pool |      93    |     178    |     470 K  |     470 K  |
|       from small pool |     464    |     557    |     432 K  |     432 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     903 K  |     903 K  |
|       from large pool |      93    |     178    |     470 K  |     470 K  |
|       from small pool |     464    |     557    |     432 K  |     432 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.143923282623291
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3940907418727875
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28393 GiB |  28386 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28284 GiB |  28277 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28393 GiB |  28386 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28284 GiB |  28277 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28393 GiB |  28385 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28284 GiB |  28277 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     905 K  |     905 K  |
|       from large pool |      93    |     178    |     471 K  |     471 K  |
|       from small pool |     464    |     557    |     433 K  |     433 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     905 K  |     905 K  |
|       from large pool |      93    |     178    |     471 K  |     471 K  |
|       from small pool |     464    |     557    |     433 K  |     433 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4830005466938019
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  29419 GiB |  29413 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29305 GiB |  29300 GiB |
|       from small pool |      9 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  29419 GiB |  29413 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29305 GiB |  29300 GiB |
|       from small pool |      9 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  29418 GiB |  29413 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29305 GiB |  29300 GiB |
|       from small pool |      8 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  38578 MiB |  32764 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  38340 MiB |  32540 MiB |
|       from small pool |     14 MiB |     42 MiB |    238 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |     933 K  |     932 K  |
|       from large pool |      69    |     178    |     490 K  |     490 K  |
|       from small pool |     366    |     557    |     443 K  |     442 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |     933 K  |     932 K  |
|       from large pool |      69    |     178    |     490 K  |     490 K  |
|       from small pool |     366    |     557    |     443 K  |     442 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7012327909469604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6768987774848938
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.959564447402954
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2730965614318848
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29479 GiB |  29471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29365 GiB |  29358 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29479 GiB |  29471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29365 GiB |  29358 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29479 GiB |  29471 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29365 GiB |  29358 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     935 K  |     934 K  |
|       from large pool |      93    |     178    |     491 K  |     491 K  |
|       from small pool |     464    |     557    |     444 K  |     443 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     935 K  |     934 K  |
|       from large pool |      93    |     178    |     491 K  |     491 K  |
|       from small pool |     464    |     557    |     444 K  |     443 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4245123267173767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32746371626853943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30321088433265686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1697438955307007
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29539 GiB |  29532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29425 GiB |  29418 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29539 GiB |  29532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29425 GiB |  29418 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29539 GiB |  29532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29425 GiB |  29418 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     937 K  |     936 K  |
|       from large pool |      93    |     178    |     492 K  |     492 K  |
|       from small pool |     464    |     557    |     445 K  |     444 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     937 K  |     936 K  |
|       from large pool |      93    |     178    |     492 K  |     492 K  |
|       from small pool |     464    |     557    |     445 K  |     444 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7816647887229919
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4375529885292053
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5793851613998413
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29599 GiB |  29592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29478 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29599 GiB |  29592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29478 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29599 GiB |  29592 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29478 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     939 K  |     938 K  |
|       from large pool |      93    |     178    |     493 K  |     493 K  |
|       from small pool |     464    |     557    |     446 K  |     445 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     939 K  |     938 K  |
|       from large pool |      93    |     178    |     493 K  |     493 K  |
|       from small pool |     464    |     557    |     446 K  |     445 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36056557297706604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7435319423675537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2636568248271942
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29660 GiB |  29652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29546 GiB |  29538 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29660 GiB |  29652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29546 GiB |  29538 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29659 GiB |  29652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29546 GiB |  29538 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     941 K  |     940 K  |
|       from large pool |      93    |     178    |     494 K  |     494 K  |
|       from small pool |     464    |     557    |     447 K  |     446 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     941 K  |     940 K  |
|       from large pool |      93    |     178    |     494 K  |     494 K  |
|       from small pool |     464    |     557    |     447 K  |     446 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26824524998664856
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6041659712791443
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30960673093795776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4925594627857208
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29720 GiB |  29712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29606 GiB |  29598 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29720 GiB |  29712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29606 GiB |  29598 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29720 GiB |  29712 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29606 GiB |  29598 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     943 K  |     942 K  |
|       from large pool |      93    |     178    |     495 K  |     495 K  |
|       from small pool |     464    |     557    |     448 K  |     447 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     943 K  |     942 K  |
|       from large pool |      93    |     178    |     495 K  |     495 K  |
|       from small pool |     464    |     557    |     448 K  |     447 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3610459864139557
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7348750233650208
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31261447072029114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37968042492866516
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29780 GiB |  29773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29666 GiB |  29658 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29780 GiB |  29773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29666 GiB |  29658 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29780 GiB |  29773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29666 GiB |  29658 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     945 K  |     945 K  |
|       from large pool |      93    |     178    |     496 K  |     495 K  |
|       from small pool |     464    |     557    |     449 K  |     449 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     945 K  |     945 K  |
|       from large pool |      93    |     178    |     496 K  |     495 K  |
|       from small pool |     464    |     557    |     449 K  |     449 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3064850866794586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6322617530822754
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9828314185142517
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29840 GiB |  29833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29726 GiB |  29718 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29840 GiB |  29833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29726 GiB |  29718 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29840 GiB |  29833 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29726 GiB |  29718 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     947 K  |     947 K  |
|       from large pool |      93    |     178    |     497 K  |     496 K  |
|       from small pool |     464    |     557    |     450 K  |     450 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     947 K  |     947 K  |
|       from large pool |      93    |     178    |     497 K  |     496 K  |
|       from small pool |     464    |     557    |     450 K  |     450 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5660059452056885
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34321141242980957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3221050202846527
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2249256372451782
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29901 GiB |  29893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29786 GiB |  29778 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29901 GiB |  29893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29786 GiB |  29778 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29901 GiB |  29893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29786 GiB |  29778 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     949 K  |     949 K  |
|       from large pool |      93    |     178    |     498 K  |     497 K  |
|       from small pool |     464    |     557    |     451 K  |     451 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     949 K  |     949 K  |
|       from large pool |      93    |     178    |     498 K  |     497 K  |
|       from small pool |     464    |     557    |     451 K  |     451 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27635854482650757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39237332344055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29961 GiB |  29953 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29846 GiB |  29838 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29961 GiB |  29953 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29846 GiB |  29838 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29961 GiB |  29953 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29846 GiB |  29838 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     951 K  |     951 K  |
|       from large pool |      93    |     178    |     498 K  |     498 K  |
|       from small pool |     464    |     557    |     452 K  |     452 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     951 K  |     951 K  |
|       from large pool |      93    |     178    |     498 K  |     498 K  |
|       from small pool |     464    |     557    |     452 K  |     452 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.71439528465271
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3958813548088074
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3083411157131195
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44660109281539917
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30021 GiB |  30014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29906 GiB |  29898 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30021 GiB |  30014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29906 GiB |  29898 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30021 GiB |  30014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29906 GiB |  29898 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     953 K  |     953 K  |
|       from large pool |      93    |     178    |     499 K  |     499 K  |
|       from small pool |     464    |     557    |     453 K  |     453 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     953 K  |     953 K  |
|       from large pool |      93    |     178    |     499 K  |     499 K  |
|       from small pool |     464    |     557    |     453 K  |     453 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2972389757633209
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3084021806716919
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30081 GiB |  30074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29966 GiB |  29958 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30081 GiB |  30074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29966 GiB |  29958 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30081 GiB |  30074 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29966 GiB |  29958 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     955 K  |     955 K  |
|       from large pool |      93    |     178    |     500 K  |     500 K  |
|       from small pool |     464    |     557    |     454 K  |     454 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     955 K  |     955 K  |
|       from large pool |      93    |     178    |     500 K  |     500 K  |
|       from small pool |     464    |     557    |     454 K  |     454 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.530341625213623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934279143810272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.146493673324585
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30142 GiB |  30134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30026 GiB |  30018 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30142 GiB |  30134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30026 GiB |  30018 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30141 GiB |  30134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30026 GiB |  30018 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     957 K  |     957 K  |
|       from large pool |      93    |     178    |     501 K  |     501 K  |
|       from small pool |     464    |     557    |     455 K  |     455 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     957 K  |     957 K  |
|       from large pool |      93    |     178    |     501 K  |     501 K  |
|       from small pool |     464    |     557    |     455 K  |     455 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.767556369304657
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7163669466972351
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27946630120277405
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49904075264930725
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30202 GiB |  30194 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30086 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30202 GiB |  30194 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30086 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30202 GiB |  30194 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30086 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     959 K  |     959 K  |
|       from large pool |      93    |     178    |     502 K  |     502 K  |
|       from small pool |     464    |     557    |     456 K  |     456 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     959 K  |     959 K  |
|       from large pool |      93    |     178    |     502 K  |     502 K  |
|       from small pool |     464    |     557    |     456 K  |     456 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3460235297679901
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3480775058269501
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5983378291130066
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30262 GiB |  30255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30146 GiB |  30138 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30262 GiB |  30255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30146 GiB |  30138 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30262 GiB |  30255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30146 GiB |  30138 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     961 K  |     961 K  |
|       from large pool |      93    |     178    |     503 K  |     503 K  |
|       from small pool |     464    |     557    |     457 K  |     457 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     961 K  |     961 K  |
|       from large pool |      93    |     178    |     503 K  |     503 K  |
|       from small pool |     464    |     557    |     457 K  |     457 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27943864464759827
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2939455211162567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5210046768188477
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30322 GiB |  30315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30206 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30322 GiB |  30315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30206 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30322 GiB |  30315 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30206 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     963 K  |     963 K  |
|       from large pool |      93    |     178    |     504 K  |     504 K  |
|       from small pool |     464    |     557    |     458 K  |     458 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     963 K  |     963 K  |
|       from large pool |      93    |     178    |     504 K  |     504 K  |
|       from small pool |     464    |     557    |     458 K  |     458 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7247592210769653
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.1832032203674316
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6760433912277222
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9549425840377808
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30383 GiB |  30375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30266 GiB |  30258 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30383 GiB |  30375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30266 GiB |  30258 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30382 GiB |  30375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30266 GiB |  30258 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     965 K  |     965 K  |
|       from large pool |      93    |     178    |     505 K  |     505 K  |
|       from small pool |     464    |     557    |     459 K  |     459 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     965 K  |     965 K  |
|       from large pool |      93    |     178    |     505 K  |     505 K  |
|       from small pool |     464    |     557    |     459 K  |     459 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3498036563396454
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7805810570716858
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30443 GiB |  30435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30326 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30443 GiB |  30435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30326 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30443 GiB |  30435 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30326 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     967 K  |     967 K  |
|       from large pool |      93    |     178    |     506 K  |     506 K  |
|       from small pool |     464    |     557    |     460 K  |     460 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     967 K  |     967 K  |
|       from large pool |      93    |     178    |     506 K  |     506 K  |
|       from small pool |     464    |     557    |     460 K  |     460 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3302747905254364
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.007093906402588
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1479820013046265
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30503 GiB |  30496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30386 GiB |  30378 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30503 GiB |  30496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30386 GiB |  30378 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30503 GiB |  30496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30386 GiB |  30378 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     969 K  |     969 K  |
|       from large pool |      93    |     178    |     507 K  |     507 K  |
|       from small pool |     464    |     557    |     461 K  |     461 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     969 K  |     969 K  |
|       from large pool |      93    |     178    |     507 K  |     507 K  |
|       from small pool |     464    |     557    |     461 K  |     461 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5999115705490112
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9031261205673218
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2931276857852936
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4080217480659485
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30563 GiB |  30556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30446 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30563 GiB |  30556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30446 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30563 GiB |  30556 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30446 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     971 K  |     971 K  |
|       from large pool |      93    |     178    |     508 K  |     508 K  |
|       from small pool |     464    |     557    |     463 K  |     462 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     971 K  |     971 K  |
|       from large pool |      93    |     178    |     508 K  |     508 K  |
|       from small pool |     464    |     557    |     463 K  |     462 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8418792486190796
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6597893238067627
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32146796584129333
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30624 GiB |  30616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30506 GiB |  30498 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30624 GiB |  30616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30506 GiB |  30498 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30623 GiB |  30616 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30506 GiB |  30498 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     973 K  |     973 K  |
|       from large pool |      93    |     178    |     509 K  |     509 K  |
|       from small pool |     464    |     557    |     464 K  |     463 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     973 K  |     973 K  |
|       from large pool |      93    |     178    |     509 K  |     509 K  |
|       from small pool |     464    |     557    |     464 K  |     463 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.24960766732692719
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3697932958602905
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5459722876548767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4065341055393219
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30684 GiB |  30676 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30566 GiB |  30559 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30684 GiB |  30676 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30566 GiB |  30559 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30684 GiB |  30676 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30566 GiB |  30559 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     975 K  |     975 K  |
|       from large pool |      93    |     178    |     510 K  |     510 K  |
|       from small pool |     464    |     557    |     465 K  |     464 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     975 K  |     975 K  |
|       from large pool |      93    |     178    |     510 K  |     510 K  |
|       from small pool |     464    |     557    |     465 K  |     464 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3288898468017578
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3475848436355591
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40844011306762695
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30744 GiB |  30737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30626 GiB |  30619 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30744 GiB |  30737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30626 GiB |  30619 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30744 GiB |  30737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30626 GiB |  30619 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     977 K  |     977 K  |
|       from large pool |      93    |     178    |     511 K  |     511 K  |
|       from small pool |     464    |     557    |     466 K  |     465 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     977 K  |     977 K  |
|       from large pool |      93    |     178    |     511 K  |     511 K  |
|       from small pool |     464    |     557    |     466 K  |     465 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.880405843257904
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.121046543121338
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3334875702857971
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32480448484420776
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30804 GiB |  30797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30686 GiB |  30679 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30804 GiB |  30797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30686 GiB |  30679 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30804 GiB |  30797 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30686 GiB |  30679 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     979 K  |     979 K  |
|       from large pool |      93    |     178    |     512 K  |     512 K  |
|       from small pool |     464    |     557    |     467 K  |     466 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     979 K  |     979 K  |
|       from large pool |      93    |     178    |     512 K  |     512 K  |
|       from small pool |     464    |     557    |     467 K  |     466 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33540695905685425
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33273300528526306
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6428158283233643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38700729608535767
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30865 GiB |  30857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30746 GiB |  30739 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30865 GiB |  30857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30746 GiB |  30739 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30865 GiB |  30857 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30746 GiB |  30739 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     981 K  |     981 K  |
|       from large pool |      93    |     178    |     513 K  |     513 K  |
|       from small pool |     464    |     557    |     468 K  |     467 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     981 K  |     981 K  |
|       from large pool |      93    |     178    |     513 K  |     513 K  |
|       from small pool |     464    |     557    |     468 K  |     467 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38971251249313354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44530007243156433
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4129522740840912
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27337580919265747
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30925 GiB |  30917 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30806 GiB |  30799 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30925 GiB |  30917 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30806 GiB |  30799 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30925 GiB |  30917 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30806 GiB |  30799 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     983 K  |     983 K  |
|       from large pool |      93    |     178    |     514 K  |     514 K  |
|       from small pool |     464    |     557    |     469 K  |     468 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     983 K  |     983 K  |
|       from large pool |      93    |     178    |     514 K  |     514 K  |
|       from small pool |     464    |     557    |     469 K  |     468 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47931110858917236
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31752562522888184
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8990013599395752
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43906450271606445
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30985 GiB |  30978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30866 GiB |  30859 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30985 GiB |  30978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30866 GiB |  30859 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30985 GiB |  30978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30866 GiB |  30859 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     985 K  |     985 K  |
|       from large pool |      93    |     178    |     515 K  |     515 K  |
|       from small pool |     464    |     557    |     470 K  |     469 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     985 K  |     985 K  |
|       from large pool |      93    |     178    |     515 K  |     515 K  |
|       from small pool |     464    |     557    |     470 K  |     469 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2859288454055786
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3845539391040802
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31036514043807983
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31045 GiB |  31038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30926 GiB |  30919 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31045 GiB |  31038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30926 GiB |  30919 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31045 GiB |  31038 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30926 GiB |  30919 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     987 K  |     987 K  |
|       from large pool |      93    |     178    |     516 K  |     516 K  |
|       from small pool |     464    |     557    |     471 K  |     470 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     987 K  |     987 K  |
|       from large pool |      93    |     178    |     516 K  |     516 K  |
|       from small pool |     464    |     557    |     471 K  |     470 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.982544422149658
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4932782053947449
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4250364303588867
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2966454029083252
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31106 GiB |  31098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30986 GiB |  30979 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31106 GiB |  31098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30986 GiB |  30979 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31106 GiB |  31098 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30986 GiB |  30979 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     989 K  |     989 K  |
|       from large pool |      93    |     178    |     517 K  |     517 K  |
|       from small pool |     464    |     557    |     472 K  |     472 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     989 K  |     989 K  |
|       from large pool |      93    |     178    |     517 K  |     517 K  |
|       from small pool |     464    |     557    |     472 K  |     472 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2986525893211365
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6313495635986328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30833685398101807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46955808997154236
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31166 GiB |  31158 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31046 GiB |  31039 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31166 GiB |  31158 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31046 GiB |  31039 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31166 GiB |  31158 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31046 GiB |  31039 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     991 K  |     991 K  |
|       from large pool |      93    |     178    |     518 K  |     518 K  |
|       from small pool |     464    |     557    |     473 K  |     473 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     991 K  |     991 K  |
|       from large pool |      93    |     178    |     518 K  |     518 K  |
|       from small pool |     464    |     557    |     473 K  |     473 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3583366572856903
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37499508261680603
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31226 GiB |  31219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31106 GiB |  31099 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31226 GiB |  31219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31106 GiB |  31099 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31226 GiB |  31219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31106 GiB |  31099 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     993 K  |     993 K  |
|       from large pool |      93    |     178    |     519 K  |     519 K  |
|       from small pool |     464    |     557    |     474 K  |     474 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     993 K  |     993 K  |
|       from large pool |      93    |     178    |     519 K  |     519 K  |
|       from small pool |     464    |     557    |     474 K  |     474 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2596176862716675
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.518908977508545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4426724910736084
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2881893217563629
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31286 GiB |  31279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31166 GiB |  31159 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31286 GiB |  31279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31166 GiB |  31159 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31286 GiB |  31279 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31166 GiB |  31159 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     996 K  |     995 K  |
|       from large pool |      93    |     178    |     520 K  |     520 K  |
|       from small pool |     464    |     557    |     475 K  |     475 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     996 K  |     995 K  |
|       from large pool |      93    |     178    |     520 K  |     520 K  |
|       from small pool |     464    |     557    |     475 K  |     475 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29457002878189087
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7104032635688782
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33935871720314026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6920673847198486
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31347 GiB |  31339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31226 GiB |  31219 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31347 GiB |  31339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31226 GiB |  31219 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31347 GiB |  31339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31226 GiB |  31219 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     998 K  |     997 K  |
|       from large pool |      93    |     178    |     521 K  |     521 K  |
|       from small pool |     464    |     557    |     476 K  |     476 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     998 K  |     997 K  |
|       from large pool |      93    |     178    |     521 K  |     521 K  |
|       from small pool |     464    |     557    |     476 K  |     476 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42006558179855347
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7361637949943542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8761228919029236
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31407 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31286 GiB |  31279 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31407 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31286 GiB |  31279 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31407 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31286 GiB |  31279 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1000 K  |     999 K  |
|       from large pool |      93    |     178    |     522 K  |     522 K  |
|       from small pool |     464    |     557    |     477 K  |     477 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1000 K  |     999 K  |
|       from large pool |      93    |     178    |     522 K  |     522 K  |
|       from small pool |     464    |     557    |     477 K  |     477 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8045116066932678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30721744894981384
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4349144697189331
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32019585371017456
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31467 GiB |  31460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31346 GiB |  31339 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31467 GiB |  31460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31346 GiB |  31339 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31467 GiB |  31460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31346 GiB |  31339 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1002 K  |    1001 K  |
|       from large pool |      93    |     178    |     523 K  |     523 K  |
|       from small pool |     464    |     557    |     478 K  |     478 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1002 K  |    1001 K  |
|       from large pool |      93    |     178    |     523 K  |     523 K  |
|       from small pool |     464    |     557    |     478 K  |     478 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647907316684723
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6221219301223755
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46378180384635925
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31527 GiB |  31520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31399 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31527 GiB |  31520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31399 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31527 GiB |  31520 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31399 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1004 K  |    1003 K  |
|       from large pool |      93    |     178    |     524 K  |     524 K  |
|       from small pool |     464    |     557    |     479 K  |     479 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1004 K  |    1003 K  |
|       from large pool |      93    |     178    |     524 K  |     524 K  |
|       from small pool |     464    |     557    |     479 K  |     479 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3581021726131439
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4509026110172272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29534807801246643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3429086208343506
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31588 GiB |  31580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31466 GiB |  31459 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31588 GiB |  31580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31466 GiB |  31459 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31588 GiB |  31580 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31466 GiB |  31459 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1006 K  |    1005 K  |
|       from large pool |      93    |     178    |     525 K  |     525 K  |
|       from small pool |     464    |     557    |     480 K  |     480 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1006 K  |    1005 K  |
|       from large pool |      93    |     178    |     525 K  |     525 K  |
|       from small pool |     464    |     557    |     480 K  |     480 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7649170160293579
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2788582742214203
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3115488588809967
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5022445917129517
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31648 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31519 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31648 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31519 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31648 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31519 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1008 K  |    1007 K  |
|       from large pool |      93    |     178    |     526 K  |     526 K  |
|       from small pool |     464    |     557    |     481 K  |     481 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1008 K  |    1007 K  |
|       from large pool |      93    |     178    |     526 K  |     526 K  |
|       from small pool |     464    |     557    |     481 K  |     481 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2896858751773834
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339032381772995
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31708 GiB |  31701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31586 GiB |  31579 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31708 GiB |  31701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31586 GiB |  31579 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31708 GiB |  31701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31586 GiB |  31579 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1010 K  |    1009 K  |
|       from large pool |      93    |     178    |     527 K  |     527 K  |
|       from small pool |     464    |     557    |     482 K  |     482 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1010 K  |    1009 K  |
|       from large pool |      93    |     178    |     527 K  |     527 K  |
|       from small pool |     464    |     557    |     482 K  |     482 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9852867126464844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5266013741493225
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5412187576293945
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43140870332717896
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31768 GiB |  31761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31639 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31768 GiB |  31761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31639 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31768 GiB |  31761 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31639 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1012 K  |    1011 K  |
|       from large pool |      93    |     178    |     528 K  |     528 K  |
|       from small pool |     464    |     557    |     484 K  |     483 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1012 K  |    1011 K  |
|       from large pool |      93    |     178    |     528 K  |     528 K  |
|       from small pool |     464    |     557    |     484 K  |     483 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2765684127807617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43842560052871704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40749555826187134
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31829 GiB |  31821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31706 GiB |  31699 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31829 GiB |  31821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31706 GiB |  31699 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31829 GiB |  31821 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31706 GiB |  31699 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1014 K  |    1013 K  |
|       from large pool |      93    |     178    |     529 K  |     529 K  |
|       from small pool |     464    |     557    |     485 K  |     484 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1014 K  |    1013 K  |
|       from large pool |      93    |     178    |     529 K  |     529 K  |
|       from small pool |     464    |     557    |     485 K  |     484 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31202223896980286
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30966389179229736
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3586636781692505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3084482252597809
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31889 GiB |  31881 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31759 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31889 GiB |  31881 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31759 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31889 GiB |  31881 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31759 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1016 K  |    1015 K  |
|       from large pool |      93    |     178    |     530 K  |     530 K  |
|       from small pool |     464    |     557    |     486 K  |     485 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1016 K  |    1015 K  |
|       from large pool |      93    |     178    |     530 K  |     530 K  |
|       from small pool |     464    |     557    |     486 K  |     485 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3757885694503784
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46557512879371643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8691501021385193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.056811809539795
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31949 GiB |  31942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31826 GiB |  31819 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31949 GiB |  31942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31826 GiB |  31819 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31949 GiB |  31942 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31826 GiB |  31819 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1018 K  |    1017 K  |
|       from large pool |      93    |     178    |     531 K  |     530 K  |
|       from small pool |     464    |     557    |     487 K  |     486 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1018 K  |    1017 K  |
|       from large pool |      93    |     178    |     531 K  |     530 K  |
|       from small pool |     464    |     557    |     487 K  |     486 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26584452390670776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.719364583492279
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.472780466079712
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277837634086609
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  32009 GiB |  32002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31887 GiB |  31879 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  32009 GiB |  32002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31887 GiB |  31879 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  32009 GiB |  32002 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31887 GiB |  31879 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1020 K  |    1019 K  |
|       from large pool |      93    |     178    |     532 K  |     531 K  |
|       from small pool |     464    |     557    |     488 K  |     487 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1020 K  |    1019 K  |
|       from large pool |      93    |     178    |     532 K  |     531 K  |
|       from small pool |     464    |     557    |     488 K  |     487 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.1056928634643555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3768501877784729
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  32070 GiB |  32062 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31947 GiB |  31939 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  32070 GiB |  32062 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31947 GiB |  31939 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  32070 GiB |  32062 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31947 GiB |  31939 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1022 K  |    1021 K  |
|       from large pool |      93    |     178    |     533 K  |     532 K  |
|       from small pool |     464    |     557    |     489 K  |     488 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1022 K  |    1021 K  |
|       from large pool |      93    |     178    |     533 K  |     532 K  |
|       from small pool |     464    |     557    |     489 K  |     488 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4697430729866028
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([4, 21, 1, 360, 360])
0
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  33095 GiB |  33090 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  32968 GiB |  32962 GiB |
|       from small pool |      9 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  33095 GiB |  33090 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  32968 GiB |  32962 GiB |
|       from small pool |      9 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  33095 GiB |  33090 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  32968 GiB |  32962 GiB |
|       from small pool |      8 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  42726 MiB |  36912 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  42460 MiB |  36660 MiB |
|       from small pool |     14 MiB |     42 MiB |    266 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |    1050 K  |    1049 K  |
|       from large pool |      69    |     178    |     551 K  |     551 K  |
|       from small pool |     366    |     557    |     498 K  |     498 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |    1050 K  |    1049 K  |
|       from large pool |      69    |     178    |     551 K  |     551 K  |
|       from small pool |     366    |     557    |     498 K  |     498 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.693540632724762
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6579349637031555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.928483247756958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1928136348724365
1
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33155 GiB |  33148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33028 GiB |  33021 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33155 GiB |  33148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33028 GiB |  33021 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33155 GiB |  33148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33028 GiB |  33021 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1052 K  |    1051 K  |
|       from large pool |      93    |     178    |     552 K  |     552 K  |
|       from small pool |     464    |     557    |     499 K  |     499 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1052 K  |    1051 K  |
|       from large pool |      93    |     178    |     552 K  |     552 K  |
|       from small pool |     464    |     557    |     499 K  |     499 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40681248903274536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3173936903476715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2905552089214325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.136673092842102
2
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33216 GiB |  33208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33088 GiB |  33081 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33216 GiB |  33208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33088 GiB |  33081 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33216 GiB |  33208 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33088 GiB |  33081 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1054 K  |    1053 K  |
|       from large pool |      93    |     178    |     553 K  |     553 K  |
|       from small pool |     464    |     557    |     500 K  |     500 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1054 K  |    1053 K  |
|       from large pool |      93    |     178    |     553 K  |     553 K  |
|       from small pool |     464    |     557    |     500 K  |     500 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7322322130203247
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4317569434642792
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5698574185371399
3
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33276 GiB |  33269 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33148 GiB |  33141 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33276 GiB |  33269 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33148 GiB |  33141 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33276 GiB |  33268 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33148 GiB |  33141 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1056 K  |    1055 K  |
|       from large pool |      93    |     178    |     554 K  |     554 K  |
|       from small pool |     464    |     557    |     501 K  |     501 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1056 K  |    1055 K  |
|       from large pool |      93    |     178    |     554 K  |     554 K  |
|       from small pool |     464    |     557    |     501 K  |     501 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3535853922367096
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.717613935470581
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25894397497177124
4
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33336 GiB |  33329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33208 GiB |  33201 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33336 GiB |  33329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33208 GiB |  33201 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33336 GiB |  33329 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33208 GiB |  33201 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1058 K  |    1057 K  |
|       from large pool |      93    |     178    |     555 K  |     555 K  |
|       from small pool |     464    |     557    |     502 K  |     502 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1058 K  |    1057 K  |
|       from large pool |      93    |     178    |     555 K  |     555 K  |
|       from small pool |     464    |     557    |     502 K  |     502 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2580583393573761
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5890412330627441
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29087549448013306
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47456738352775574
5
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33396 GiB |  33389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33268 GiB |  33261 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33396 GiB |  33389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33268 GiB |  33261 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33396 GiB |  33389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33268 GiB |  33261 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1060 K  |    1059 K  |
|       from large pool |      93    |     178    |     556 K  |     556 K  |
|       from small pool |     464    |     557    |     503 K  |     503 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1060 K  |    1059 K  |
|       from large pool |      93    |     178    |     556 K  |     556 K  |
|       from small pool |     464    |     557    |     503 K  |     503 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35363325476646423
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7146875262260437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30186089873313904
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3687035143375397
6
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33457 GiB |  33449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33328 GiB |  33321 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33457 GiB |  33449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33328 GiB |  33321 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33457 GiB |  33449 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33328 GiB |  33321 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1062 K  |    1061 K  |
|       from large pool |      93    |     178    |     557 K  |     557 K  |
|       from small pool |     464    |     557    |     504 K  |     504 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1062 K  |    1061 K  |
|       from large pool |      93    |     178    |     557 K  |     557 K  |
|       from small pool |     464    |     557    |     504 K  |     504 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29473981261253357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6211012005805969
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9554638862609863
7
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33517 GiB |  33510 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33388 GiB |  33381 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33517 GiB |  33510 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33388 GiB |  33381 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33517 GiB |  33509 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33388 GiB |  33381 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1064 K  |    1063 K  |
|       from large pool |      93    |     178    |     558 K  |     558 K  |
|       from small pool |     464    |     557    |     505 K  |     505 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1064 K  |    1063 K  |
|       from large pool |      93    |     178    |     558 K  |     558 K  |
|       from small pool |     464    |     557    |     505 K  |     505 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5585214495658875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3318652808666229
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30660611391067505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2095849514007568
8
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33577 GiB |  33570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33448 GiB |  33441 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33577 GiB |  33570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33448 GiB |  33441 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33577 GiB |  33570 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33448 GiB |  33441 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1066 K  |    1065 K  |
|       from large pool |      93    |     178    |     559 K  |     559 K  |
|       from small pool |     464    |     557    |     506 K  |     506 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1066 K  |    1065 K  |
|       from large pool |      93    |     178    |     559 K  |     559 K  |
|       from small pool |     464    |     557    |     506 K  |     506 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26302003860473633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3856435716152191
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
9
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33637 GiB |  33630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33508 GiB |  33501 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33637 GiB |  33630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33508 GiB |  33501 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33637 GiB |  33630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33508 GiB |  33501 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1068 K  |    1067 K  |
|       from large pool |      93    |     178    |     560 K  |     560 K  |
|       from small pool |     464    |     557    |     507 K  |     507 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1068 K  |    1067 K  |
|       from large pool |      93    |     178    |     560 K  |     560 K  |
|       from small pool |     464    |     557    |     507 K  |     507 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7001263499259949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39076924324035645
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2909272015094757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4353330731391907
10
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33698 GiB |  33690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33568 GiB |  33561 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33698 GiB |  33690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33568 GiB |  33561 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33698 GiB |  33690 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33568 GiB |  33561 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1070 K  |    1069 K  |
|       from large pool |      93    |     178    |     561 K  |     561 K  |
|       from small pool |     464    |     557    |     509 K  |     508 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1070 K  |    1069 K  |
|       from large pool |      93    |     178    |     561 K  |     561 K  |
|       from small pool |     464    |     557    |     509 K  |     508 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934657633304596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3020230829715729
11
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33758 GiB |  33751 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33628 GiB |  33621 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33758 GiB |  33751 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33628 GiB |  33621 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33758 GiB |  33750 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33628 GiB |  33621 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1072 K  |    1071 K  |
|       from large pool |      93    |     178    |     562 K  |     562 K  |
|       from small pool |     464    |     557    |     510 K  |     509 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1072 K  |    1071 K  |
|       from large pool |      93    |     178    |     562 K  |     562 K  |
|       from small pool |     464    |     557    |     510 K  |     509 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5108436346054077
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28752565383911133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1144323348999023
12
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33818 GiB |  33811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33688 GiB |  33681 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33818 GiB |  33811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33688 GiB |  33681 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33818 GiB |  33811 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33688 GiB |  33681 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1074 K  |    1073 K  |
|       from large pool |      93    |     178    |     563 K  |     563 K  |
|       from small pool |     464    |     557    |     511 K  |     510 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1074 K  |    1073 K  |
|       from large pool |      93    |     178    |     563 K  |     563 K  |
|       from small pool |     464    |     557    |     511 K  |     510 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7548717856407166
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7015661597251892
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2655992805957794
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4824598729610443
13
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33878 GiB |  33871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33748 GiB |  33741 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33878 GiB |  33871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33748 GiB |  33741 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33878 GiB |  33871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33748 GiB |  33741 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1076 K  |    1075 K  |
|       from large pool |      93    |     178    |     564 K  |     564 K  |
|       from small pool |     464    |     557    |     512 K  |     511 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1076 K  |    1075 K  |
|       from large pool |      93    |     178    |     564 K  |     564 K  |
|       from small pool |     464    |     557    |     512 K  |     511 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339358389377594
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3373473882675171
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5819714665412903
14
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33939 GiB |  33931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33808 GiB |  33801 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33939 GiB |  33931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33808 GiB |  33801 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33939 GiB |  33931 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33808 GiB |  33801 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1078 K  |    1077 K  |
|       from large pool |      93    |     178    |     565 K  |     565 K  |
|       from small pool |     464    |     557    |     513 K  |     512 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1078 K  |    1077 K  |
|       from large pool |      93    |     178    |     565 K  |     565 K  |
|       from small pool |     464    |     557    |     513 K  |     512 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2661121189594269
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27563580870628357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5024704933166504
15
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33999 GiB |  33992 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33868 GiB |  33861 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33999 GiB |  33992 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33868 GiB |  33861 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33999 GiB |  33991 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33868 GiB |  33861 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1080 K  |    1079 K  |
|       from large pool |      93    |     178    |     566 K  |     566 K  |
|       from small pool |     464    |     557    |     514 K  |     513 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1080 K  |    1079 K  |
|       from large pool |      93    |     178    |     566 K  |     566 K  |
|       from small pool |     464    |     557    |     514 K  |     513 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7264050841331482
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.1469216346740723
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6701516509056091
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9373541474342346
16
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34059 GiB |  34052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33928 GiB |  33921 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34059 GiB |  34052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33928 GiB |  33921 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34059 GiB |  34052 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33928 GiB |  33921 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1082 K  |    1081 K  |
|       from large pool |      93    |     178    |     567 K  |     566 K  |
|       from small pool |     464    |     557    |     515 K  |     514 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1082 K  |    1081 K  |
|       from large pool |      93    |     178    |     567 K  |     566 K  |
|       from small pool |     464    |     557    |     515 K  |     514 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33666372299194336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7623443603515625
17
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34119 GiB |  34112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33988 GiB |  33981 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34119 GiB |  34112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33988 GiB |  33981 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34119 GiB |  34112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33988 GiB |  33981 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1084 K  |    1083 K  |
|       from large pool |      93    |     178    |     568 K  |     567 K  |
|       from small pool |     464    |     557    |     516 K  |     515 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1084 K  |    1083 K  |
|       from large pool |      93    |     178    |     568 K  |     567 K  |
|       from small pool |     464    |     557    |     516 K  |     515 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3192974925041199
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.9725024700164795
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1234350204467773
18
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34180 GiB |  34172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34048 GiB |  34041 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34180 GiB |  34172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34048 GiB |  34041 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34180 GiB |  34172 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34048 GiB |  34041 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1086 K  |    1085 K  |
|       from large pool |      93    |     178    |     569 K  |     568 K  |
|       from small pool |     464    |     557    |     517 K  |     516 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1086 K  |    1085 K  |
|       from large pool |      93    |     178    |     569 K  |     568 K  |
|       from small pool |     464    |     557    |     517 K  |     516 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5868390202522278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8784924745559692
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28700289130210876
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40265190601348877
19
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34240 GiB |  34233 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34108 GiB |  34101 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34240 GiB |  34233 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34108 GiB |  34101 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34240 GiB |  34232 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34108 GiB |  34101 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1088 K  |    1087 K  |
|       from large pool |      93    |     178    |     569 K  |     569 K  |
|       from small pool |     464    |     557    |     518 K  |     517 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1088 K  |    1087 K  |
|       from large pool |      93    |     178    |     569 K  |     569 K  |
|       from small pool |     464    |     557    |     518 K  |     517 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.818615734577179
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6450898051261902
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31625646352767944
20
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34300 GiB |  34293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34168 GiB |  34161 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34300 GiB |  34293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34168 GiB |  34161 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34300 GiB |  34293 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34168 GiB |  34161 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1090 K  |    1089 K  |
|       from large pool |      93    |     178    |     570 K  |     570 K  |
|       from small pool |     464    |     557    |     519 K  |     518 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1090 K  |    1089 K  |
|       from large pool |      93    |     178    |     570 K  |     570 K  |
|       from small pool |     464    |     557    |     519 K  |     518 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.23847685754299164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34598883986473083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5259736776351929
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3959523141384125
21
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34360 GiB |  34353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34228 GiB |  34221 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34360 GiB |  34353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34228 GiB |  34221 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34360 GiB |  34353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34228 GiB |  34221 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1092 K  |    1091 K  |
|       from large pool |      93    |     178    |     571 K  |     571 K  |
|       from small pool |     464    |     557    |     520 K  |     520 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1092 K  |    1091 K  |
|       from large pool |      93    |     178    |     571 K  |     571 K  |
|       from small pool |     464    |     557    |     520 K  |     520 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31735894083976746
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3372364044189453
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3983061611652374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
22
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34421 GiB |  34413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34289 GiB |  34281 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34421 GiB |  34413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34289 GiB |  34281 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34421 GiB |  34413 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34289 GiB |  34281 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1094 K  |    1093 K  |
|       from large pool |      93    |     178    |     572 K  |     572 K  |
|       from small pool |     464    |     557    |     521 K  |     521 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1094 K  |    1093 K  |
|       from large pool |      93    |     178    |     572 K  |     572 K  |
|       from small pool |     464    |     557    |     521 K  |     521 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8612839579582214
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0949510335922241
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32029056549072266
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3059912919998169
23
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34481 GiB |  34474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34349 GiB |  34341 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34481 GiB |  34474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34349 GiB |  34341 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34481 GiB |  34474 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34349 GiB |  34341 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1096 K  |    1095 K  |
|       from large pool |      93    |     178    |     573 K  |     573 K  |
|       from small pool |     464    |     557    |     522 K  |     522 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1096 K  |    1095 K  |
|       from large pool |      93    |     178    |     573 K  |     573 K  |
|       from small pool |     464    |     557    |     522 K  |     522 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31798598170280457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3149357736110687
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6279577016830444
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37705492973327637
24
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34541 GiB |  34534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34409 GiB |  34401 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34541 GiB |  34534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34409 GiB |  34401 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34541 GiB |  34534 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34409 GiB |  34401 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1098 K  |    1097 K  |
|       from large pool |      93    |     178    |     574 K  |     574 K  |
|       from small pool |     464    |     557    |     523 K  |     523 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1098 K  |    1097 K  |
|       from large pool |      93    |     178    |     574 K  |     574 K  |
|       from small pool |     464    |     557    |     523 K  |     523 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38158321380615234
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4312494099140167
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40601539611816406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25878503918647766
25
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34602 GiB |  34594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34469 GiB |  34461 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34602 GiB |  34594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34469 GiB |  34461 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34601 GiB |  34594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34469 GiB |  34461 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1100 K  |    1099 K  |
|       from large pool |      93    |     178    |     575 K  |     575 K  |
|       from small pool |     464    |     557    |     524 K  |     524 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1100 K  |    1099 K  |
|       from large pool |      93    |     178    |     575 K  |     575 K  |
|       from small pool |     464    |     557    |     524 K  |     524 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47405463457107544
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30011799931526184
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8759403228759766
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43228986859321594
26
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34662 GiB |  34654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34529 GiB |  34521 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34662 GiB |  34654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34529 GiB |  34521 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34662 GiB |  34654 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34529 GiB |  34521 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1102 K  |    1101 K  |
|       from large pool |      93    |     178    |     576 K  |     576 K  |
|       from small pool |     464    |     557    |     525 K  |     525 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1102 K  |    1101 K  |
|       from large pool |      93    |     178    |     576 K  |     576 K  |
|       from small pool |     464    |     557    |     525 K  |     525 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27250176668167114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37063175439834595
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29902151226997375
27
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34722 GiB |  34715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34589 GiB |  34581 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34722 GiB |  34715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34589 GiB |  34581 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34722 GiB |  34715 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34589 GiB |  34581 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1104 K  |    1103 K  |
|       from large pool |      93    |     178    |     577 K  |     577 K  |
|       from small pool |     464    |     557    |     526 K  |     526 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1104 K  |    1103 K  |
|       from large pool |      93    |     178    |     577 K  |     577 K  |
|       from small pool |     464    |     557    |     526 K  |     526 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.947033166885376
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.478669673204422
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41550976037979126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2823288142681122
28
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34782 GiB |  34775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34649 GiB |  34641 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34782 GiB |  34775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34649 GiB |  34641 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34782 GiB |  34775 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34649 GiB |  34641 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1106 K  |    1106 K  |
|       from large pool |      93    |     178    |     578 K  |     578 K  |
|       from small pool |     464    |     557    |     527 K  |     527 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1106 K  |    1106 K  |
|       from large pool |      93    |     178    |     578 K  |     578 K  |
|       from small pool |     464    |     557    |     527 K  |     527 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2913677394390106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6122833490371704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29741814732551575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45951148867607117
29
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34843 GiB |  34835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34709 GiB |  34701 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34843 GiB |  34835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34709 GiB |  34701 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34843 GiB |  34835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34709 GiB |  34701 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1108 K  |    1108 K  |
|       from large pool |      93    |     178    |     579 K  |     579 K  |
|       from small pool |     464    |     557    |     528 K  |     528 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1108 K  |    1108 K  |
|       from large pool |      93    |     178    |     579 K  |     579 K  |
|       from small pool |     464    |     557    |     528 K  |     528 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3470873236656189
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36318981647491455
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
30
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34903 GiB |  34895 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34769 GiB |  34761 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34903 GiB |  34895 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34769 GiB |  34761 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34903 GiB |  34895 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34769 GiB |  34761 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1110 K  |    1110 K  |
|       from large pool |      93    |     178    |     580 K  |     580 K  |
|       from small pool |     464    |     557    |     529 K  |     529 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1110 K  |    1110 K  |
|       from large pool |      93    |     178    |     580 K  |     580 K  |
|       from small pool |     464    |     557    |     529 K  |     529 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2315360307693481
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4951473474502563
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4098076820373535
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2728656232357025
31
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34963 GiB |  34956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34829 GiB |  34821 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34963 GiB |  34956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34829 GiB |  34821 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34963 GiB |  34956 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34829 GiB |  34821 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1112 K  |    1112 K  |
|       from large pool |      93    |     178    |     581 K  |     581 K  |
|       from small pool |     464    |     557    |     530 K  |     530 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1112 K  |    1112 K  |
|       from large pool |      93    |     178    |     581 K  |     581 K  |
|       from small pool |     464    |     557    |     530 K  |     530 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28271758556365967
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6820204257965088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32747241854667664
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6805041432380676
32
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35023 GiB |  35016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34889 GiB |  34881 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35023 GiB |  35016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34889 GiB |  34881 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35023 GiB |  35016 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34889 GiB |  34881 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1114 K  |    1114 K  |
|       from large pool |      93    |     178    |     582 K  |     582 K  |
|       from small pool |     464    |     557    |     532 K  |     531 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1114 K  |    1114 K  |
|       from large pool |      93    |     178    |     582 K  |     582 K  |
|       from small pool |     464    |     557    |     532 K  |     531 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40764039754867554
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7225446701049805
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8893114328384399
33
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35084 GiB |  35076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34949 GiB |  34941 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35084 GiB |  35076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34949 GiB |  34941 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35084 GiB |  35076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34949 GiB |  34941 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1116 K  |    1116 K  |
|       from large pool |      93    |     178    |     583 K  |     583 K  |
|       from small pool |     464    |     557    |     533 K  |     532 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1116 K  |    1116 K  |
|       from large pool |      93    |     178    |     583 K  |     583 K  |
|       from small pool |     464    |     557    |     533 K  |     532 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7829195261001587
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29536300897598267
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41791871190071106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31172215938568115
34
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35144 GiB |  35136 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35009 GiB |  35001 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35144 GiB |  35136 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35009 GiB |  35001 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35144 GiB |  35136 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35009 GiB |  35001 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1118 K  |    1118 K  |
|       from large pool |      93    |     178    |     584 K  |     584 K  |
|       from small pool |     464    |     557    |     534 K  |     533 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1118 K  |    1118 K  |
|       from large pool |      93    |     178    |     584 K  |     584 K  |
|       from small pool |     464    |     557    |     534 K  |     533 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4493716061115265
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6113709807395935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45497411489486694
35
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35204 GiB |  35197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35069 GiB |  35061 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35204 GiB |  35197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35069 GiB |  35061 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35204 GiB |  35197 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35069 GiB |  35061 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1120 K  |    1120 K  |
|       from large pool |      93    |     178    |     585 K  |     585 K  |
|       from small pool |     464    |     557    |     535 K  |     534 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1120 K  |    1120 K  |
|       from large pool |      93    |     178    |     585 K  |     585 K  |
|       from small pool |     464    |     557    |     535 K  |     534 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3454032242298126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4403054714202881
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2816068232059479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3324041962623596
36
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35264 GiB |  35257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35129 GiB |  35121 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35264 GiB |  35257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35129 GiB |  35121 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35264 GiB |  35257 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35129 GiB |  35121 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1122 K  |    1122 K  |
|       from large pool |      93    |     178    |     586 K  |     586 K  |
|       from small pool |     464    |     557    |     536 K  |     535 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1122 K  |    1122 K  |
|       from large pool |      93    |     178    |     586 K  |     586 K  |
|       from small pool |     464    |     557    |     536 K  |     535 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.711246907711029
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26826685667037964
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934325337409973
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4922246038913727
37
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35325 GiB |  35317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35189 GiB |  35181 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35325 GiB |  35317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35189 GiB |  35181 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35325 GiB |  35317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35189 GiB |  35181 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1124 K  |    1124 K  |
|       from large pool |      93    |     178    |     587 K  |     587 K  |
|       from small pool |     464    |     557    |     537 K  |     536 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1124 K  |    1124 K  |
|       from large pool |      93    |     178    |     587 K  |     587 K  |
|       from small pool |     464    |     557    |     537 K  |     536 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2767014801502228
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3281143307685852
38
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35385 GiB |  35377 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35249 GiB |  35241 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35385 GiB |  35377 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35249 GiB |  35241 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35385 GiB |  35377 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35249 GiB |  35241 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1126 K  |    1126 K  |
|       from large pool |      93    |     178    |     588 K  |     588 K  |
|       from small pool |     464    |     557    |     538 K  |     537 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1126 K  |    1126 K  |
|       from large pool |      93    |     178    |     588 K  |     588 K  |
|       from small pool |     464    |     557    |     538 K  |     537 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.952993392944336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5135407447814941
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5215725898742676
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4196229577064514
39
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35445 GiB |  35438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35309 GiB |  35302 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35445 GiB |  35438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35309 GiB |  35302 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35445 GiB |  35438 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35309 GiB |  35302 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1128 K  |    1128 K  |
|       from large pool |      93    |     178    |     589 K  |     589 K  |
|       from small pool |     464    |     557    |     539 K  |     538 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1128 K  |    1128 K  |
|       from large pool |      93    |     178    |     589 K  |     589 K  |
|       from small pool |     464    |     557    |     539 K  |     538 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2626209855079651
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4253860414028168
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39951568841934204
40
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35505 GiB |  35498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35369 GiB |  35362 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35505 GiB |  35498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35369 GiB |  35362 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35505 GiB |  35498 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35369 GiB |  35362 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1130 K  |    1130 K  |
|       from large pool |      93    |     178    |     590 K  |     590 K  |
|       from small pool |     464    |     557    |     540 K  |     539 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1130 K  |    1130 K  |
|       from large pool |      93    |     178    |     590 K  |     590 K  |
|       from small pool |     464    |     557    |     540 K  |     539 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29863911867141724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29291844367980957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35073089599609375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29881617426872253
41
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35566 GiB |  35558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35429 GiB |  35422 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35566 GiB |  35558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35429 GiB |  35422 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35565 GiB |  35558 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35429 GiB |  35422 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1132 K  |    1132 K  |
|       from large pool |      93    |     178    |     591 K  |     591 K  |
|       from small pool |     464    |     557    |     541 K  |     540 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1132 K  |    1132 K  |
|       from large pool |      93    |     178    |     591 K  |     591 K  |
|       from small pool |     464    |     557    |     541 K  |     540 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36321255564689636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44291359186172485
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.846362829208374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.039322853088379
42
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35626 GiB |  35618 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35489 GiB |  35482 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35626 GiB |  35618 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35489 GiB |  35482 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35626 GiB |  35618 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35489 GiB |  35482 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1134 K  |    1134 K  |
|       from large pool |      93    |     178    |     592 K  |     592 K  |
|       from small pool |     464    |     557    |     542 K  |     542 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1134 K  |    1134 K  |
|       from large pool |      93    |     178    |     592 K  |     592 K  |
|       from small pool |     464    |     557    |     542 K  |     542 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25906282663345337
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.698800802230835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4358466863632202
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3205110430717468
43
input size 43545648
target size 2073648
mask size 518448
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35686 GiB |  35679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35549 GiB |  35542 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35686 GiB |  35679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35549 GiB |  35542 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35686 GiB |  35679 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35549 GiB |  35542 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1136 K  |    1136 K  |
|       from large pool |      93    |     178    |     593 K  |     593 K  |
|       from small pool |     464    |     557    |     543 K  |     543 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1136 K  |    1136 K  |
|       from large pool |      93    |     178    |     593 K  |     593 K  |
|       from small pool |     464    |     557    |     543 K  |     543 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.070176601409912
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3621932864189148
44
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35746 GiB |  35739 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35609 GiB |  35602 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35746 GiB |  35739 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35609 GiB |  35602 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35746 GiB |  35739 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35609 GiB |  35602 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1138 K  |    1138 K  |
|       from large pool |      93    |     178    |     594 K  |     594 K  |
|       from small pool |     464    |     557    |     544 K  |     544 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1138 K  |    1138 K  |
|       from large pool |      93    |     178    |     594 K  |     594 K  |
|       from small pool |     464    |     557    |     544 K  |     544 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45830103754997253
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 4 360 done at Thu Nov 14 11:37:43 CET 2024
UNet6 with 1 10 0.0001 8 360 start at Thu Nov 14 11:37:43 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 8
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.819812536239624
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9529114365577698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.3863213062286377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.270076036453247
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6869325637817383
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46848130226135254
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5421428680419922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5739983320236206
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    468 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    468 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 125289 MiB | 121480 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 124821 MiB | 121019 MiB |
|       from small pool |      7 MiB |     24 MiB |    467 MiB |    460 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    4262    |    3941    |
|       from large pool |      47    |     102    |    1968    |    1921    |
|       from small pool |     274    |     352    |    2294    |    2020    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    4262    |    3941    |
|       from large pool |      47    |     102    |    1968    |    1921    |
|       from small pool |     274    |     352    |    2294    |    2020    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2186293601989746
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5850042104721069
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7131848931312561
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5979920029640198
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.130446195602417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47118911147117615
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 248664 MiB | 244855 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 248664 MiB | 244855 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 248664 MiB | 244854 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 247741 MiB | 243939 MiB |
|       from small pool |      7 MiB |     24 MiB |    922 MiB |    915 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |    8280    |    7959    |
|       from large pool |      47    |     102    |    3908    |    3861    |
|       from small pool |     274    |     352    |    4372    |    4098    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |    8280    |    7959    |
|       from large pool |      47    |     102    |    3908    |    3861    |
|       from small pool |     274    |     352    |    4372    |    4098    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5719398856163025
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.110304594039917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48696455359458923
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7697487473487854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5989560484886169
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0078785419464111
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47610917687416077
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6136468648910522
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370673 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370673 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 372065 MiB | 368256 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 370672 MiB | 366871 MiB |
|       from small pool |      7 MiB |     24 MiB |   1392 MiB |   1385 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   12344    |   12023    |
|       from large pool |      47    |     102    |    5854    |    5807    |
|       from small pool |     274    |     352    |    6490    |    6216    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   12344    |   12023    |
|       from large pool |      47    |     102    |    5854    |    5807    |
|       from small pool |     274    |     352    |    6490    |    6216    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4699391722679138
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8132690191268921
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3295847177505493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6827605366706848
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4973190426826477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.585635781288147
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.51414155960083
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1869 MiB |   1862 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1869 MiB |   1862 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 495483 MiB | 491674 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 493614 MiB | 489812 MiB |
|       from small pool |      7 MiB |     24 MiB |   1868 MiB |   1861 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   16385    |   16064    |
|       from large pool |      47    |     102    |    7801    |    7754    |
|       from small pool |     274    |     352    |    8584    |    8310    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   16385    |   16064    |
|       from large pool |      47    |     102    |    7801    |    7754    |
|       from small pool |     274    |     352    |    8584    |    8310    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45469796657562256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.624519407749176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9587867259979248
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6278560161590576
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49461838603019714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7044584155082703
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 618860 MiB | 615051 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612735 MiB |
|       from small pool |      7 MiB |     24 MiB |   2324 MiB |   2316 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 618860 MiB | 615051 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612735 MiB |
|       from small pool |      7 MiB |     24 MiB |   2324 MiB |   2316 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 618859 MiB | 615050 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 616536 MiB | 612734 MiB |
|       from small pool |      7 MiB |     24 MiB |   2323 MiB |   2315 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   20403    |   20082    |
|       from large pool |      47    |     102    |    9745    |    9698    |
|       from small pool |     274    |     352    |   10658    |   10384    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   20403    |   20082    |
|       from large pool |      47    |     102    |    9745    |    9698    |
|       from small pool |     274    |     352    |   10658    |   10384    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5164517164230347
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4544129967689514
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.86475670337677
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47753116488456726
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5423285961151123
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB | 742236 MiB | 738427 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2777 MiB |   2770 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB | 742236 MiB | 738427 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2777 MiB |   2770 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB | 742235 MiB | 738426 MiB |
|       from large pool |   3801 MiB |   5814 MiB | 739458 MiB | 735657 MiB |
|       from small pool |      7 MiB |     24 MiB |   2776 MiB |   2769 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   24398    |   24077    |
|       from large pool |      47    |     102    |   11685    |   11638    |
|       from small pool |     274    |     352    |   12713    |   12439    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   24398    |   24077    |
|       from large pool |      47    |     102    |   11685    |   11638    |
|       from small pool |     274    |     352    |   12713    |   12439    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0763672590255737
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.039473056793213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5298306345939636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7522132992744446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5095365643501282
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48460251092910767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8418570160865784
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    845 GiB |    841 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    842 GiB |    838 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   28439    |   28118    |
|       from large pool |      47    |     102    |   13633    |   13586    |
|       from small pool |     274    |     352    |   14806    |   14532    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   28439    |   28118    |
|       from large pool |      47    |     102    |   13633    |   13586    |
|       from small pool |     274    |     352    |   14806    |   14532    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4620964825153351
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47385135293006897
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.827709436416626
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2050328254699707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.6952083110809326
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.031891942024231
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2293715476989746
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |    965 GiB |    962 GiB |
|       from large pool |   3801 MiB |   5814 MiB |    962 GiB |    958 GiB |
|       from small pool |      7 MiB |     24 MiB |      3 GiB |      3 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   32480    |   32159    |
|       from large pool |      47    |     102    |   15572    |   15525    |
|       from small pool |     274    |     352    |   16908    |   16634    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   32480    |   32159    |
|       from large pool |      47    |     102    |   15572    |   15525    |
|       from small pool |     274    |     352    |   16908    |   16634    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49924877285957336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0482702255249023
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5716233253479004
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.473301887512207
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4562150239944458
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1086 GiB |   1082 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1082 GiB |   1078 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   36475    |   36154    |
|       from large pool |      47    |     102    |   17511    |   17464    |
|       from small pool |     274    |     352    |   18964    |   18690    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   36475    |   36154    |
|       from large pool |      47    |     102    |   17511    |   17464    |
|       from small pool |     274    |     352    |   18964    |   18690    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7648544311523438
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2041324377059937
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47707146406173706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.630420446395874
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.144110083580017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8894302248954773
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44735756516456604
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1206 GiB |   1203 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1202 GiB |   1198 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   40516    |   40195    |
|       from large pool |      47    |     102    |   19459    |   19412    |
|       from small pool |     274    |     352    |   21057    |   20783    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   40516    |   40195    |
|       from large pool |      47    |     102    |   19459    |   19412    |
|       from small pool |     274    |     352    |   21057    |   20783    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5024728775024414
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5545372366905212
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7979448437690735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5833857655525208
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5818025469779968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5606418251991272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5785847902297974
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1327 GiB |   1323 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1322 GiB |   1318 GiB |
|       from small pool |      7 MiB |     24 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   44557    |   44236    |
|       from large pool |      47    |     102    |   21406    |   21359    |
|       from small pool |     274    |     352    |   23151    |   22877    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   44557    |   44236    |
|       from large pool |      47    |     102    |   21406    |   21359    |
|       from small pool |     274    |     352    |   23151    |   22877    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1468136310577393
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.450875163078308
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6367223858833313
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5154714584350586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5152022838592529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.528084397315979
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9421567320823669
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6088292002677917
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1447 GiB |   1444 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1442 GiB |   1438 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   48621    |   48300    |
|       from large pool |      47    |     102    |   23356    |   23309    |
|       from small pool |     274    |     352    |   25265    |   24991    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   48621    |   48300    |
|       from large pool |      47    |     102    |   23356    |   23309    |
|       from small pool |     274    |     352    |   25265    |   24991    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6201375126838684
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6374879479408264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5473155975341797
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5828478932380676
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6870982050895691
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5076937675476074
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.2537639141082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6441835165023804
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1568 GiB |   1564 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1562 GiB |   1558 GiB |
|       from small pool |      7 MiB |     24 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   52685    |   52364    |
|       from large pool |      47    |     102    |   25307    |   25260    |
|       from small pool |     274    |     352    |   27378    |   27104    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   52685    |   52364    |
|       from large pool |      47    |     102    |   25307    |   25260    |
|       from small pool |     274    |     352    |   27378    |   27104    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4633548855781555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6354823112487793
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5546389818191528
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.452296257019043
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7913306355476379
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6001733541488647
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6769973039627075
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1688 GiB |   1685 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1682 GiB |   1678 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   56726    |   56405    |
|       from large pool |      47    |     102    |   27250    |   27203    |
|       from small pool |     274    |     352    |   29476    |   29202    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   56726    |   56405    |
|       from large pool |      47    |     102    |   27250    |   27203    |
|       from small pool |     274    |     352    |   29476    |   29202    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4553399682044983
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8695197105407715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4755610227584839
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6617066860198975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5238131284713745
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5245546698570251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1809 GiB |   1805 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1802 GiB |   1798 GiB |
|       from small pool |      7 MiB |     24 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   60744    |   60423    |
|       from large pool |      47    |     102    |   29194    |   29147    |
|       from small pool |     274    |     352    |   31550    |   31276    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   60744    |   60423    |
|       from large pool |      47    |     102    |   29194    |   29147    |
|       from small pool |     274    |     352    |   31550    |   31276    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5921008586883545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9015032052993774
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.9101366996765137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6102474927902222
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46769586205482483
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5767532587051392
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5057856440544128
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9696930050849915
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   1929 GiB |   1926 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   1922 GiB |   1918 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   64808    |   64487    |
|       from large pool |      47    |     102    |   31141    |   31094    |
|       from small pool |     274    |     352    |   33667    |   33393    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   64808    |   64487    |
|       from large pool |      47    |     102    |   31141    |   31094    |
|       from small pool |     274    |     352    |   33667    |   33393    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.587297797203064
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0258359909057617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5137578248977661
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.074904203414917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4704446494579315
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8295745253562927
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5119169354438782
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2050 GiB |   2046 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2042 GiB |   2039 GiB |
|       from small pool |      7 MiB |     24 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   68849    |   68528    |
|       from large pool |      47    |     102    |   33084    |   33037    |
|       from small pool |     274    |     352    |   35765    |   35491    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   68849    |   68528    |
|       from large pool |      47    |     102    |   33084    |   33037    |
|       from small pool |     274    |     352    |   35765    |   35491    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7610528469085693
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9171606302261353
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6281032562255859
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5952099561691284
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6960201859474182
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6789958477020264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4713931977748871
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2170 GiB |   2167 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2162 GiB |   2159 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   72890    |   72569    |
|       from large pool |      47    |     102    |   35027    |   34980    |
|       from small pool |     274    |     352    |   37863    |   37589    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   72890    |   72569    |
|       from large pool |      47    |     102    |   35027    |   34980    |
|       from small pool |     274    |     352    |   37863    |   37589    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4038227796554565
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.578901469707489
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48654380440711975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7137617468833923
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.586050271987915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4967315196990967
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2291 GiB |   2287 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2282 GiB |   2279 GiB |
|       from small pool |      7 MiB |     24 MiB |      8 GiB |      8 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   76908    |   76587    |
|       from large pool |      47    |     102    |   36964    |   36917    |
|       from small pool |     274    |     352    |   39944    |   39670    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   76908    |   76587    |
|       from large pool |      47    |     102    |   36964    |   36917    |
|       from small pool |     274    |     352    |   39944    |   39670    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.397573947906494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7835416197776794
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.8879265785217285
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5795229077339172
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46186575293540955
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6076156497001648
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6935876607894897
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2411 GiB |   2408 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2402 GiB |   2399 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   80949    |   80628    |
|       from large pool |      47    |     102    |   38912    |   38865    |
|       from small pool |     274    |     352    |   42037    |   41763    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   80949    |   80628    |
|       from large pool |      47    |     102    |   38912    |   38865    |
|       from small pool |     274    |     352    |   42037    |   41763    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5685961842536926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6882216334342957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5235651135444641
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.561565101146698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5332809686660767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7282124757766724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.192653775215149
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4065489768981934
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2532 GiB |   2528 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2522 GiB |   2519 GiB |
|       from small pool |      7 MiB |     24 MiB |      9 GiB |      9 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   85013    |   84692    |
|       from large pool |      47    |     102    |   40858    |   40811    |
|       from small pool |     274    |     352    |   44155    |   43881    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   85013    |   84692    |
|       from large pool |      47    |     102    |   40858    |   40811    |
|       from small pool |     274    |     352    |   44155    |   43881    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.482292503118515
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0171582698822021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.007269859313965
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48738574981689453
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.58840799331665
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6192532181739807
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3809 MiB |   5830 MiB |   2652 GiB |   2649 GiB |
|       from large pool |   3801 MiB |   5814 MiB |   2642 GiB |   2639 GiB |
|       from small pool |      7 MiB |     24 MiB |     10 GiB |     10 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6148 MiB |   6148 MiB |   6148 MiB |      0 B   |
|       from large pool |   6120 MiB |   6120 MiB |   6120 MiB |      0 B   |
|       from small pool |     28 MiB |     28 MiB |     28 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     321    |     452    |   89031    |   88710    |
|       from large pool |      47    |     102    |   42802    |   42755    |
|       from small pool |     274    |     352    |   46229    |   45955    |
|---------------------------------------------------------------------------|
| Active allocs         |     321    |     452    |   89031    |   88710    |
|       from large pool |      47    |     102    |   42802    |   42755    |
|       from small pool |     274    |     352    |   46229    |   45955    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7556139826774597
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9493 MiB |   3689 GiB |   3684 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3675 GiB |   3669 GiB |
|       from small pool |      9 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9493 MiB |   3689 GiB |   3684 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3675 GiB |   3669 GiB |
|       from small pool |      9 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9493 MiB |   3689 GiB |   3684 GiB |
|       from large pool |   5687 MiB |   9478 MiB |   3675 GiB |   3669 GiB |
|       from small pool |      8 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9542 MiB |   9542 MiB |   3728 MiB |
|       from large pool |   5800 MiB |   9500 MiB |   9500 MiB |   3700 MiB |
|       from small pool |     14 MiB |     42 MiB |     42 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     672    |  118258    |  117823    |
|       from large pool |      69    |     178    |   61433    |   61364    |
|       from small pool |     366    |     557    |   56825    |   56459    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     672    |  118258    |  117823    |
|       from large pool |      69    |     178    |   61433    |   61364    |
|       from small pool |     366    |     557    |   56825    |   56459    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8054918646812439
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8987407088279724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.2919647693634033
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7529160976409912
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.619989275932312
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40582361817359924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41985389590263367
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4629015922546387
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3810 GiB |   3802 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3795 GiB |   3788 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3810 GiB |   3802 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3795 GiB |   3788 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3810 GiB |   3802 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3795 GiB |   3788 GiB |
|       from small pool |     13 MiB |     36 MiB |     14 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  122322    |  121765    |
|       from large pool |      93    |     178    |   63378    |   63285    |
|       from small pool |     464    |     557    |   58944    |   58480    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  122322    |  121765    |
|       from large pool |      93    |     178    |   63378    |   63285    |
|       from small pool |     464    |     557    |   58944    |   58480    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8853329420089722
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5445839762687683
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.674015462398529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4879615008831024
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0255072116851807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42342409491539
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   3930 GiB |   3923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3915 GiB |   3908 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   3930 GiB |   3923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3915 GiB |   3908 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   3930 GiB |   3923 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   3915 GiB |   3908 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  126340    |  125783    |
|       from large pool |      93    |     178    |   65318    |   65225    |
|       from small pool |     464    |     557    |   61022    |   60558    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  126340    |  125783    |
|       from large pool |      93    |     178    |   65318    |   65225    |
|       from small pool |     464    |     557    |   61022    |   60558    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4279136657714844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7758976221084595
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3747066557407379
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6917065382003784
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4910371005535126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9175930619239807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41859519481658936
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5455162525177002
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4051 GiB |   4043 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4035 GiB |   4028 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4051 GiB |   4043 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4035 GiB |   4028 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4051 GiB |   4043 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4035 GiB |   4028 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  130404    |  129847    |
|       from large pool |      93    |     178    |   67264    |   67171    |
|       from small pool |     464    |     557    |   63140    |   62676    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  130404    |  129847    |
|       from large pool |      93    |     178    |   67264    |   67171    |
|       from small pool |     464    |     557    |   63140    |   62676    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4035603404045105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7738136053085327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.258652925491333
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6637643575668335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4387687146663666
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5114082098007202
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4561054706573486
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4171 GiB |   4164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4155 GiB |   4148 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4171 GiB |   4164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4155 GiB |   4148 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4171 GiB |   4164 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4155 GiB |   4148 GiB |
|       from small pool |     13 MiB |     36 MiB |     15 GiB |     15 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  134445    |  133888    |
|       from large pool |      93    |     178    |   69211    |   69118    |
|       from small pool |     464    |     557    |   65234    |   64770    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  134445    |  133888    |
|       from large pool |      93    |     178    |   69211    |   69118    |
|       from small pool |     464    |     557    |   65234    |   64770    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3829658627510071
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.524093747138977
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9038376212120056
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5851014256477356
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4196215569972992
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6253869533538818
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4292 GiB |   4284 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4275 GiB |   4268 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4292 GiB |   4284 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4275 GiB |   4268 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4292 GiB |   4284 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4275 GiB |   4268 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  138463    |  137906    |
|       from large pool |      93    |     178    |   71155    |   71062    |
|       from small pool |     464    |     557    |   67308    |   66844    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  138463    |  137906    |
|       from large pool |      93    |     178    |   71155    |   71062    |
|       from small pool |     464    |     557    |   67308    |   66844    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46743452548980713
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3872469365596771
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8338868618011475
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41059255599975586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.443751335144043
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4412 GiB |   4405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4395 GiB |   4388 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4412 GiB |   4405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4395 GiB |   4388 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4412 GiB |   4405 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4395 GiB |   4388 GiB |
|       from small pool |     13 MiB |     36 MiB |     16 GiB |     16 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  142458    |  141901    |
|       from large pool |      93    |     178    |   73095    |   73002    |
|       from small pool |     464    |     557    |   69363    |   68899    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  142458    |  141901    |
|       from large pool |      93    |     178    |   73095    |   73002    |
|       from small pool |     464    |     557    |   69363    |   68899    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0170003175735474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.995087206363678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40507644414901733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6749089360237122
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4420895576477051
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43542855978012085
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7903597950935364
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4533 GiB |   4525 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4515 GiB |   4508 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4533 GiB |   4525 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4515 GiB |   4508 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4533 GiB |   4525 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4515 GiB |   4508 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  146499    |  145942    |
|       from large pool |      93    |     178    |   75043    |   74950    |
|       from small pool |     464    |     557    |   71456    |   70992    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  146499    |  145942    |
|       from large pool |      93    |     178    |   75043    |   74950    |
|       from small pool |     464    |     557    |   71456    |   70992    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38722386956214905
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3567829728126526
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8009729385375977
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1887037754058838
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5324246883392334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9487202763557434
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1619105339050293
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4653 GiB |   4646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4635 GiB |   4628 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4653 GiB |   4646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4635 GiB |   4628 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4653 GiB |   4646 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4635 GiB |   4628 GiB |
|       from small pool |     13 MiB |     36 MiB |     17 GiB |     17 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  150540    |  149983    |
|       from large pool |      93    |     178    |   76982    |   76889    |
|       from small pool |     464    |     557    |   73558    |   73094    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  150540    |  149983    |
|       from large pool |      93    |     178    |   76982    |   76889    |
|       from small pool |     464    |     557    |   73558    |   73094    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4423845112323761
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9855327606201172
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4008445143699646
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.32944393157959
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3845133781433105
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4774 GiB |   4766 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4755 GiB |   4748 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4774 GiB |   4766 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4755 GiB |   4748 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4774 GiB |   4766 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4755 GiB |   4748 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  154535    |  153978    |
|       from large pool |      93    |     178    |   78921    |   78828    |
|       from small pool |     464    |     557    |   75614    |   75150    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  154535    |  153978    |
|       from large pool |      93    |     178    |   78921    |   78828    |
|       from small pool |     464    |     557    |   75614    |   75150    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7258349061012268
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1670548915863037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4191601872444153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5944328904151917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1055978536605835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8371577262878418
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39751115441322327
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   4894 GiB |   4887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4875 GiB |   4868 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   4894 GiB |   4887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4875 GiB |   4868 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   4894 GiB |   4887 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4875 GiB |   4868 GiB |
|       from small pool |     13 MiB |     36 MiB |     18 GiB |     18 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  158576    |  158019    |
|       from large pool |      93    |     178    |   80869    |   80776    |
|       from small pool |     464    |     557    |   77707    |   77243    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  158576    |  158019    |
|       from large pool |      93    |     178    |   80869    |   80776    |
|       from small pool |     464    |     557    |   77707    |   77243    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35939866304397583
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48182982206344604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7070066332817078
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5354675054550171
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49496012926101685
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4740426540374756
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.530408501625061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5015 GiB |   5007 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4996 GiB |   4988 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5015 GiB |   5007 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4996 GiB |   4988 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5015 GiB |   5007 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   4996 GiB |   4988 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  162617    |  162060    |
|       from large pool |      93    |     178    |   82816    |   82723    |
|       from small pool |     464    |     557    |   79801    |   79337    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  162617    |  162060    |
|       from large pool |      93    |     178    |   82816    |   82723    |
|       from small pool |     464    |     557    |   79801    |   79337    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0800422430038452
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3574137687683105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46985873579978943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4406193196773529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.446282297372818
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4453347325325012
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8741986751556396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5293667912483215
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5135 GiB |   5128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5116 GiB |   5108 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5135 GiB |   5128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5116 GiB |   5108 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5135 GiB |   5128 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5116 GiB |   5108 GiB |
|       from small pool |     13 MiB |     36 MiB |     19 GiB |     19 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  166681    |  166124    |
|       from large pool |      93    |     178    |   84766    |   84673    |
|       from small pool |     464    |     557    |   81915    |   81451    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  166681    |  166124    |
|       from large pool |      93    |     178    |   84766    |   84673    |
|       from small pool |     464    |     557    |   81915    |   81451    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5353571176528931
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5791845321655273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5059974789619446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4314745366573334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6558837294578552
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42855778336524963
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.206753730773926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6051461696624756
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5256 GiB |   5248 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5236 GiB |   5228 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5256 GiB |   5248 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5236 GiB |   5228 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5256 GiB |   5248 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5236 GiB |   5228 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  170745    |  170188    |
|       from large pool |      93    |     178    |   86717    |   86624    |
|       from small pool |     464    |     557    |   84028    |   83564    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  170745    |  170188    |
|       from large pool |      93    |     178    |   86717    |   86624    |
|       from small pool |     464    |     557    |   84028    |   83564    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3908587694168091
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5420536398887634
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3993499279022217
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.305393695831299
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7225639224052429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.537074863910675
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44736871123313904
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5376 GiB |   5369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5356 GiB |   5348 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5376 GiB |   5369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5356 GiB |   5348 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5376 GiB |   5369 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5356 GiB |   5348 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  174786    |  174229    |
|       from large pool |      93    |     178    |   88660    |   88567    |
|       from small pool |     464    |     557    |   86126    |   85662    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  174786    |  174229    |
|       from large pool |      93    |     178    |   88660    |   88567    |
|       from small pool |     464    |     557    |   86126    |   85662    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38459938764572144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7890965938568115
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.414558082818985
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.603987991809845
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46700191497802734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4694973826408386
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5497 GiB |   5489 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5476 GiB |   5468 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5497 GiB |   5489 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5476 GiB |   5468 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5497 GiB |   5489 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5476 GiB |   5468 GiB |
|       from small pool |     13 MiB |     36 MiB |     20 GiB |     20 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  178804    |  178247    |
|       from large pool |      93    |     178    |   90604    |   90511    |
|       from small pool |     464    |     557    |   88200    |   87736    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  178804    |  178247    |
|       from large pool |      93    |     178    |   90604    |   90511    |
|       from small pool |     464    |     557    |   88200    |   87736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5276029109954834
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.850875973701477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.771341323852539
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.464836061000824
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3977920413017273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2948168516159058
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44135576486587524
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9448678493499756
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5617 GiB |   5610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5596 GiB |   5588 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5617 GiB |   5610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5596 GiB |   5588 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5617 GiB |   5610 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5596 GiB |   5588 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  182868    |  182311    |
|       from large pool |      93    |     178    |   92551    |   92458    |
|       from small pool |     464    |     557    |   90317    |   89853    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  182868    |  182311    |
|       from large pool |      93    |     178    |   92551    |   92458    |
|       from small pool |     464    |     557    |   90317    |   89853    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5373835563659668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9716783761978149
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4940139055252075
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.019716739654541
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4043095111846924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6526936292648315
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4361291527748108
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5738 GiB |   5730 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5716 GiB |   5708 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5738 GiB |   5730 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5716 GiB |   5708 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5738 GiB |   5730 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5716 GiB |   5708 GiB |
|       from small pool |     13 MiB |     36 MiB |     21 GiB |     21 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  186909    |  186352    |
|       from large pool |      93    |     178    |   94494    |   94401    |
|       from small pool |     464    |     557    |   92415    |   91951    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  186909    |  186352    |
|       from large pool |      93    |     178    |   94494    |   94401    |
|       from small pool |     464    |     557    |   92415    |   91951    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6763297915458679
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.846520721912384
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5822674632072449
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5073311924934387
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6249715685844421
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4491252601146698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41228458285331726
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5858 GiB |   5851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5836 GiB |   5828 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5858 GiB |   5851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5836 GiB |   5828 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5858 GiB |   5851 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5836 GiB |   5828 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  190950    |  190393    |
|       from large pool |      93    |     178    |   96437    |   96344    |
|       from small pool |     464    |     557    |   94513    |   94049    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  190950    |  190393    |
|       from large pool |      93    |     178    |   96437    |   96344    |
|       from small pool |     464    |     557    |   94513    |   94049    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9837915897369385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43238136172294617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3756480813026428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6602489352226257
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43490418791770935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4389401078224182
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   5979 GiB |   5971 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5956 GiB |   5949 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   5979 GiB |   5971 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5956 GiB |   5949 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   5979 GiB |   5971 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   5956 GiB |   5949 GiB |
|       from small pool |     13 MiB |     36 MiB |     22 GiB |     22 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  194968    |  194411    |
|       from large pool |      93    |     178    |   98374    |   98281    |
|       from small pool |     464    |     557    |   96594    |   96130    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  194968    |  194411    |
|       from large pool |      93    |     178    |   98374    |   98281    |
|       from small pool |     464    |     557    |   96594    |   96130    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.278047800064087
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7019065022468567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.877516031265259
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5246642231941223
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3866238594055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5449886918067932
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6539317965507507
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6099 GiB |   6092 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6076 GiB |   6069 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6099 GiB |   6092 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6076 GiB |   6069 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6099 GiB |   6092 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6076 GiB |   6069 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  199009    |  198452    |
|       from large pool |      93    |     178    |  100322    |  100229    |
|       from small pool |     464    |     557    |   98687    |   98223    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  199009    |  198452    |
|       from large pool |      93    |     178    |  100322    |  100229    |
|       from small pool |     464    |     557    |   98687    |   98223    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4264691472053528
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45463478565216064
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45638638734817505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4559684693813324
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47985419631004333
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6698529720306396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1541709899902344
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3551671504974365
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6220 GiB |   6212 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6196 GiB |   6189 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6220 GiB |   6212 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6196 GiB |   6189 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6220 GiB |   6212 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6196 GiB |   6189 GiB |
|       from small pool |     13 MiB |     36 MiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  203073    |  202516    |
|       from large pool |      93    |     178    |  102268    |  102175    |
|       from small pool |     464    |     557    |  100805    |  100341    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  203073    |  202516    |
|       from large pool |      93    |     178    |  102268    |  102175    |
|       from small pool |     464    |     557    |  100805    |  100341    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42673611640930176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.969355583190918
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.86638605594635
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41490432620048523
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.436746597290039
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5215848684310913
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   6340 GiB |   6333 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6316 GiB |   6309 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   6340 GiB |   6333 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6316 GiB |   6309 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   6340 GiB |   6333 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   6316 GiB |   6309 GiB |
|       from small pool |     13 MiB |     36 MiB |     24 GiB |     24 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9954 MiB |  13682 MiB |   3728 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  13620 MiB |   3700 MiB |
|       from small pool |     34 MiB |     42 MiB |     62 MiB |     28 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  207091    |  206534    |
|       from large pool |      93    |     178    |  104212    |  104119    |
|       from small pool |     464    |     557    |  102879    |  102415    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  207091    |  206534    |
|       from large pool |      93    |     178    |  104212    |  104119    |
|       from small pool |     464    |     557    |  102879    |  102415    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6882298588752747
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |   7373 GiB |   7368 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7345 GiB |   7339 GiB |
|       from small pool |      9 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |   7373 GiB |   7368 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7345 GiB |   7339 GiB |
|       from small pool |      9 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |   7373 GiB |   7368 GiB |
|       from large pool |   5687 MiB |   9606 MiB |   7345 GiB |   7339 GiB |
|       from small pool |      8 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  13690 MiB |   7876 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  13620 MiB |   7820 MiB |
|       from small pool |     14 MiB |     42 MiB |     70 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  236082    |  235647    |
|       from large pool |      69    |     178    |  122797    |  122728    |
|       from small pool |     366    |     557    |  113285    |  112919    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  236082    |  235647    |
|       from large pool |      69    |     178    |  122797    |  122728    |
|       from small pool |     366    |     557    |  113285    |  112919    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8051015734672546
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8529430627822876
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.214339017868042
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5116938352584839
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5819724798202515
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4383721649646759
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41861456632614136
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3880025148391724
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7494 GiB |   7486 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7465 GiB |   7458 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7494 GiB |   7486 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7465 GiB |   7458 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7494 GiB |   7486 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7465 GiB |   7458 GiB |
|       from small pool |     13 MiB |     36 MiB |     28 GiB |     28 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  240146    |  239589    |
|       from large pool |      93    |     178    |  124742    |  124649    |
|       from small pool |     464    |     557    |  115404    |  114940    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  240146    |  239589    |
|       from large pool |      93    |     178    |  124742    |  124649    |
|       from small pool |     464    |     557    |  115404    |  114940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7734600305557251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5285988450050354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6681726574897766
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4541483521461487
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9507399797439575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39212068915367126
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7614 GiB |   7607 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7585 GiB |   7578 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7614 GiB |   7607 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7585 GiB |   7578 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7614 GiB |   7607 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7585 GiB |   7578 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  244164    |  243607    |
|       from large pool |      93    |     178    |  126682    |  126589    |
|       from small pool |     464    |     557    |  117482    |  117018    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  244164    |  243607    |
|       from large pool |      93    |     178    |  126682    |  126589    |
|       from small pool |     464    |     557    |  117482    |  117018    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3957740068435669
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7045068740844727
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3592888116836548
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.640126645565033
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45678287744522095
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8674015998840332
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3970751464366913
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5010831356048584
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7735 GiB |   7727 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7705 GiB |   7698 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7735 GiB |   7727 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7705 GiB |   7698 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7735 GiB |   7727 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7705 GiB |   7698 GiB |
|       from small pool |     13 MiB |     36 MiB |     29 GiB |     29 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  248228    |  247671    |
|       from large pool |      93    |     178    |  128628    |  128535    |
|       from small pool |     464    |     557    |  119600    |  119136    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  248228    |  247671    |
|       from large pool |      93    |     178    |  128628    |  128535    |
|       from small pool |     464    |     557    |  119600    |  119136    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37873467803001404
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7549389600753784
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.209031105041504
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6678506731987
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41784077882766724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4937847852706909
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4121454954147339
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7855 GiB |   7848 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7825 GiB |   7818 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7855 GiB |   7848 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7825 GiB |   7818 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7855 GiB |   7848 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7825 GiB |   7818 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  252269    |  251712    |
|       from large pool |      93    |     178    |  130575    |  130482    |
|       from small pool |     464    |     557    |  121694    |  121230    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  252269    |  251712    |
|       from large pool |      93    |     178    |  130575    |  130482    |
|       from small pool |     464    |     557    |  121694    |  121230    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35888829827308655
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4921519160270691
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8699957728385925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5450640916824341
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3905563950538635
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5765966773033142
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   7976 GiB |   7968 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7945 GiB |   7938 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   7976 GiB |   7968 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7945 GiB |   7938 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   7976 GiB |   7968 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   7945 GiB |   7938 GiB |
|       from small pool |     13 MiB |     36 MiB |     30 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  256287    |  255730    |
|       from large pool |      93    |     178    |  132519    |  132426    |
|       from small pool |     464    |     557    |  123768    |  123304    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  256287    |  255730    |
|       from large pool |      93    |     178    |  132519    |  132426    |
|       from small pool |     464    |     557    |  123768    |  123304    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43139874935150146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3643650412559509
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7877963781356812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3885669708251953
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.3744027614593506
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8096 GiB |   8089 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8065 GiB |   8058 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8096 GiB |   8089 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8065 GiB |   8058 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8096 GiB |   8089 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8065 GiB |   8058 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     30 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  260282    |  259725    |
|       from large pool |      93    |     178    |  134459    |  134366    |
|       from small pool |     464    |     557    |  125823    |  125359    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  260282    |  259725    |
|       from large pool |      93    |     178    |  134459    |  134366    |
|       from small pool |     464    |     557    |  125823    |  125359    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9635235071182251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9398651123046875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3759452998638153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6498486995697021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42940425872802734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4148862063884735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7516554594039917
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8217 GiB |   8209 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8185 GiB |   8178 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8217 GiB |   8209 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8185 GiB |   8178 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8217 GiB |   8209 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8185 GiB |   8178 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  264323    |  263766    |
|       from large pool |      93    |     178    |  136407    |  136314    |
|       from small pool |     464    |     557    |  127916    |  127452    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  264323    |  263766    |
|       from large pool |      93    |     178    |  136407    |  136314    |
|       from small pool |     464    |     557    |  127916    |  127452    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35976043343544006
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34368252754211426
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7625540494918823
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1395182609558105
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.423069477081299
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9135857224464417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1172702312469482
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8337 GiB |   8330 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8305 GiB |   8298 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8337 GiB |   8330 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8305 GiB |   8298 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8337 GiB |   8330 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8305 GiB |   8298 GiB |
|       from small pool |     13 MiB |     36 MiB |     31 GiB |     31 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  268364    |  267807    |
|       from large pool |      93    |     178    |  138346    |  138253    |
|       from small pool |     464    |     557    |  130018    |  129554    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  268364    |  267807    |
|       from large pool |      93    |     178    |  138346    |  138253    |
|       from small pool |     464    |     557    |  130018    |  129554    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4248979389667511
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9466566443443298
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4133960008621216
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.23195743560791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3307774066925049
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8458 GiB |   8450 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8425 GiB |   8418 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8458 GiB |   8450 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8425 GiB |   8418 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8458 GiB |   8450 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8425 GiB |   8418 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  272359    |  271802    |
|       from large pool |      93    |     178    |  140285    |  140192    |
|       from small pool |     464    |     557    |  132074    |  131610    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  272359    |  271802    |
|       from large pool |      93    |     178    |  140285    |  140192    |
|       from small pool |     464    |     557    |  132074    |  131610    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7032762765884399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1340081691741943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.390132337808609
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5579783916473389
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0716018676757812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.802668571472168
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38565701246261597
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8578 GiB |   8571 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8545 GiB |   8538 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8578 GiB |   8571 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8545 GiB |   8538 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8578 GiB |   8571 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8545 GiB |   8538 GiB |
|       from small pool |     13 MiB |     36 MiB |     32 GiB |     32 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  276400    |  275843    |
|       from large pool |      93    |     178    |  142233    |  142140    |
|       from small pool |     464    |     557    |  134167    |  133703    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  276400    |  275843    |
|       from large pool |      93    |     178    |  142233    |  142140    |
|       from small pool |     464    |     557    |  134167    |  133703    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32250872254371643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47355711460113525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.661649763584137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5043798685073853
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4497036635875702
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.438198983669281
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5030548572540283
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8699 GiB |   8691 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8665 GiB |   8658 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8699 GiB |   8691 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8665 GiB |   8658 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8699 GiB |   8691 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8665 GiB |   8658 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  280441    |  279884    |
|       from large pool |      93    |     178    |  144180    |  144087    |
|       from small pool |     464    |     557    |  136261    |  135797    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  280441    |  279884    |
|       from large pool |      93    |     178    |  144180    |  144087    |
|       from small pool |     464    |     557    |  136261    |  135797    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0335768461227417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2954051494598389
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44945961236953735
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41032615303993225
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44713613390922546
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4125525653362274
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8212732076644897
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5073781609535217
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8819 GiB |   8812 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8786 GiB |   8778 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8819 GiB |   8812 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8786 GiB |   8778 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8819 GiB |   8812 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8786 GiB |   8778 GiB |
|       from small pool |     13 MiB |     36 MiB |     33 GiB |     33 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  284505    |  283948    |
|       from large pool |      93    |     178    |  146130    |  146037    |
|       from small pool |     464    |     557    |  138375    |  137911    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  284505    |  283948    |
|       from large pool |      93    |     178    |  146130    |  146037    |
|       from small pool |     464    |     557    |  138375    |  137911    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5154852271080017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5469192266464233
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4909832775592804
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3931466341018677
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.621256947517395
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39793649315834045
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1539275646209717
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5704979300498962
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   8940 GiB |   8932 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8906 GiB |   8898 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   8940 GiB |   8932 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8906 GiB |   8898 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   8940 GiB |   8932 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   8906 GiB |   8898 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  288569    |  288012    |
|       from large pool |      93    |     178    |  148081    |  147988    |
|       from small pool |     464    |     557    |  140488    |  140024    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  288569    |  288012    |
|       from large pool |      93    |     178    |  148081    |  147988    |
|       from small pool |     464    |     557    |  140488    |  140024    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3635222911834717
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.516581118106842
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.403873085975647
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.208215236663818
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6724585890769958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5222636461257935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4144033193588257
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9060 GiB |   9053 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9026 GiB |   9018 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9060 GiB |   9053 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9026 GiB |   9018 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9060 GiB |   9053 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9026 GiB |   9018 GiB |
|       from small pool |     13 MiB |     36 MiB |     34 GiB |     34 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  292610    |  292053    |
|       from large pool |      93    |     178    |  150024    |  149931    |
|       from small pool |     464    |     557    |  142586    |  142122    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  292610    |  292053    |
|       from large pool |      93    |     178    |  150024    |  149931    |
|       from small pool |     464    |     557    |  142586    |  142122    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35863155126571655
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.746972918510437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3903963267803192
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5846830606460571
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43731755018234253
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4497511386871338
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9181 GiB |   9173 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9146 GiB |   9138 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9181 GiB |   9173 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9146 GiB |   9138 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9181 GiB |   9173 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9146 GiB |   9138 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  296628    |  296071    |
|       from large pool |      93    |     178    |  151968    |  151875    |
|       from small pool |     464    |     557    |  144660    |  144196    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  296628    |  296071    |
|       from large pool |      93    |     178    |  151968    |  151875    |
|       from small pool |     464    |     557    |  144660    |  144196    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.481804609298706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7918583154678345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.672724723815918
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42840874195098877
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36995062232017517
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1104559898376465
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41665565967559814
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9020617604255676
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9301 GiB |   9294 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9266 GiB |   9258 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9301 GiB |   9294 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9266 GiB |   9258 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9301 GiB |   9294 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9266 GiB |   9258 GiB |
|       from small pool |     13 MiB |     36 MiB |     35 GiB |     35 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  300692    |  300135    |
|       from large pool |      93    |     178    |  153915    |  153822    |
|       from small pool |     464    |     557    |  146777    |  146313    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  300692    |  300135    |
|       from large pool |      93    |     178    |  153915    |  153822    |
|       from small pool |     464    |     557    |  146777    |  146313    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5116944313049316
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9252290725708008
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.414633870124817
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9859626293182373
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3803067207336426
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5922043323516846
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.402712345123291
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9422 GiB |   9414 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9386 GiB |   9378 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9422 GiB |   9414 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9386 GiB |   9378 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9422 GiB |   9414 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9386 GiB |   9378 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  304733    |  304176    |
|       from large pool |      93    |     178    |  155858    |  155765    |
|       from small pool |     464    |     557    |  148875    |  148411    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  304733    |  304176    |
|       from large pool |      93    |     178    |  155858    |  155765    |
|       from small pool |     464    |     557    |  148875    |  148411    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6224695444107056
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.794919490814209
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5667665600776672
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4867575764656067
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5816335678100586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4143410921096802
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44441157579421997
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9542 GiB |   9535 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9506 GiB |   9498 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9542 GiB |   9535 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9506 GiB |   9498 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9542 GiB |   9535 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9506 GiB |   9498 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  308774    |  308217    |
|       from large pool |      93    |     178    |  157801    |  157708    |
|       from small pool |     464    |     557    |  150973    |  150509    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  308774    |  308217    |
|       from large pool |      93    |     178    |  157801    |  157708    |
|       from small pool |     464    |     557    |  150973    |  150509    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8031931519508362
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40109309554100037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3602941930294037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.627627432346344
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3945261240005493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4165565073490143
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9663 GiB |   9655 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9626 GiB |   9618 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9663 GiB |   9655 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9626 GiB |   9618 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9663 GiB |   9655 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9626 GiB |   9618 GiB |
|       from small pool |     13 MiB |     36 MiB |     36 GiB |     36 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  312792    |  312235    |
|       from large pool |      93    |     178    |  159738    |  159645    |
|       from small pool |     464    |     557    |  153054    |  152590    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  312792    |  312235    |
|       from large pool |      93    |     178    |  159738    |  159645    |
|       from small pool |     464    |     557    |  153054    |  152590    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.199267625808716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6530634164810181
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.8289592266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5036813020706177
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3602833151817322
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5181873440742493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6069742441177368
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9783 GiB |   9776 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9746 GiB |   9739 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9783 GiB |   9776 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9746 GiB |   9739 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9783 GiB |   9776 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9746 GiB |   9739 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  316833    |  316276    |
|       from large pool |      93    |     178    |  161686    |  161593    |
|       from small pool |     464    |     557    |  155147    |  154683    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  316833    |  316276    |
|       from large pool |      93    |     178    |  161686    |  161593    |
|       from small pool |     464    |     557    |  155147    |  154683    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4211292862892151
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40407049655914307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4450536072254181
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4276082515716553
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4543696343898773
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6541560292243958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1092151403427124
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3023735284805298
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |   9904 GiB |   9896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9866 GiB |   9859 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |   9904 GiB |   9896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9866 GiB |   9859 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |   9904 GiB |   9896 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9866 GiB |   9859 GiB |
|       from small pool |     13 MiB |     36 MiB |     37 GiB |     37 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  320897    |  320340    |
|       from large pool |      93    |     178    |  163632    |  163539    |
|       from small pool |     464    |     557    |  157265    |  156801    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  320897    |  320340    |
|       from large pool |      93    |     178    |  163632    |  163539    |
|       from small pool |     464    |     557    |  157265    |  156801    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39061033725738525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9333477020263672
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7632112503051758
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39761194586753845
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.3332133293151855
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4968581199645996
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  10024 GiB |  10017 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9986 GiB |   9979 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  10024 GiB |  10017 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9986 GiB |   9979 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  10024 GiB |  10017 GiB |
|       from large pool |   7593 MiB |   9606 MiB |   9986 GiB |   9979 GiB |
|       from small pool |     13 MiB |     36 MiB |     38 GiB |     38 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  17830 MiB |   7876 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  17740 MiB |   7820 MiB |
|       from small pool |     34 MiB |     42 MiB |     90 MiB |     56 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  324915    |  324358    |
|       from large pool |      93    |     178    |  165576    |  165483    |
|       from small pool |     464    |     557    |  159339    |  158875    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  324915    |  324358    |
|       from large pool |      93    |     178    |  165576    |  165483    |
|       from small pool |     464    |     557    |  159339    |  158875    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6446283459663391
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  11057 GiB |  11052 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  11015 GiB |  11009 GiB |
|       from small pool |      9 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  11057 GiB |  11052 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  11015 GiB |  11009 GiB |
|       from small pool |      9 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  11057 GiB |  11052 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  11015 GiB |  11009 GiB |
|       from small pool |      8 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  17838 MiB |  12024 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  17740 MiB |  11940 MiB |
|       from small pool |     14 MiB |     42 MiB |     98 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  353906    |  353471    |
|       from large pool |      69    |     178    |  184161    |  184092    |
|       from small pool |     366    |     557    |  169745    |  169379    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  353906    |  353471    |
|       from large pool |      69    |     178    |  184161    |  184092    |
|       from small pool |     366    |     557    |  169745    |  169379    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7930572628974915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8106309175491333
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.154629945755005
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4358925819396973
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5403582453727722
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42518410086631775
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3946791887283325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.337820291519165
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11178 GiB |  11170 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11135 GiB |  11128 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11178 GiB |  11170 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11135 GiB |  11128 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11178 GiB |  11170 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11135 GiB |  11128 GiB |
|       from small pool |     13 MiB |     36 MiB |     42 GiB |     42 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  357970    |  357413    |
|       from large pool |      93    |     178    |  186106    |  186013    |
|       from small pool |     464    |     557    |  171864    |  171400    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  357970    |  357413    |
|       from large pool |      93    |     178    |  186106    |  186013    |
|       from small pool |     464    |     557    |  171864    |  171400    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7283328771591187
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5086467266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6587628722190857
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43243226408958435
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8997114896774292
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3564055263996124
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11298 GiB |  11291 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11255 GiB |  11248 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11298 GiB |  11291 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11255 GiB |  11248 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11298 GiB |  11291 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11255 GiB |  11248 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  361988    |  361431    |
|       from large pool |      93    |     178    |  188046    |  187953    |
|       from small pool |     464    |     557    |  173942    |  173478    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  361988    |  361431    |
|       from large pool |      93    |     178    |  188046    |  187953    |
|       from small pool |     464    |     557    |  173942    |  173478    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3781545162200928
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6633870601654053
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34436315298080444
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6021005511283875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4337024390697479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8381946086883545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3798515796661377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46760791540145874
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11419 GiB |  11411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11375 GiB |  11368 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11419 GiB |  11411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11375 GiB |  11368 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11419 GiB |  11411 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11375 GiB |  11368 GiB |
|       from small pool |     13 MiB |     36 MiB |     43 GiB |     43 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  366052    |  365495    |
|       from large pool |      93    |     178    |  189992    |  189899    |
|       from small pool |     464    |     557    |  176060    |  175596    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  366052    |  365495    |
|       from large pool |      93    |     178    |  189992    |  189899    |
|       from small pool |     464    |     557    |  176060    |  175596    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36306190490722656
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7336841821670532
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1666553020477295
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6589175462722778
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40363696217536926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4622725248336792
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3715578317642212
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11539 GiB |  11532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11495 GiB |  11488 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11539 GiB |  11532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11495 GiB |  11488 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11539 GiB |  11532 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11495 GiB |  11488 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  370093    |  369536    |
|       from large pool |      93    |     178    |  191939    |  191846    |
|       from small pool |     464    |     557    |  178154    |  177690    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  370093    |  369536    |
|       from large pool |      93    |     178    |  191939    |  191846    |
|       from small pool |     464    |     557    |  178154    |  177690    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3419116735458374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46878868341445923
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8391717672348022
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5013014674186707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37441208958625793
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5385311841964722
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11660 GiB |  11652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11615 GiB |  11608 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11660 GiB |  11652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11615 GiB |  11608 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11660 GiB |  11652 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11615 GiB |  11608 GiB |
|       from small pool |     13 MiB |     36 MiB |     44 GiB |     44 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  374111    |  373554    |
|       from large pool |      93    |     178    |  193883    |  193790    |
|       from small pool |     464    |     557    |  180228    |  179764    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  374111    |  373554    |
|       from large pool |      93    |     178    |  193883    |  193790    |
|       from small pool |     464    |     557    |  180228    |  179764    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3904067277908325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35047394037246704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.732211947441101
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3668222427368164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.326054096221924
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11780 GiB |  11773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11735 GiB |  11728 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11780 GiB |  11773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11735 GiB |  11728 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11780 GiB |  11773 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11735 GiB |  11728 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  378106    |  377549    |
|       from large pool |      93    |     178    |  195823    |  195730    |
|       from small pool |     464    |     557    |  182283    |  181819    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  378106    |  377549    |
|       from large pool |      93    |     178    |  195823    |  195730    |
|       from small pool |     464    |     557    |  182283    |  181819    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9112567901611328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8813654184341431
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35766473412513733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6242033839225769
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4178542494773865
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39821115136146545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7165666818618774
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  11901 GiB |  11893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11855 GiB |  11848 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  11901 GiB |  11893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11855 GiB |  11848 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  11901 GiB |  11893 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11855 GiB |  11848 GiB |
|       from small pool |     13 MiB |     36 MiB |     45 GiB |     45 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  382147    |  381590    |
|       from large pool |      93    |     178    |  197771    |  197678    |
|       from small pool |     464    |     557    |  184376    |  183912    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  382147    |  381590    |
|       from large pool |      93    |     178    |  197771    |  197678    |
|       from small pool |     464    |     557    |  184376    |  183912    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34212782979011536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284926116466522
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7136108875274658
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9933941960334778
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.3595523834228516
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8102750778198242
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0816224813461304
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12021 GiB |  12014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11975 GiB |  11968 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12021 GiB |  12014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11975 GiB |  11968 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12021 GiB |  12014 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  11975 GiB |  11968 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  386188    |  385631    |
|       from large pool |      93    |     178    |  199710    |  199617    |
|       from small pool |     464    |     557    |  186478    |  186014    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  386188    |  385631    |
|       from large pool |      93    |     178    |  199710    |  199617    |
|       from small pool |     464    |     557    |  186478    |  186014    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.413299024105072
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9135479927062988
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4067084491252899
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.174579620361328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2894893884658813
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12142 GiB |  12134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12095 GiB |  12088 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12142 GiB |  12134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12095 GiB |  12088 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12142 GiB |  12134 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12095 GiB |  12088 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  390183    |  389626    |
|       from large pool |      93    |     178    |  201649    |  201556    |
|       from small pool |     464    |     557    |  188534    |  188070    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  390183    |  389626    |
|       from large pool |      93    |     178    |  201649    |  201556    |
|       from small pool |     464    |     557    |  188534    |  188070    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6825628876686096
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.094824194908142
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36362388730049133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5129873752593994
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.030917763710022
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7728220224380493
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37418532371520996
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12262 GiB |  12255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12215 GiB |  12208 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12262 GiB |  12255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12215 GiB |  12208 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12262 GiB |  12255 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12215 GiB |  12208 GiB |
|       from small pool |     13 MiB |     36 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  394224    |  393667    |
|       from large pool |      93    |     178    |  203597    |  203504    |
|       from small pool |     464    |     557    |  190627    |  190163    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  394224    |  393667    |
|       from large pool |      93    |     178    |  203597    |  203504    |
|       from small pool |     464    |     557    |  190627    |  190163    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30440935492515564
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46403172612190247
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6374162435531616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47682198882102966
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4160236716270447
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41514167189598083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4792505204677582
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12383 GiB |  12375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12335 GiB |  12328 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12383 GiB |  12375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12335 GiB |  12328 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12383 GiB |  12375 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12335 GiB |  12328 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  398265    |  397708    |
|       from large pool |      93    |     178    |  205544    |  205451    |
|       from small pool |     464    |     557    |  192721    |  192257    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  398265    |  397708    |
|       from large pool |      93    |     178    |  205544    |  205451    |
|       from small pool |     464    |     557    |  192721    |  192257    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9984489679336548
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2547656297683716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42159074544906616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3940301835536957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43876731395721436
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3962877094745636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7742434144020081
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48457634449005127
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12503 GiB |  12496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12456 GiB |  12448 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12503 GiB |  12496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12456 GiB |  12448 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12503 GiB |  12496 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12456 GiB |  12448 GiB |
|       from small pool |     13 MiB |     36 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  402329    |  401772    |
|       from large pool |      93    |     178    |  207494    |  207401    |
|       from small pool |     464    |     557    |  194835    |  194371    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  402329    |  401772    |
|       from large pool |      93    |     178    |  207494    |  207401    |
|       from small pool |     464    |     557    |  194835    |  194371    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4956094026565552
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5226385593414307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4763917326927185
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3738737106323242
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5782414078712463
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3818342983722687
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.098876714706421
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5317774415016174
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12624 GiB |  12617 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12576 GiB |  12568 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12624 GiB |  12617 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12576 GiB |  12568 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12624 GiB |  12617 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12576 GiB |  12568 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  406393    |  405836    |
|       from large pool |      93    |     178    |  209445    |  209352    |
|       from small pool |     464    |     557    |  196948    |  196484    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  406393    |  405836    |
|       from large pool |      93    |     178    |  209445    |  209352    |
|       from small pool |     464    |     557    |  196948    |  196484    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34576982259750366
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49367421865463257
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38496139645576477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.151196479797363
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6276695728302002
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5083506107330322
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4003390669822693
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12744 GiB |  12737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12696 GiB |  12688 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12744 GiB |  12737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12696 GiB |  12688 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12744 GiB |  12737 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12696 GiB |  12688 GiB |
|       from small pool |     13 MiB |     36 MiB |     48 GiB |     48 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  410434    |  409877    |
|       from large pool |      93    |     178    |  211388    |  211295    |
|       from small pool |     464    |     557    |  199046    |  198582    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  410434    |  409877    |
|       from large pool |      93    |     178    |  211388    |  211295    |
|       from small pool |     464    |     557    |  199046    |  198582    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34301993250846863
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.722851037979126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37242257595062256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5657562613487244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41457399725914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43614786863327026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12865 GiB |  12858 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12816 GiB |  12808 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12865 GiB |  12858 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12816 GiB |  12808 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12865 GiB |  12858 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12816 GiB |  12808 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  414452    |  413895    |
|       from large pool |      93    |     178    |  213332    |  213239    |
|       from small pool |     464    |     557    |  201120    |  200656    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  414452    |  413895    |
|       from large pool |      93    |     178    |  213332    |  213239    |
|       from small pool |     464    |     557    |  201120    |  200656    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4422942399978638
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7304792404174805
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.612187385559082
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4083971083164215
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35246723890304565
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9530659914016724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40092340111732483
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8486791849136353
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  12985 GiB |  12978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12936 GiB |  12928 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  12985 GiB |  12978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12936 GiB |  12928 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  12985 GiB |  12978 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  12936 GiB |  12928 GiB |
|       from small pool |     13 MiB |     36 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  418516    |  417959    |
|       from large pool |      93    |     178    |  215279    |  215186    |
|       from small pool |     464    |     557    |  203237    |  202773    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  418516    |  417959    |
|       from large pool |      93    |     178    |  215279    |  215186    |
|       from small pool |     464    |     557    |  203237    |  202773    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.490337997674942
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8784583210945129
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2507680654525757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9552468061447144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3652568459510803
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5493290424346924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3815479874610901
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13106 GiB |  13099 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13056 GiB |  13048 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13106 GiB |  13099 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13056 GiB |  13048 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13106 GiB |  13099 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13056 GiB |  13048 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  422557    |  422000    |
|       from large pool |      93    |     178    |  217222    |  217129    |
|       from small pool |     464    |     557    |  205335    |  204871    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  422557    |  422000    |
|       from large pool |      93    |     178    |  217222    |  217129    |
|       from small pool |     464    |     557    |  205335    |  204871    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5802987217903137
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7484342455863953
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5494769811630249
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4643653333187103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5457404851913452
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3989465534687042
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42997774481773376
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13226 GiB |  13219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13176 GiB |  13168 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13226 GiB |  13219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13176 GiB |  13168 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13226 GiB |  13219 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13176 GiB |  13168 GiB |
|       from small pool |     13 MiB |     36 MiB |     50 GiB |     50 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  426598    |  426041    |
|       from large pool |      93    |     178    |  219165    |  219072    |
|       from small pool |     464    |     557    |  207433    |  206969    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  426598    |  426041    |
|       from large pool |      93    |     178    |  219165    |  219072    |
|       from small pool |     464    |     557    |  207433    |  206969    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7423388957977295
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38405466079711914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3448895215988159
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5970014333724976
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.376468688249588
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40056467056274414
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13347 GiB |  13340 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13296 GiB |  13288 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13347 GiB |  13340 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13296 GiB |  13288 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13347 GiB |  13339 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13296 GiB |  13288 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  430616    |  430059    |
|       from large pool |      93    |     178    |  221102    |  221009    |
|       from small pool |     464    |     557    |  209514    |  209050    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  430616    |  430059    |
|       from large pool |      93    |     178    |  221102    |  221009    |
|       from small pool |     464    |     557    |  209514    |  209050    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1499416828155518
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6170884370803833
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.7615437507629395
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4902063310146332
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.342864990234375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5018545985221863
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5526416301727295
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13467 GiB |  13460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13416 GiB |  13408 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13467 GiB |  13460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13416 GiB |  13408 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13467 GiB |  13460 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13416 GiB |  13408 GiB |
|       from small pool |     13 MiB |     36 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  434657    |  434100    |
|       from large pool |      93    |     178    |  223050    |  222957    |
|       from small pool |     464    |     557    |  211607    |  211143    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  434657    |  434100    |
|       from large pool |      93    |     178    |  223050    |  222957    |
|       from small pool |     464    |     557    |  211607    |  211143    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3963841199874878
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3859878480434418
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43436458706855774
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40195322036743164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4347972571849823
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6304241418838501
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0596929788589478
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2464430332183838
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13588 GiB |  13581 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13536 GiB |  13529 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13588 GiB |  13581 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13536 GiB |  13529 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13588 GiB |  13581 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13536 GiB |  13529 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  438721    |  438164    |
|       from large pool |      93    |     178    |  224996    |  224903    |
|       from small pool |     464    |     557    |  213725    |  213261    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  438721    |  438164    |
|       from large pool |      93    |     178    |  224996    |  224903    |
|       from small pool |     464    |     557    |  213725    |  213261    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35329416394233704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8949295878410339
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.693165898323059
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38602107763290405
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.273541450500488
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47628358006477356
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  13708 GiB |  13701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13656 GiB |  13649 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  13708 GiB |  13701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13656 GiB |  13649 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  13708 GiB |  13701 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  13656 GiB |  13649 GiB |
|       from small pool |     13 MiB |     36 MiB |     52 GiB |     52 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  21978 MiB |  12024 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  21860 MiB |  11940 MiB |
|       from small pool |     34 MiB |     42 MiB |    118 MiB |     84 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  442739    |  442182    |
|       from large pool |      93    |     178    |  226940    |  226847    |
|       from small pool |     464    |     557    |  215799    |  215335    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  442739    |  442182    |
|       from large pool |      93    |     178    |  226940    |  226847    |
|       from small pool |     464    |     557    |  215799    |  215335    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6043571829795837
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  14741 GiB |  14736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14685 GiB |  14679 GiB |
|       from small pool |      9 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  14741 GiB |  14736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14685 GiB |  14679 GiB |
|       from small pool |      9 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  14741 GiB |  14736 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  14685 GiB |  14679 GiB |
|       from small pool |      8 MiB |     36 MiB |     56 GiB |     56 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  21986 MiB |  16172 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  21860 MiB |  16060 MiB |
|       from small pool |     14 MiB |     42 MiB |    126 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  471730    |  471295    |
|       from large pool |      69    |     178    |  245525    |  245456    |
|       from small pool |     366    |     557    |  226205    |  225839    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  471730    |  471295    |
|       from large pool |      69    |     178    |  245525    |  245456    |
|       from small pool |     366    |     557    |  226205    |  225839    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7696083784103394
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7738329172134399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1072099208831787
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4392237663269043
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5005015730857849
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3845720589160919
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3539958596229553
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3030188083648682
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14862 GiB |  14855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14805 GiB |  14797 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14862 GiB |  14855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14805 GiB |  14797 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14862 GiB |  14855 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14805 GiB |  14797 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  475794    |  475237    |
|       from large pool |      93    |     178    |  247470    |  247377    |
|       from small pool |     464    |     557    |  228324    |  227860    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  475794    |  475237    |
|       from large pool |      93    |     178    |  247470    |  247377    |
|       from small pool |     464    |     557    |  228324    |  227860    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7387155294418335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48472341895103455
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6403278708457947
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.413040429353714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8626539707183838
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324313223361969
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  14982 GiB |  14975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14925 GiB |  14918 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  14982 GiB |  14975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14925 GiB |  14918 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  14982 GiB |  14975 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  14925 GiB |  14918 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  479812    |  479255    |
|       from large pool |      93    |     178    |  249410    |  249317    |
|       from small pool |     464    |     557    |  230402    |  229938    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  479812    |  479255    |
|       from large pool |      93    |     178    |  249410    |  249317    |
|       from small pool |     464    |     557    |  230402    |  229938    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35225561261177063
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6438730955123901
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32586467266082764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.574292778968811
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41302573680877686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8201944231987
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36107563972473145
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4429234266281128
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15103 GiB |  15096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15045 GiB |  15038 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15103 GiB |  15096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15045 GiB |  15038 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15103 GiB |  15096 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15045 GiB |  15038 GiB |
|       from small pool |     13 MiB |     36 MiB |     57 GiB |     57 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  483876    |  483319    |
|       from large pool |      93    |     178    |  251356    |  251263    |
|       from small pool |     464    |     557    |  232520    |  232056    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  483876    |  483319    |
|       from large pool |      93    |     178    |  251356    |  251263    |
|       from small pool |     464    |     557    |  232520    |  232056    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3480510413646698
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7084197998046875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1274973154067993
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6368315815925598
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3884425163269043
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41889122128486633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3325780630111694
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15223 GiB |  15216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15165 GiB |  15158 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15223 GiB |  15216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15165 GiB |  15158 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15223 GiB |  15216 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15165 GiB |  15158 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  487917    |  487360    |
|       from large pool |      93    |     178    |  253303    |  253210    |
|       from small pool |     464    |     557    |  234614    |  234150    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  487917    |  487360    |
|       from large pool |      93    |     178    |  253303    |  253210    |
|       from small pool |     464    |     557    |  234614    |  234150    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32780951261520386
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44647303223609924
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.807952344417572
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4614025950431824
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3634142279624939
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.507057785987854
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15344 GiB |  15337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15285 GiB |  15278 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15344 GiB |  15337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15285 GiB |  15278 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15344 GiB |  15337 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15285 GiB |  15278 GiB |
|       from small pool |     13 MiB |     36 MiB |     58 GiB |     58 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  491935    |  491378    |
|       from large pool |      93    |     178    |  255247    |  255154    |
|       from small pool |     464    |     557    |  236688    |  236224    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  491935    |  491378    |
|       from large pool |      93    |     178    |  255247    |  255154    |
|       from small pool |     464    |     557    |  236688    |  236224    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35348328948020935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3369205892086029
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6761924028396606
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34206584095954895
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.289836883544922
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15464 GiB |  15457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15405 GiB |  15398 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15464 GiB |  15457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15405 GiB |  15398 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15464 GiB |  15457 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15405 GiB |  15398 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  495930    |  495373    |
|       from large pool |      93    |     178    |  257187    |  257094    |
|       from small pool |     464    |     557    |  238743    |  238279    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  495930    |  495373    |
|       from large pool |      93    |     178    |  257187    |  257094    |
|       from small pool |     464    |     557    |  238743    |  238279    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8633443713188171
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8268972635269165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33858802914619446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5944257974624634
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39823782444000244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.382181316614151
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6845089793205261
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15585 GiB |  15578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15525 GiB |  15518 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15585 GiB |  15578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15525 GiB |  15518 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15585 GiB |  15578 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15525 GiB |  15518 GiB |
|       from small pool |     13 MiB |     36 MiB |     59 GiB |     59 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  499971    |  499414    |
|       from large pool |      93    |     178    |  259135    |  259042    |
|       from small pool |     464    |     557    |  240836    |  240372    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  499971    |  499414    |
|       from large pool |      93    |     178    |  259135    |  259042    |
|       from small pool |     464    |     557    |  240836    |  240372    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32874244451522827
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3081795275211334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6619094610214233
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8459346890449524
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.321760416030884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7155598998069763
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0504289865493774
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15705 GiB |  15698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15645 GiB |  15638 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15705 GiB |  15698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15645 GiB |  15638 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15705 GiB |  15698 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15645 GiB |  15638 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  504012    |  503455    |
|       from large pool |      93    |     178    |  261074    |  260981    |
|       from small pool |     464    |     557    |  242938    |  242474    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  504012    |  503455    |
|       from large pool |      93    |     178    |  261074    |  260981    |
|       from small pool |     464    |     557    |  242938    |  242474    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40089112520217896
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8821102380752563
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3742945194244385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.1395344734191895
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2572300434112549
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15826 GiB |  15818 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15765 GiB |  15758 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15826 GiB |  15818 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15765 GiB |  15758 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15826 GiB |  15818 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15765 GiB |  15758 GiB |
|       from small pool |     13 MiB |     36 MiB |     60 GiB |     60 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  508007    |  507450    |
|       from large pool |      93    |     178    |  263013    |  262920    |
|       from small pool |     464    |     557    |  244994    |  244530    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  508007    |  507450    |
|       from large pool |      93    |     178    |  263013    |  262920    |
|       from small pool |     464    |     557    |  244994    |  244530    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6645398736000061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0516414642333984
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3420185446739197
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4718320369720459
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9858909249305725
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7448924779891968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3587813079357147
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  15946 GiB |  15939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15885 GiB |  15878 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  15946 GiB |  15939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15885 GiB |  15878 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  15946 GiB |  15939 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  15885 GiB |  15878 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  512048    |  511491    |
|       from large pool |      93    |     178    |  264961    |  264868    |
|       from small pool |     464    |     557    |  247087    |  246623    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  512048    |  511491    |
|       from large pool |      93    |     178    |  264961    |  264868    |
|       from small pool |     464    |     557    |  247087    |  246623    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2892478406429291
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.446908563375473
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6241509914398193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.452237606048584
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38668879866600037
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39500245451927185
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4571174681186676
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16067 GiB |  16060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16005 GiB |  15998 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16067 GiB |  16060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16005 GiB |  15998 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16067 GiB |  16060 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16005 GiB |  15998 GiB |
|       from small pool |     13 MiB |     36 MiB |     61 GiB |     61 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  516089    |  515532    |
|       from large pool |      93    |     178    |  266908    |  266815    |
|       from small pool |     464    |     557    |  249181    |  248717    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  516089    |  515532    |
|       from large pool |      93    |     178    |  266908    |  266815    |
|       from small pool |     464    |     557    |  249181    |  248717    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9703024625778198
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2268974781036377
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38222089409828186
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3834834098815918
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4158337712287903
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38689056038856506
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7324391007423401
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4568125903606415
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16188 GiB |  16180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16125 GiB |  16118 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16188 GiB |  16180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16125 GiB |  16118 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16187 GiB |  16180 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16125 GiB |  16118 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  520153    |  519596    |
|       from large pool |      93    |     178    |  268858    |  268765    |
|       from small pool |     464    |     557    |  251295    |  250831    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  520153    |  519596    |
|       from large pool |      93    |     178    |  268858    |  268765    |
|       from small pool |     464    |     557    |  251295    |  250831    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46983617544174194
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5018084049224854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45918580889701843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34954211115837097
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5389177799224854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3717734217643738
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0475189685821533
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49729806184768677
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16308 GiB |  16301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16246 GiB |  16238 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16308 GiB |  16301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16246 GiB |  16238 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16308 GiB |  16301 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16246 GiB |  16238 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  524217    |  523660    |
|       from large pool |      93    |     178    |  270809    |  270716    |
|       from small pool |     464    |     557    |  253408    |  252944    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  524217    |  523660    |
|       from large pool |      93    |     178    |  270809    |  270716    |
|       from small pool |     464    |     557    |  253408    |  252944    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33280983567237854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4671946167945862
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34541434049606323
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.116434574127197
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5871601700782776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4871812164783478
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3709505498409271
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16429 GiB |  16421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16366 GiB |  16358 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16429 GiB |  16421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16366 GiB |  16358 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16429 GiB |  16421 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16366 GiB |  16358 GiB |
|       from small pool |     13 MiB |     36 MiB |     62 GiB |     62 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  528258    |  527701    |
|       from large pool |      93    |     178    |  272752    |  272659    |
|       from small pool |     464    |     557    |  255506    |  255042    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  528258    |  527701    |
|       from large pool |      93    |     178    |  272752    |  272659    |
|       from small pool |     464    |     557    |  255506    |  255042    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3285726010799408
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7077078819274902
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3541874587535858
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.540101170539856
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39517709612846375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4215240776538849
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16549 GiB |  16542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16486 GiB |  16478 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16549 GiB |  16542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16486 GiB |  16478 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16549 GiB |  16542 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16486 GiB |  16478 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  532276    |  531719    |
|       from large pool |      93    |     178    |  274696    |  274603    |
|       from small pool |     464    |     557    |  257580    |  257116    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  532276    |  531719    |
|       from large pool |      93    |     178    |  274696    |  274603    |
|       from small pool |     464    |     557    |  257580    |  257116    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4052671194076538
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6727595329284668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5740201473236084
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3823288679122925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33647620677948
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8517757058143616
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38571423292160034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7971600890159607
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16670 GiB |  16662 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16606 GiB |  16598 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16670 GiB |  16662 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16606 GiB |  16598 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16670 GiB |  16662 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16606 GiB |  16598 GiB |
|       from small pool |     13 MiB |     36 MiB |     63 GiB |     63 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  536340    |  535783    |
|       from large pool |      93    |     178    |  276643    |  276550    |
|       from small pool |     464    |     557    |  259697    |  259233    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  536340    |  535783    |
|       from large pool |      93    |     178    |  276643    |  276550    |
|       from small pool |     464    |     557    |  259697    |  259233    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47017186880111694
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8344438076019287
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.068676471710205
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9240391254425049
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35040900111198425
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.511786937713623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36324790120124817
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16790 GiB |  16783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16726 GiB |  16718 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16790 GiB |  16783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16726 GiB |  16718 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16790 GiB |  16783 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16726 GiB |  16718 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  540381    |  539824    |
|       from large pool |      93    |     178    |  278586    |  278493    |
|       from small pool |     464    |     557    |  261795    |  261331    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  540381    |  539824    |
|       from large pool |      93    |     178    |  278586    |  278493    |
|       from small pool |     464    |     557    |  261795    |  261331    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5441670417785645
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7062374949455261
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5278030037879944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43699127435684204
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5143771767616272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3693526089191437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3911777138710022
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  16911 GiB |  16903 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16846 GiB |  16838 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  16911 GiB |  16903 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16846 GiB |  16838 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  16911 GiB |  16903 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16846 GiB |  16838 GiB |
|       from small pool |     13 MiB |     36 MiB |     64 GiB |     64 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  544422    |  543865    |
|       from large pool |      93    |     178    |  280529    |  280436    |
|       from small pool |     464    |     557    |  263893    |  263429    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  544422    |  543865    |
|       from large pool |      93    |     178    |  280529    |  280436    |
|       from small pool |     464    |     557    |  263893    |  263429    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.763845682144165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35922425985336304
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3260841965675354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.566985011100769
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3556440770626068
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3841143846511841
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17031 GiB |  17024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16966 GiB |  16958 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17031 GiB |  17024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16966 GiB |  16958 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17031 GiB |  17024 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  16966 GiB |  16958 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  548440    |  547883    |
|       from large pool |      93    |     178    |  282466    |  282373    |
|       from small pool |     464    |     557    |  265974    |  265510    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  548440    |  547883    |
|       from large pool |      93    |     178    |  282466    |  282373    |
|       from small pool |     464    |     557    |  265974    |  265510    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1170198917388916
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5884301662445068
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.694685697555542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4767865240573883
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.328854501247406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4874052405357361
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.501418948173523
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17152 GiB |  17144 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17086 GiB |  17078 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17152 GiB |  17144 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17086 GiB |  17078 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17152 GiB |  17144 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17086 GiB |  17078 GiB |
|       from small pool |     13 MiB |     36 MiB |     65 GiB |     65 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  552481    |  551924    |
|       from large pool |      93    |     178    |  284414    |  284321    |
|       from small pool |     464    |     557    |  268067    |  267603    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  552481    |  551924    |
|       from large pool |      93    |     178    |  284414    |  284321    |
|       from small pool |     464    |     557    |  268067    |  267603    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35631272196769714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3638763725757599
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.415113240480423
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3737080991268158
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41739779710769653
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5961752533912659
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.011290192604065
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.192165732383728
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17272 GiB |  17265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17206 GiB |  17198 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17272 GiB |  17265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17206 GiB |  17198 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17272 GiB |  17265 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17206 GiB |  17198 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  556545    |  555988    |
|       from large pool |      93    |     178    |  286360    |  286267    |
|       from small pool |     464    |     557    |  270185    |  269721    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  556545    |  555988    |
|       from large pool |      93    |     178    |  286360    |  286267    |
|       from small pool |     464    |     557    |  270185    |  269721    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3219052255153656
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8539865016937256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6443272829055786
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3701934218406677
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.238527774810791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45275771617889404
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  17393 GiB |  17385 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17326 GiB |  17319 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  17393 GiB |  17385 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17326 GiB |  17319 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  17393 GiB |  17385 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  17326 GiB |  17319 GiB |
|       from small pool |     13 MiB |     36 MiB |     66 GiB |     66 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  26126 MiB |  16172 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  25980 MiB |  16060 MiB |
|       from small pool |     34 MiB |     42 MiB |    146 MiB |    112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  560563    |  560006    |
|       from large pool |      93    |     178    |  288304    |  288211    |
|       from small pool |     464    |     557    |  272259    |  271795    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  560563    |  560006    |
|       from large pool |      93    |     178    |  288304    |  288211    |
|       from small pool |     464    |     557    |  272259    |  271795    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.564845860004425
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  18426 GiB |  18420 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18355 GiB |  18349 GiB |
|       from small pool |      9 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  18426 GiB |  18420 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18355 GiB |  18349 GiB |
|       from small pool |      9 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  18426 GiB |  18420 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  18355 GiB |  18349 GiB |
|       from small pool |      8 MiB |     36 MiB |     70 GiB |     70 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  26134 MiB |  20320 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  25980 MiB |  20180 MiB |
|       from small pool |     14 MiB |     42 MiB |    154 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  589554    |  589119    |
|       from large pool |      69    |     178    |  306889    |  306820    |
|       from small pool |     366    |     557    |  282665    |  282299    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  589554    |  589119    |
|       from large pool |      69    |     178    |  306889    |  306820    |
|       from small pool |     366    |     557    |  282665    |  282299    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7437087893486023
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7437713742256165
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0666611194610596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4547584056854248
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4739750623703003
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3508828282356262
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3234092891216278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2739440202713013
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18546 GiB |  18539 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18475 GiB |  18467 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18546 GiB |  18539 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18475 GiB |  18467 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18546 GiB |  18539 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18475 GiB |  18467 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  593618    |  593061    |
|       from large pool |      93    |     178    |  308834    |  308741    |
|       from small pool |     464    |     557    |  284784    |  284320    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  593618    |  593061    |
|       from large pool |      93    |     178    |  308834    |  308741    |
|       from small pool |     464    |     557    |  284784    |  284320    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7835104465484619
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647943675518036
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6195951104164124
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3989918529987335
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.83207368850708
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30287811160087585
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18667 GiB |  18659 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18595 GiB |  18587 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18667 GiB |  18659 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18595 GiB |  18587 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18667 GiB |  18659 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18595 GiB |  18587 GiB |
|       from small pool |     13 MiB |     36 MiB |     71 GiB |     71 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  597636    |  597079    |
|       from large pool |      93    |     178    |  310774    |  310681    |
|       from small pool |     464    |     557    |  286862    |  286398    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  597636    |  597079    |
|       from large pool |      93    |     178    |  310774    |  310681    |
|       from small pool |     464    |     557    |  286862    |  286398    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32705992460250854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6540850400924683
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32307741045951843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.553713858127594
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3983871340751648
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8048974275588989
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34606677293777466
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42535436153411865
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18787 GiB |  18780 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18715 GiB |  18708 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18787 GiB |  18780 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18715 GiB |  18708 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18787 GiB |  18780 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18715 GiB |  18708 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  601700    |  601143    |
|       from large pool |      93    |     178    |  312720    |  312627    |
|       from small pool |     464    |     557    |  288980    |  288516    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  601700    |  601143    |
|       from large pool |      93    |     178    |  312720    |  312627    |
|       from small pool |     464    |     557    |  288980    |  288516    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33705025911331177
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6835212707519531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.089398980140686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6109908223152161
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37597376108169556
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38276466727256775
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2975618839263916
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  18908 GiB |  18900 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18835 GiB |  18828 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  18908 GiB |  18900 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18835 GiB |  18828 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  18908 GiB |  18900 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18835 GiB |  18828 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  605741    |  605184    |
|       from large pool |      93    |     178    |  314667    |  314574    |
|       from small pool |     464    |     557    |  291074    |  290610    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  605741    |  605184    |
|       from large pool |      93    |     178    |  314667    |  314574    |
|       from small pool |     464    |     557    |  291074    |  290610    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3183952271938324
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4295913279056549
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7786715626716614
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43221718072891235
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3559081554412842
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48468106985092163
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19028 GiB |  19021 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18955 GiB |  18948 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19028 GiB |  19021 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18955 GiB |  18948 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19028 GiB |  19021 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  18955 GiB |  18948 GiB |
|       from small pool |     13 MiB |     36 MiB |     72 GiB |     72 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  609759    |  609202    |
|       from large pool |      93    |     178    |  316611    |  316518    |
|       from small pool |     464    |     557    |  293148    |  292684    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  609759    |  609202    |
|       from large pool |      93    |     178    |  316611    |  316518    |
|       from small pool |     464    |     557    |  293148    |  292684    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32916566729545593
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3274155557155609
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.625609278678894
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32250678539276123
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.256333589553833
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19149 GiB |  19141 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19075 GiB |  19068 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19149 GiB |  19141 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19075 GiB |  19068 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19149 GiB |  19141 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19075 GiB |  19068 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  613754    |  613197    |
|       from large pool |      93    |     178    |  318551    |  318458    |
|       from small pool |     464    |     557    |  295203    |  294739    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  613754    |  613197    |
|       from large pool |      93    |     178    |  318551    |  318458    |
|       from small pool |     464    |     557    |  295203    |  294739    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8248248100280762
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7831247448921204
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32505783438682556
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5658968687057495
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37843772768974304
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37125566601753235
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.657664954662323
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19269 GiB |  19262 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19195 GiB |  19188 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19269 GiB |  19262 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19195 GiB |  19188 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19269 GiB |  19262 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19195 GiB |  19188 GiB |
|       from small pool |     13 MiB |     36 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  617795    |  617238    |
|       from large pool |      93    |     178    |  320499    |  320406    |
|       from small pool |     464    |     557    |  297296    |  296832    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  617795    |  617238    |
|       from large pool |      93    |     178    |  320499    |  320406    |
|       from small pool |     464    |     557    |  297296    |  296832    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3204960823059082
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3045646548271179
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.614041805267334
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7644869685173035
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2923824787139893
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6829583048820496
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0228385925292969
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19390 GiB |  19382 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19315 GiB |  19308 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19390 GiB |  19382 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19315 GiB |  19308 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19390 GiB |  19382 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19315 GiB |  19308 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  621836    |  621279    |
|       from large pool |      93    |     178    |  322438    |  322345    |
|       from small pool |     464    |     557    |  299398    |  298934    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  621836    |  621279    |
|       from large pool |      93    |     178    |  322438    |  322345    |
|       from small pool |     464    |     557    |  299398    |  298934    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38931605219841003
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8528540134429932
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3485627770423889
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.111616611480713
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2297002077102661
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19510 GiB |  19503 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19435 GiB |  19428 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19510 GiB |  19503 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19435 GiB |  19428 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19510 GiB |  19503 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19435 GiB |  19428 GiB |
|       from small pool |     13 MiB |     36 MiB |     74 GiB |     74 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  625831    |  625274    |
|       from large pool |      93    |     178    |  324377    |  324284    |
|       from small pool |     464    |     557    |  301454    |  300990    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  625831    |  625274    |
|       from large pool |      93    |     178    |  324377    |  324284    |
|       from small pool |     464    |     557    |  301454    |  300990    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6492116451263428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.008128046989441
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284187912940979
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4428568184375763
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9412129521369934
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7195854187011719
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34543299674987793
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19631 GiB |  19623 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19555 GiB |  19548 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19631 GiB |  19623 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19555 GiB |  19548 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19631 GiB |  19623 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19555 GiB |  19548 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  629872    |  629315    |
|       from large pool |      93    |     178    |  326325    |  326232    |
|       from small pool |     464    |     557    |  303547    |  303083    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  629872    |  629315    |
|       from large pool |      93    |     178    |  326325    |  326232    |
|       from small pool |     464    |     557    |  303547    |  303083    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2819531559944153
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4309505522251129
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6133702993392944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43492189049720764
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3658623695373535
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37986767292022705
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44018375873565674
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19751 GiB |  19744 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19675 GiB |  19668 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19751 GiB |  19744 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19675 GiB |  19668 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19751 GiB |  19744 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19675 GiB |  19668 GiB |
|       from small pool |     13 MiB |     36 MiB |     75 GiB |     75 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  633913    |  633356    |
|       from large pool |      93    |     178    |  328272    |  328179    |
|       from small pool |     464    |     557    |  305641    |  305177    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  633913    |  633356    |
|       from large pool |      93    |     178    |  328272    |  328179    |
|       from small pool |     464    |     557    |  305641    |  305177    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9464237093925476
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2035741806030273
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3545955717563629
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3758346438407898
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39175179600715637
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3806363046169281
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6995801329612732
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43269583582878113
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19872 GiB |  19864 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19795 GiB |  19788 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19872 GiB |  19864 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19795 GiB |  19788 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19872 GiB |  19864 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19795 GiB |  19788 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  637977    |  637420    |
|       from large pool |      93    |     178    |  330222    |  330129    |
|       from small pool |     464    |     557    |  307755    |  307291    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  637977    |  637420    |
|       from large pool |      93    |     178    |  330222    |  330129    |
|       from small pool |     464    |     557    |  307755    |  307291    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44496119022369385
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4859105348587036
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4437786638736725
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284643292427063
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5112730264663696
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36504316329956055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0017402172088623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47355973720550537
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  19992 GiB |  19985 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19915 GiB |  19908 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  19992 GiB |  19985 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19915 GiB |  19908 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  19992 GiB |  19985 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  19915 GiB |  19908 GiB |
|       from small pool |     13 MiB |     36 MiB |     76 GiB |     76 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  642041    |  641484    |
|       from large pool |      93    |     178    |  332173    |  332080    |
|       from small pool |     464    |     557    |  309868    |  309404    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  642041    |  641484    |
|       from large pool |      93    |     178    |  332173    |  332080    |
|       from small pool |     464    |     557    |  309868    |  309404    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32535889744758606
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4425390660762787
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3178510069847107
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.0886030197143555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5539808869361877
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4657462239265442
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35042551159858704
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20113 GiB |  20105 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20036 GiB |  20028 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20113 GiB |  20105 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20036 GiB |  20028 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20113 GiB |  20105 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20036 GiB |  20028 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  646082    |  645525    |
|       from large pool |      93    |     178    |  334116    |  334023    |
|       from small pool |     464    |     557    |  311966    |  311502    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  646082    |  645525    |
|       from large pool |      93    |     178    |  334116    |  334023    |
|       from small pool |     464    |     557    |  311966    |  311502    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.318915456533432
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6950581073760986
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34033575654029846
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5144366025924683
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3827149271965027
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4091763198375702
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20233 GiB |  20226 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20156 GiB |  20148 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20233 GiB |  20226 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20156 GiB |  20148 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20233 GiB |  20226 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20156 GiB |  20148 GiB |
|       from small pool |     13 MiB |     36 MiB |     77 GiB |     77 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  650100    |  649543    |
|       from large pool |      93    |     178    |  336060    |  335967    |
|       from small pool |     464    |     557    |  314040    |  313576    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  650100    |  649543    |
|       from large pool |      93    |     178    |  336060    |  335967    |
|       from small pool |     464    |     557    |  314040    |  313576    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.3682557344436646
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6217763423919678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.543980598449707
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35708898305892944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3252008557319641
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8107115626335144
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37360048294067383
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7553129196166992
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20354 GiB |  20346 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20276 GiB |  20268 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20354 GiB |  20346 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20276 GiB |  20268 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20354 GiB |  20346 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20276 GiB |  20268 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  654164    |  653607    |
|       from large pool |      93    |     178    |  338007    |  337914    |
|       from small pool |     464    |     557    |  316157    |  315693    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  654164    |  653607    |
|       from large pool |      93    |     178    |  338007    |  337914    |
|       from small pool |     464    |     557    |  316157    |  315693    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4545861482620239
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7977326512336731
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9332625269889832
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8923819065093994
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339046835899353
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4856336712837219
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3496454358100891
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20474 GiB |  20467 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20396 GiB |  20388 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20474 GiB |  20467 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20396 GiB |  20388 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20474 GiB |  20467 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20396 GiB |  20388 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  658205    |  657648    |
|       from large pool |      93    |     178    |  339950    |  339857    |
|       from small pool |     464    |     557    |  318255    |  317791    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  658205    |  657648    |
|       from large pool |      93    |     178    |  339950    |  339857    |
|       from small pool |     464    |     557    |  318255    |  317791    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5165325999259949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6721661686897278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5066771507263184
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41250136494636536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4908815622329712
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3487595319747925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3607846796512604
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20595 GiB |  20587 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20516 GiB |  20508 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20595 GiB |  20587 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20516 GiB |  20508 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20595 GiB |  20587 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20516 GiB |  20508 GiB |
|       from small pool |     13 MiB |     36 MiB |     78 GiB |     78 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  662246    |  661689    |
|       from large pool |      93    |     178    |  341893    |  341800    |
|       from small pool |     464    |     557    |  320353    |  319889    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  662246    |  661689    |
|       from large pool |      93    |     178    |  341893    |  341800    |
|       from small pool |     464    |     557    |  320353    |  319889    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8139474987983704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33619898557662964
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3233568072319031
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5422070026397705
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33855047821998596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3711854815483093
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20715 GiB |  20708 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20636 GiB |  20628 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20715 GiB |  20708 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20636 GiB |  20628 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20715 GiB |  20708 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20636 GiB |  20628 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  666264    |  665707    |
|       from large pool |      93    |     178    |  343830    |  343737    |
|       from small pool |     464    |     557    |  322434    |  321970    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  666264    |  665707    |
|       from large pool |      93    |     178    |  343830    |  343737    |
|       from small pool |     464    |     557    |  322434    |  321970    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.088186502456665
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5678302049636841
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.637929677963257
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46539825201034546
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31939923763275146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47557511925697327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46110841631889343
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20836 GiB |  20828 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20756 GiB |  20748 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20836 GiB |  20828 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20756 GiB |  20748 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20836 GiB |  20828 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20756 GiB |  20748 GiB |
|       from small pool |     13 MiB |     36 MiB |     79 GiB |     79 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  670305    |  669748    |
|       from large pool |      93    |     178    |  345778    |  345685    |
|       from small pool |     464    |     557    |  324527    |  324063    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  670305    |  669748    |
|       from large pool |      93    |     178    |  345778    |  345685    |
|       from small pool |     464    |     557    |  324527    |  324063    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3283836245536804
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35422033071517944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39511236548423767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35176724195480347
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4055427610874176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5598140954971313
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9668205976486206
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1445995569229126
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  20956 GiB |  20949 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20876 GiB |  20868 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  20956 GiB |  20949 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20876 GiB |  20868 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  20956 GiB |  20949 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20876 GiB |  20868 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  674369    |  673812    |
|       from large pool |      93    |     178    |  347724    |  347631    |
|       from small pool |     464    |     557    |  326645    |  326181    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  674369    |  673812    |
|       from large pool |      93    |     178    |  347724    |  347631    |
|       from small pool |     464    |     557    |  326645    |  326181    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3026847243309021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8137850761413574
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.6032146215438843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35565489530563354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.211021900177002
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43184077739715576
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  21077 GiB |  21069 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20996 GiB |  20988 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  21077 GiB |  21069 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20996 GiB |  20988 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  21077 GiB |  21069 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  20996 GiB |  20988 GiB |
|       from small pool |     13 MiB |     36 MiB |     80 GiB |     80 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  30274 MiB |  20320 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  30100 MiB |  20180 MiB |
|       from small pool |     34 MiB |     42 MiB |    174 MiB |    140 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  678387    |  677830    |
|       from large pool |      93    |     178    |  349668    |  349575    |
|       from small pool |     464    |     557    |  328719    |  328255    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  678387    |  677830    |
|       from large pool |      93    |     178    |  349668    |  349575    |
|       from small pool |     464    |     557    |  328719    |  328255    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5301486849784851
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  22110 GiB |  22104 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  22025 GiB |  22019 GiB |
|       from small pool |      9 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  22110 GiB |  22104 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  22025 GiB |  22019 GiB |
|       from small pool |      9 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  22110 GiB |  22104 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  22025 GiB |  22019 GiB |
|       from small pool |      8 MiB |     36 MiB |     84 GiB |     84 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  30282 MiB |  24468 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  30100 MiB |  24300 MiB |
|       from small pool |     14 MiB |     42 MiB |    182 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |  707378    |  706943    |
|       from large pool |      69    |     178    |  368253    |  368184    |
|       from small pool |     366    |     557    |  339125    |  338759    |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |  707378    |  706943    |
|       from large pool |      69    |     178    |  368253    |  368184    |
|       from small pool |     366    |     557    |  339125    |  338759    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.723175048828125
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.718856155872345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.028942108154297
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4304053783416748
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45900553464889526
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33748161792755127
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31310099363327026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2421724796295166
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22230 GiB |  22223 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22145 GiB |  22137 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22230 GiB |  22223 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22145 GiB |  22137 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22230 GiB |  22223 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22145 GiB |  22137 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  711442    |  710885    |
|       from large pool |      93    |     178    |  370198    |  370105    |
|       from small pool |     464    |     557    |  341244    |  340780    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  711442    |  710885    |
|       from large pool |      93    |     178    |  370198    |  370105    |
|       from small pool |     464    |     557    |  341244    |  340780    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8151156306266785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4519675076007843
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6022875308990479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38473716378211975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8026916980743408
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.287600040435791
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22351 GiB |  22343 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22265 GiB |  22257 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22351 GiB |  22343 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22265 GiB |  22257 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22351 GiB |  22343 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22265 GiB |  22257 GiB |
|       from small pool |     13 MiB |     36 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  715460    |  714903    |
|       from large pool |      93    |     178    |  372138    |  372045    |
|       from small pool |     464    |     557    |  343322    |  342858    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  715460    |  714903    |
|       from large pool |      93    |     178    |  372138    |  372045    |
|       from small pool |     464    |     557    |  343322    |  342858    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30573081970214844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.652103841304779
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3306933641433716
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5344435572624207
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38471439480781555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7849844098091125
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33515018224716187
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40964803099632263
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22471 GiB |  22464 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22385 GiB |  22377 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22471 GiB |  22464 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22385 GiB |  22377 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22471 GiB |  22464 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22385 GiB |  22377 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  719524    |  718967    |
|       from large pool |      93    |     178    |  374084    |  373991    |
|       from small pool |     464    |     557    |  345440    |  344976    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  719524    |  718967    |
|       from large pool |      93    |     178    |  374084    |  373991    |
|       from small pool |     464    |     557    |  345440    |  344976    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3287726640701294
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6621514558792114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0514967441558838
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5896925330162048
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36614593863487244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36037692427635193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2676422595977783
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22592 GiB |  22584 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22505 GiB |  22498 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22592 GiB |  22584 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22505 GiB |  22498 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22592 GiB |  22584 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22505 GiB |  22498 GiB |
|       from small pool |     13 MiB |     36 MiB |     86 GiB |     86 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  723565    |  723008    |
|       from large pool |      93    |     178    |  376031    |  375938    |
|       from small pool |     464    |     557    |  347534    |  347070    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  723565    |  723008    |
|       from large pool |      93    |     178    |  376031    |  375938    |
|       from small pool |     464    |     557    |  347534    |  347070    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3083057403564453
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41466179490089417
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7532024383544922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41358983516693115
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3455303907394409
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4698421061038971
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22712 GiB |  22705 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22625 GiB |  22618 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22712 GiB |  22705 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22625 GiB |  22618 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22712 GiB |  22705 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22625 GiB |  22618 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  727583    |  727026    |
|       from large pool |      93    |     178    |  377975    |  377882    |
|       from small pool |     464    |     557    |  349608    |  349144    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  727583    |  727026    |
|       from large pool |      93    |     178    |  377975    |  377882    |
|       from small pool |     464    |     557    |  349608    |  349144    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3146267831325531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3215275704860687
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5843149423599243
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3101251423358917
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.220048666000366
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22833 GiB |  22825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22745 GiB |  22738 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22833 GiB |  22825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22745 GiB |  22738 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22833 GiB |  22825 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22745 GiB |  22738 GiB |
|       from small pool |     13 MiB |     36 MiB |     87 GiB |     87 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  731578    |  731021    |
|       from large pool |      93    |     178    |  379915    |  379822    |
|       from small pool |     464    |     557    |  351663    |  351199    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  731578    |  731021    |
|       from large pool |      93    |     178    |  379915    |  379822    |
|       from small pool |     464    |     557    |  351663    |  351199    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7976096272468567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7521964311599731
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31254225969314575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5406280159950256
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36393192410469055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3654620349407196
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.636022686958313
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  22953 GiB |  22946 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22865 GiB |  22858 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  22953 GiB |  22946 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22865 GiB |  22858 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  22953 GiB |  22946 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22865 GiB |  22858 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  735619    |  735062    |
|       from large pool |      93    |     178    |  381863    |  381770    |
|       from small pool |     464    |     557    |  353756    |  353292    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  735619    |  735062    |
|       from large pool |      93    |     178    |  381863    |  381770    |
|       from small pool |     464    |     557    |  353756    |  353292    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3111319839954376
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3127814531326294
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5739250183105469
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.735058069229126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2600882053375244
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6824032664299011
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9979923367500305
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23074 GiB |  23066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22985 GiB |  22978 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23074 GiB |  23066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22985 GiB |  22978 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23074 GiB |  23066 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  22985 GiB |  22978 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  739660    |  739103    |
|       from large pool |      93    |     178    |  383802    |  383709    |
|       from small pool |     464    |     557    |  355858    |  355394    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  739660    |  739103    |
|       from large pool |      93    |     178    |  383802    |  383709    |
|       from small pool |     464    |     557    |  355858    |  355394    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3777829110622406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.826256513595581
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3405210077762604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.080611228942871
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2025891542434692
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23194 GiB |  23187 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23105 GiB |  23098 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23194 GiB |  23187 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23105 GiB |  23098 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23194 GiB |  23187 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23105 GiB |  23098 GiB |
|       from small pool |     13 MiB |     36 MiB |     88 GiB |     88 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  743655    |  743098    |
|       from large pool |      93    |     178    |  385741    |  385648    |
|       from small pool |     464    |     557    |  357914    |  357450    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  743655    |  743098    |
|       from large pool |      93    |     178    |  385741    |  385648    |
|       from small pool |     464    |     557    |  357914    |  357450    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6337785124778748
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9671251177787781
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3173796534538269
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4255298674106598
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9008482694625854
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.69732666015625
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33567777276039124
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23315 GiB |  23307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23225 GiB |  23218 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23315 GiB |  23307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23225 GiB |  23218 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23315 GiB |  23307 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23225 GiB |  23218 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |  747696    |  747139    |
|       from large pool |      93    |     178    |  387689    |  387596    |
|       from small pool |     464    |     557    |  360007    |  359543    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |  747696    |  747139    |
|       from large pool |      93    |     178    |  387689    |  387596    |
|       from small pool |     464    |     557    |  360007    |  359543    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27587974071502686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4161907136440277
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5964747071266174
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42475447058677673
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35216233134269714
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36862891912460327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42884722352027893
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23435 GiB |  23428 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23345 GiB |  23338 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23435 GiB |  23428 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23345 GiB |  23338 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23435 GiB |  23428 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23345 GiB |  23338 GiB |
|       from small pool |     13 MiB |     36 MiB |     89 GiB |     89 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     751 K  |     751 K  |
|       from large pool |      93    |     178    |     389 K  |     389 K  |
|       from small pool |     464    |     557    |     362 K  |     361 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     751 K  |     751 K  |
|       from large pool |      93    |     178    |     389 K  |     389 K  |
|       from small pool |     464    |     557    |     362 K  |     361 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.924312174320221
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1783323287963867
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34544917941093445
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3645091652870178
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3730444312095642
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3705114424228668
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6758893728256226
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41454723477363586
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23556 GiB |  23548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23465 GiB |  23458 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23556 GiB |  23548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23465 GiB |  23458 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23556 GiB |  23548 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23465 GiB |  23458 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     755 K  |     755 K  |
|       from large pool |      93    |     178    |     391 K  |     391 K  |
|       from small pool |     464    |     557    |     364 K  |     363 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     755 K  |     755 K  |
|       from large pool |      93    |     178    |     391 K  |     391 K  |
|       from small pool |     464    |     557    |     364 K  |     363 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4214242398738861
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4737102687358856
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4317299723625183
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3111536204814911
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49499887228012085
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35472050309181213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.961248755455017
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45868903398513794
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23676 GiB |  23669 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23585 GiB |  23578 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23676 GiB |  23669 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23585 GiB |  23578 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23676 GiB |  23669 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23585 GiB |  23578 GiB |
|       from small pool |     13 MiB |     36 MiB |     90 GiB |     90 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     759 K  |     759 K  |
|       from large pool |      93    |     178    |     393 K  |     393 K  |
|       from small pool |     464    |     557    |     366 K  |     365 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     759 K  |     759 K  |
|       from large pool |      93    |     178    |     393 K  |     393 K  |
|       from small pool |     464    |     557    |     366 K  |     365 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3169795572757721
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4208192527294159
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3132786750793457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.057366371154785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5287954807281494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4487692713737488
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33699437975883484
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23797 GiB |  23789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23705 GiB |  23698 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23797 GiB |  23789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23705 GiB |  23698 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23797 GiB |  23789 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23705 GiB |  23698 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     763 K  |     763 K  |
|       from large pool |      93    |     178    |     395 K  |     395 K  |
|       from small pool |     464    |     557    |     368 K  |     367 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     763 K  |     763 K  |
|       from large pool |      93    |     178    |     395 K  |     395 K  |
|       from small pool |     464    |     557    |     368 K  |     367 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3130371570587158
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6779537200927734
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3303520083427429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4945813715457916
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37621408700942993
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3988354504108429
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  23917 GiB |  23910 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23826 GiB |  23818 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  23917 GiB |  23910 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23826 GiB |  23818 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  23917 GiB |  23910 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23826 GiB |  23818 GiB |
|       from small pool |     13 MiB |     36 MiB |     91 GiB |     91 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     767 K  |     767 K  |
|       from large pool |      93    |     178    |     397 K  |     397 K  |
|       from small pool |     464    |     557    |     370 K  |     370 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     767 K  |     767 K  |
|       from large pool |      93    |     178    |     397 K  |     397 K  |
|       from small pool |     464    |     557    |     370 K  |     370 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.330076813697815
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.579289197921753
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.5126287937164307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3340296745300293
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3169589936733246
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7846478223800659
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3635338246822357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.725496232509613
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24038 GiB |  24030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23946 GiB |  23938 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24038 GiB |  24030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23946 GiB |  23938 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24038 GiB |  24030 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  23946 GiB |  23938 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     771 K  |     771 K  |
|       from large pool |      93    |     178    |     399 K  |     399 K  |
|       from small pool |     464    |     557    |     372 K  |     372 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     771 K  |     771 K  |
|       from large pool |      93    |     178    |     399 K  |     399 K  |
|       from small pool |     464    |     557    |     372 K  |     372 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44399502873420715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7699281573295593
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8696199655532837
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8602725863456726
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3302028179168701
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4687436521053314
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33963802456855774
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24158 GiB |  24151 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24066 GiB |  24058 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24158 GiB |  24151 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24066 GiB |  24058 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24158 GiB |  24151 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24066 GiB |  24058 GiB |
|       from small pool |     13 MiB |     36 MiB |     92 GiB |     92 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     776 K  |     775 K  |
|       from large pool |      93    |     178    |     401 K  |     401 K  |
|       from small pool |     464    |     557    |     374 K  |     374 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     776 K  |     775 K  |
|       from large pool |      93    |     178    |     401 K  |     401 K  |
|       from small pool |     464    |     557    |     374 K  |     374 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4965958893299103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6479334235191345
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48864591121673584
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39237332344055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47472578287124634
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33520302176475525
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3509271442890167
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24279 GiB |  24271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24186 GiB |  24178 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24279 GiB |  24271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24186 GiB |  24178 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24279 GiB |  24271 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24186 GiB |  24178 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     780 K  |     779 K  |
|       from large pool |      93    |     178    |     403 K  |     403 K  |
|       from small pool |     464    |     557    |     376 K  |     376 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     780 K  |     779 K  |
|       from large pool |      93    |     178    |     403 K  |     403 K  |
|       from small pool |     464    |     557    |     376 K  |     376 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8338758945465088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31649288535118103
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33143237233161926
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5244999527931213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324046790599823
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36128175258636475
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24399 GiB |  24392 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24306 GiB |  24298 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24399 GiB |  24392 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24306 GiB |  24298 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24399 GiB |  24392 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24306 GiB |  24298 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     784 K  |     783 K  |
|       from large pool |      93    |     178    |     405 K  |     405 K  |
|       from small pool |     464    |     557    |     378 K  |     378 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     784 K  |     783 K  |
|       from large pool |      93    |     178    |     405 K  |     405 K  |
|       from small pool |     464    |     557    |     378 K  |     378 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.0560989379882812
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.553006112575531
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.594550609588623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45530781149864197
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3091706931591034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647732377052307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43392854928970337
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24520 GiB |  24512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24426 GiB |  24418 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24520 GiB |  24512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24426 GiB |  24418 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24520 GiB |  24512 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24426 GiB |  24418 GiB |
|       from small pool |     13 MiB |     36 MiB |     93 GiB |     93 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     788 K  |     787 K  |
|       from large pool |      93    |     178    |     407 K  |     407 K  |
|       from small pool |     464    |     557    |     380 K  |     380 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     788 K  |     787 K  |
|       from large pool |      93    |     178    |     407 K  |     407 K  |
|       from small pool |     464    |     557    |     380 K  |     380 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.321036696434021
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34806233644485474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37958210706710815
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3358091115951538
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3980853259563446
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.526502251625061
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9276179671287537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1062926054000854
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24640 GiB |  24633 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24546 GiB |  24538 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24640 GiB |  24633 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24546 GiB |  24538 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24640 GiB |  24633 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24546 GiB |  24538 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     792 K  |     791 K  |
|       from large pool |      93    |     178    |     409 K  |     408 K  |
|       from small pool |     464    |     557    |     383 K  |     382 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     792 K  |     791 K  |
|       from large pool |      93    |     178    |     409 K  |     408 K  |
|       from small pool |     464    |     557    |     383 K  |     382 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2902069091796875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7763500809669495
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5605475902557373
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3448650538921356
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.180288791656494
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4129044711589813
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  24761 GiB |  24753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24666 GiB |  24658 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  24761 GiB |  24753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24666 GiB |  24658 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  24761 GiB |  24753 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  24666 GiB |  24658 GiB |
|       from small pool |     13 MiB |     36 MiB |     94 GiB |     94 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  34422 MiB |  24468 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  34220 MiB |  24300 MiB |
|       from small pool |     34 MiB |     42 MiB |    202 MiB |    168 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     796 K  |     795 K  |
|       from large pool |      93    |     178    |     411 K  |     410 K  |
|       from small pool |     464    |     557    |     385 K  |     384 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     796 K  |     795 K  |
|       from large pool |      93    |     178    |     411 K  |     410 K  |
|       from small pool |     464    |     557    |     385 K  |     384 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5026814937591553
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  25794 GiB |  25788 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25695 GiB |  25689 GiB |
|       from small pool |      9 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  25794 GiB |  25788 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25695 GiB |  25689 GiB |
|       from small pool |      9 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  25794 GiB |  25788 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  25695 GiB |  25689 GiB |
|       from small pool |      8 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  34430 MiB |  28616 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  34220 MiB |  28420 MiB |
|       from small pool |     14 MiB |     42 MiB |    210 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |     825 K  |     824 K  |
|       from large pool |      69    |     178    |     429 K  |     429 K  |
|       from small pool |     366    |     557    |     395 K  |     395 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |     825 K  |     824 K  |
|       from large pool |      69    |     178    |     429 K  |     429 K  |
|       from small pool |     366    |     557    |     395 K  |     395 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7098458409309387
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6970778703689575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.993215560913086
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.361167550086975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4433552026748657
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3333328068256378
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3102828562259674
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2063350677490234
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  25914 GiB |  25907 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25815 GiB |  25807 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  25914 GiB |  25907 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25815 GiB |  25807 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  25914 GiB |  25907 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25815 GiB |  25807 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     829 K  |     828 K  |
|       from large pool |      93    |     178    |     431 K  |     431 K  |
|       from small pool |     464    |     557    |     397 K  |     397 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     829 K  |     828 K  |
|       from large pool |      93    |     178    |     431 K  |     431 K  |
|       from small pool |     464    |     557    |     397 K  |     397 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8118047714233398
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4439007639884949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5893954634666443
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3698454797267914
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7727218866348267
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27374371886253357
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26035 GiB |  26027 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25935 GiB |  25927 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26035 GiB |  26027 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25935 GiB |  25927 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26035 GiB |  26027 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  25935 GiB |  25927 GiB |
|       from small pool |     13 MiB |     36 MiB |     99 GiB |     99 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     833 K  |     832 K  |
|       from large pool |      93    |     178    |     433 K  |     433 K  |
|       from small pool |     464    |     557    |     399 K  |     399 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     833 K  |     832 K  |
|       from large pool |      93    |     178    |     433 K  |     433 K  |
|       from small pool |     464    |     557    |     399 K  |     399 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2851434350013733
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6276633143424988
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3264438509941101
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5133658647537231
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37052497267723083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7600528001785278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.324270099401474
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39370864629745483
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26155 GiB |  26148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26055 GiB |  26047 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26155 GiB |  26148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26055 GiB |  26047 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26155 GiB |  26148 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26055 GiB |  26047 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     837 K  |     836 K  |
|       from large pool |      93    |     178    |     435 K  |     435 K  |
|       from small pool |     464    |     557    |     401 K  |     401 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     837 K  |     836 K  |
|       from large pool |      93    |     178    |     435 K  |     435 K  |
|       from small pool |     464    |     557    |     401 K  |     401 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3186584711074829
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6454132795333862
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0152084827423096
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.575340986251831
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3553259074687958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34137189388275146
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2435381412506104
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26276 GiB |  26268 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26175 GiB |  26168 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26276 GiB |  26268 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26175 GiB |  26168 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26276 GiB |  26268 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26175 GiB |  26168 GiB |
|       from small pool |     13 MiB |     36 MiB |    100 GiB |    100 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     841 K  |     840 K  |
|       from large pool |      93    |     178    |     437 K  |     437 K  |
|       from small pool |     464    |     557    |     403 K  |     403 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     841 K  |     840 K  |
|       from large pool |      93    |     178    |     437 K  |     437 K  |
|       from small pool |     464    |     557    |     403 K  |     403 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29306724667549133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4008773863315582
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.731844425201416
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4023657441139221
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3284552991390228
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45803284645080566
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26396 GiB |  26389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26295 GiB |  26288 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26396 GiB |  26389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26295 GiB |  26288 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26396 GiB |  26389 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26295 GiB |  26288 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     845 K  |     844 K  |
|       from large pool |      93    |     178    |     439 K  |     439 K  |
|       from small pool |     464    |     557    |     406 K  |     405 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     845 K  |     844 K  |
|       from large pool |      93    |     178    |     439 K  |     439 K  |
|       from small pool |     464    |     557    |     406 K  |     405 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30404379963874817
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31538671255111694
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5533117055892944
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3011203706264496
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1825239658355713
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26517 GiB |  26509 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26415 GiB |  26408 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26517 GiB |  26509 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26415 GiB |  26408 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26517 GiB |  26509 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26415 GiB |  26408 GiB |
|       from small pool |     13 MiB |     36 MiB |    101 GiB |    101 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     849 K  |     848 K  |
|       from large pool |      93    |     178    |     441 K  |     441 K  |
|       from small pool |     464    |     557    |     408 K  |     407 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     849 K  |     848 K  |
|       from large pool |      93    |     178    |     441 K  |     441 K  |
|       from small pool |     464    |     557    |     408 K  |     407 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7800406217575073
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7315957546234131
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29639318585395813
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5183584690093994
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3537620007991791
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3583802580833435
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6166451573371887
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26637 GiB |  26630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26535 GiB |  26528 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26637 GiB |  26630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26535 GiB |  26528 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26637 GiB |  26630 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26535 GiB |  26528 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     853 K  |     852 K  |
|       from large pool |      93    |     178    |     443 K  |     443 K  |
|       from small pool |     464    |     557    |     410 K  |     409 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     853 K  |     852 K  |
|       from large pool |      93    |     178    |     443 K  |     443 K  |
|       from small pool |     464    |     557    |     410 K  |     409 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2961908280849457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3096919357776642
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5434669256210327
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7250176072120667
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.2225394248962402
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6801353096961975
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.975432276725769
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26758 GiB |  26750 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26655 GiB |  26648 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26758 GiB |  26750 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26655 GiB |  26648 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26758 GiB |  26750 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26655 GiB |  26648 GiB |
|       from small pool |     13 MiB |     36 MiB |    102 GiB |    102 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     857 K  |     856 K  |
|       from large pool |      93    |     178    |     445 K  |     445 K  |
|       from small pool |     464    |     557    |     412 K  |     411 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     857 K  |     856 K  |
|       from large pool |      93    |     178    |     445 K  |     445 K  |
|       from small pool |     464    |     557    |     412 K  |     411 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36429905891418457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8020622134208679
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33765748143196106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.044615268707275
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.174917459487915
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26878 GiB |  26871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26775 GiB |  26768 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26878 GiB |  26871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26775 GiB |  26768 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26878 GiB |  26871 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26775 GiB |  26768 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     861 K  |     860 K  |
|       from large pool |      93    |     178    |     447 K  |     447 K  |
|       from small pool |     464    |     557    |     414 K  |     413 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     861 K  |     860 K  |
|       from large pool |      93    |     178    |     447 K  |     447 K  |
|       from small pool |     464    |     557    |     414 K  |     413 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6165820956230164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9317919611930847
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30421990156173706
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41483116149902344
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8679857850074768
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6773892045021057
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277986943721771
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  26999 GiB |  26991 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26895 GiB |  26888 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  26999 GiB |  26991 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26895 GiB |  26888 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  26999 GiB |  26991 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  26895 GiB |  26888 GiB |
|       from small pool |     13 MiB |     36 MiB |    103 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     865 K  |     864 K  |
|       from large pool |      93    |     178    |     449 K  |     448 K  |
|       from small pool |     464    |     557    |     416 K  |     416 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     865 K  |     864 K  |
|       from large pool |      93    |     178    |     449 K  |     448 K  |
|       from small pool |     464    |     557    |     416 K  |     416 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26407402753829956
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3954724073410034
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5719655156135559
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41636985540390015
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34038442373275757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35828423500061035
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4188620150089264
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27119 GiB |  27112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27015 GiB |  27008 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27119 GiB |  27112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27015 GiB |  27008 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27119 GiB |  27112 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27015 GiB |  27008 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    103 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     869 K  |     869 K  |
|       from large pool |      93    |     178    |     451 K  |     450 K  |
|       from small pool |     464    |     557    |     418 K  |     418 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     869 K  |     869 K  |
|       from large pool |      93    |     178    |     451 K  |     450 K  |
|       from small pool |     464    |     557    |     418 K  |     418 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9020735025405884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1499011516571045
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3417537212371826
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34626662731170654
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35472482442855835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35314419865608215
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6580479145050049
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3996224105358124
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27240 GiB |  27232 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27135 GiB |  27128 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27240 GiB |  27232 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27135 GiB |  27128 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27240 GiB |  27232 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27135 GiB |  27128 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     873 K  |     873 K  |
|       from large pool |      93    |     178    |     452 K  |     452 K  |
|       from small pool |     464    |     557    |     420 K  |     420 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     873 K  |     873 K  |
|       from large pool |      93    |     178    |     452 K  |     452 K  |
|       from small pool |     464    |     557    |     420 K  |     420 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4013262093067169
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46032166481018066
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42160987854003906
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2922847867012024
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.48536011576652527
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3375800549983978
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9268697500228882
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44759947061538696
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27360 GiB |  27353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27255 GiB |  27248 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27360 GiB |  27353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27255 GiB |  27248 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27360 GiB |  27353 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27255 GiB |  27248 GiB |
|       from small pool |     13 MiB |     36 MiB |    104 GiB |    104 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     877 K  |     877 K  |
|       from large pool |      93    |     178    |     454 K  |     454 K  |
|       from small pool |     464    |     557    |     422 K  |     422 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     877 K  |     877 K  |
|       from large pool |      93    |     178    |     454 K  |     454 K  |
|       from small pool |     464    |     557    |     422 K  |     422 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30262506008148193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.401305228471756
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3150266408920288
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.020753860473633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.509464681148529
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43568670749664307
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31719741225242615
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27481 GiB |  27473 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27375 GiB |  27368 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27481 GiB |  27473 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27375 GiB |  27368 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27481 GiB |  27473 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27375 GiB |  27368 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     881 K  |     881 K  |
|       from large pool |      93    |     178    |     456 K  |     456 K  |
|       from small pool |     464    |     557    |     424 K  |     424 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     881 K  |     881 K  |
|       from large pool |      93    |     178    |     456 K  |     456 K  |
|       from small pool |     464    |     557    |     424 K  |     424 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30639827251434326
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6550703048706055
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3199657201766968
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4804512858390808
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3688831031322479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3875214755535126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27601 GiB |  27594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27495 GiB |  27488 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27601 GiB |  27594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27495 GiB |  27488 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27601 GiB |  27594 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27495 GiB |  27488 GiB |
|       from small pool |     13 MiB |     36 MiB |    105 GiB |    105 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     885 K  |     885 K  |
|       from large pool |      93    |     178    |     458 K  |     458 K  |
|       from small pool |     464    |     557    |     426 K  |     426 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     885 K  |     885 K  |
|       from large pool |      93    |     178    |     458 K  |     458 K  |
|       from small pool |     464    |     557    |     426 K  |     426 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2929304838180542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.545644760131836
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4781038761138916
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30991798639297485
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3069058656692505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7484599947929382
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3521009385585785
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7055948972702026
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27722 GiB |  27714 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27616 GiB |  27608 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27722 GiB |  27714 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27616 GiB |  27608 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27722 GiB |  27714 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27616 GiB |  27608 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     889 K  |     889 K  |
|       from large pool |      93    |     178    |     460 K  |     460 K  |
|       from small pool |     464    |     557    |     429 K  |     428 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     889 K  |     889 K  |
|       from large pool |      93    |     178    |     460 K  |     460 K  |
|       from small pool |     464    |     557    |     429 K  |     428 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43298038840293884
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7503966093063354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8610623478889465
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8302368521690369
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3196645975112915
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45290619134902954
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3298962116241455
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27842 GiB |  27835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27736 GiB |  27728 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27842 GiB |  27835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27736 GiB |  27728 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27842 GiB |  27835 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27736 GiB |  27728 GiB |
|       from small pool |     13 MiB |     36 MiB |    106 GiB |    106 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     893 K  |     893 K  |
|       from large pool |      93    |     178    |     462 K  |     462 K  |
|       from small pool |     464    |     557    |     431 K  |     430 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     893 K  |     893 K  |
|       from large pool |      93    |     178    |     462 K  |     462 K  |
|       from small pool |     464    |     557    |     431 K  |     430 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4801141321659088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.632495105266571
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47458669543266296
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.374237596988678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4621663987636566
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31554439663887024
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34858933091163635
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  27963 GiB |  27955 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27856 GiB |  27848 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  27963 GiB |  27955 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27856 GiB |  27848 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  27963 GiB |  27955 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27856 GiB |  27848 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     897 K  |     897 K  |
|       from large pool |      93    |     178    |     464 K  |     464 K  |
|       from small pool |     464    |     557    |     433 K  |     432 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     897 K  |     897 K  |
|       from large pool |      93    |     178    |     464 K  |     464 K  |
|       from small pool |     464    |     557    |     433 K  |     432 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8112183809280396
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2961934208869934
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277743458747864
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.512164831161499
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30690136551856995
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35072124004364014
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28083 GiB |  28076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27976 GiB |  27968 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28083 GiB |  28076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27976 GiB |  27968 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28083 GiB |  28076 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  27976 GiB |  27968 GiB |
|       from small pool |     13 MiB |     36 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     901 K  |     901 K  |
|       from large pool |      93    |     178    |     466 K  |     466 K  |
|       from small pool |     464    |     557    |     435 K  |     434 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     901 K  |     901 K  |
|       from large pool |      93    |     178    |     466 K  |     466 K  |
|       from small pool |     464    |     557    |     435 K  |     434 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.020768642425537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5399312376976013
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5637624263763428
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44393324851989746
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2937313914299011
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4522640109062195
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.417385071516037
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28204 GiB |  28196 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28096 GiB |  28088 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28204 GiB |  28196 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28096 GiB |  28088 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28204 GiB |  28196 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28096 GiB |  28088 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     905 K  |     905 K  |
|       from large pool |      93    |     178    |     468 K  |     468 K  |
|       from small pool |     464    |     557    |     437 K  |     436 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     905 K  |     905 K  |
|       from large pool |      93    |     178    |     468 K  |     468 K  |
|       from small pool |     464    |     557    |     437 K  |     436 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3195478916168213
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3309571444988251
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3678264617919922
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32141485810279846
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3885186016559601
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4946769177913666
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8951320648193359
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.077818751335144
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28324 GiB |  28317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28216 GiB |  28208 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28324 GiB |  28317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28216 GiB |  28208 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28324 GiB |  28317 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28216 GiB |  28208 GiB |
|       from small pool |     13 MiB |     36 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     910 K  |     909 K  |
|       from large pool |      93    |     178    |     470 K  |     470 K  |
|       from small pool |     464    |     557    |     439 K  |     439 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     910 K  |     909 K  |
|       from large pool |      93    |     178    |     470 K  |     470 K  |
|       from small pool |     464    |     557    |     439 K  |     439 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2774108350276947
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.744400680065155
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5157862901687622
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33590614795684814
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.143923282623291
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3940907418727875
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  28445 GiB |  28437 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28336 GiB |  28328 GiB |
|       from small pool |     13 MiB |     36 MiB |    109 GiB |    109 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  28445 GiB |  28437 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28336 GiB |  28328 GiB |
|       from small pool |     13 MiB |     36 MiB |    109 GiB |    109 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  28445 GiB |  28437 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  28336 GiB |  28328 GiB |
|       from small pool |     13 MiB |     36 MiB |    109 GiB |    109 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  38570 MiB |  28616 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  38340 MiB |  28420 MiB |
|       from small pool |     34 MiB |     42 MiB |    230 MiB |    196 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     914 K  |     913 K  |
|       from large pool |      93    |     178    |     472 K  |     472 K  |
|       from small pool |     464    |     557    |     441 K  |     441 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     914 K  |     913 K  |
|       from large pool |      93    |     178    |     472 K  |     472 K  |
|       from small pool |     464    |     557    |     441 K  |     441 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4830005466938019
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  29478 GiB |  29472 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29365 GiB |  29359 GiB |
|       from small pool |      9 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  29478 GiB |  29472 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29365 GiB |  29359 GiB |
|       from small pool |      9 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  29478 GiB |  29472 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  29365 GiB |  29359 GiB |
|       from small pool |      8 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  38578 MiB |  32764 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  38340 MiB |  32540 MiB |
|       from small pool |     14 MiB |     42 MiB |    238 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |     943 K  |     942 K  |
|       from large pool |      69    |     178    |     490 K  |     490 K  |
|       from small pool |     366    |     557    |     452 K  |     451 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |     943 K  |     942 K  |
|       from large pool |      69    |     178    |     490 K  |     490 K  |
|       from small pool |     366    |     557    |     452 K  |     451 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7012327909469604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6768987774848938
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.959564447402954
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2730965614318848
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4245123267173767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32746371626853943
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30321088433265686
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1697438955307007
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29598 GiB |  29591 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29477 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29598 GiB |  29591 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29477 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29598 GiB |  29591 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29485 GiB |  29477 GiB |
|       from small pool |     13 MiB |     36 MiB |    113 GiB |    113 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     947 K  |     946 K  |
|       from large pool |      93    |     178    |     492 K  |     492 K  |
|       from small pool |     464    |     557    |     454 K  |     453 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     947 K  |     946 K  |
|       from large pool |      93    |     178    |     492 K  |     492 K  |
|       from small pool |     464    |     557    |     454 K  |     453 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7816647887229919
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4375529885292053
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5793851613998413
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36056557297706604
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.7435319423675537
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2636568248271942
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29719 GiB |  29711 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29605 GiB |  29597 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29719 GiB |  29711 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29605 GiB |  29597 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29719 GiB |  29711 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29605 GiB |  29597 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     951 K  |     950 K  |
|       from large pool |      93    |     178    |     494 K  |     494 K  |
|       from small pool |     464    |     557    |     456 K  |     455 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     951 K  |     950 K  |
|       from large pool |      93    |     178    |     494 K  |     494 K  |
|       from small pool |     464    |     557    |     456 K  |     455 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26824524998664856
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6041659712791443
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30960673093795776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4925594627857208
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3610459864139557
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7348750233650208
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31261447072029114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37968042492866516
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29839 GiB |  29832 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29725 GiB |  29717 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29839 GiB |  29832 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29725 GiB |  29717 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29839 GiB |  29832 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29725 GiB |  29717 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     955 K  |     954 K  |
|       from large pool |      93    |     178    |     496 K  |     496 K  |
|       from small pool |     464    |     557    |     458 K  |     457 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     955 K  |     954 K  |
|       from large pool |      93    |     178    |     496 K  |     496 K  |
|       from small pool |     464    |     557    |     458 K  |     457 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3064850866794586
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6322617530822754
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9828314185142517
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5660059452056885
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34321141242980957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3221050202846527
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2249256372451782
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  29960 GiB |  29952 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29845 GiB |  29837 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  29960 GiB |  29952 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29845 GiB |  29837 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  29960 GiB |  29952 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29845 GiB |  29837 GiB |
|       from small pool |     13 MiB |     36 MiB |    114 GiB |    114 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     959 K  |     958 K  |
|       from large pool |      93    |     178    |     498 K  |     498 K  |
|       from small pool |     464    |     557    |     460 K  |     459 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     959 K  |     958 K  |
|       from large pool |      93    |     178    |     498 K  |     498 K  |
|       from small pool |     464    |     557    |     460 K  |     459 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27635854482650757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39237332344055176
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.71439528465271
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3958813548088074
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3083411157131195
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44660109281539917
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30080 GiB |  30073 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29965 GiB |  29957 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30080 GiB |  30073 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29965 GiB |  29957 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30080 GiB |  30073 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  29965 GiB |  29957 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     963 K  |     962 K  |
|       from large pool |      93    |     178    |     500 K  |     500 K  |
|       from small pool |     464    |     557    |     462 K  |     462 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     963 K  |     962 K  |
|       from large pool |      93    |     178    |     500 K  |     500 K  |
|       from small pool |     464    |     557    |     462 K  |     462 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2972389757633209
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3084021806716919
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.530341625213623
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934279143810272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.146493673324585
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30201 GiB |  30193 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30085 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30201 GiB |  30193 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30085 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30201 GiB |  30193 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30085 GiB |  30078 GiB |
|       from small pool |     13 MiB |     36 MiB |    115 GiB |    115 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     967 K  |     966 K  |
|       from large pool |      93    |     178    |     502 K  |     502 K  |
|       from small pool |     464    |     557    |     464 K  |     464 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     967 K  |     966 K  |
|       from large pool |      93    |     178    |     502 K  |     502 K  |
|       from small pool |     464    |     557    |     464 K  |     464 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.767556369304657
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7163669466972351
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27946630120277405
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.49904075264930725
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3460235297679901
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3480775058269501
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5983378291130066
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30321 GiB |  30314 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30205 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30321 GiB |  30314 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30205 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30321 GiB |  30314 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30205 GiB |  30198 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     971 K  |     970 K  |
|       from large pool |      93    |     178    |     504 K  |     504 K  |
|       from small pool |     464    |     557    |     466 K  |     466 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     971 K  |     970 K  |
|       from large pool |      93    |     178    |     504 K  |     504 K  |
|       from small pool |     464    |     557    |     466 K  |     466 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27943864464759827
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2939455211162567
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5210046768188477
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7247592210769653
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.1832032203674316
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6760433912277222
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9549425840377808
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30442 GiB |  30434 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30325 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30442 GiB |  30434 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30325 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30442 GiB |  30434 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30325 GiB |  30318 GiB |
|       from small pool |     13 MiB |     36 MiB |    116 GiB |    116 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     975 K  |     974 K  |
|       from large pool |      93    |     178    |     506 K  |     506 K  |
|       from small pool |     464    |     557    |     468 K  |     468 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     975 K  |     974 K  |
|       from large pool |      93    |     178    |     506 K  |     506 K  |
|       from small pool |     464    |     557    |     468 K  |     468 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3498036563396454
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7805810570716858
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3302747905254364
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 4.007093906402588
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1479820013046265
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30562 GiB |  30555 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30445 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30562 GiB |  30555 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30445 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30562 GiB |  30555 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30445 GiB |  30438 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     979 K  |     978 K  |
|       from large pool |      93    |     178    |     508 K  |     508 K  |
|       from small pool |     464    |     557    |     470 K  |     470 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     979 K  |     978 K  |
|       from large pool |      93    |     178    |     508 K  |     508 K  |
|       from small pool |     464    |     557    |     470 K  |     470 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5999115705490112
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9031261205673218
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2931276857852936
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4080217480659485
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8418792486190796
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6597893238067627
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32146796584129333
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30683 GiB |  30675 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30565 GiB |  30558 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30683 GiB |  30675 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30565 GiB |  30558 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30683 GiB |  30675 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30565 GiB |  30558 GiB |
|       from small pool |     13 MiB |     36 MiB |    117 GiB |    117 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     983 K  |     982 K  |
|       from large pool |      93    |     178    |     510 K  |     510 K  |
|       from small pool |     464    |     557    |     472 K  |     472 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     983 K  |     982 K  |
|       from large pool |      93    |     178    |     510 K  |     510 K  |
|       from small pool |     464    |     557    |     472 K  |     472 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.24960766732692719
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3697932958602905
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5459722876548767
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4065341055393219
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3288898468017578
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3475848436355591
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40844011306762695
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30803 GiB |  30796 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30685 GiB |  30678 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30803 GiB |  30796 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30685 GiB |  30678 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30803 GiB |  30796 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30685 GiB |  30678 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     987 K  |     986 K  |
|       from large pool |      93    |     178    |     512 K  |     512 K  |
|       from small pool |     464    |     557    |     475 K  |     474 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     987 K  |     986 K  |
|       from large pool |      93    |     178    |     512 K  |     512 K  |
|       from small pool |     464    |     557    |     475 K  |     474 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.880405843257904
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.121046543121338
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3334875702857971
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32480448484420776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33540695905685425
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33273300528526306
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6428158283233643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38700729608535767
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  30924 GiB |  30916 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30805 GiB |  30798 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  30924 GiB |  30916 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30805 GiB |  30798 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  30924 GiB |  30916 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30805 GiB |  30798 GiB |
|       from small pool |     13 MiB |     36 MiB |    118 GiB |    118 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     991 K  |     990 K  |
|       from large pool |      93    |     178    |     514 K  |     514 K  |
|       from small pool |     464    |     557    |     477 K  |     476 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     991 K  |     990 K  |
|       from large pool |      93    |     178    |     514 K  |     514 K  |
|       from small pool |     464    |     557    |     477 K  |     476 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38971251249313354
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44530007243156433
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4129522740840912
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27337580919265747
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47931110858917236
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31752562522888184
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8990013599395752
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43906450271606445
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31044 GiB |  31037 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30925 GiB |  30918 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31044 GiB |  31037 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30925 GiB |  30918 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31044 GiB |  31037 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  30925 GiB |  30918 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     995 K  |     994 K  |
|       from large pool |      93    |     178    |     516 K  |     516 K  |
|       from small pool |     464    |     557    |     479 K  |     478 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     995 K  |     994 K  |
|       from large pool |      93    |     178    |     516 K  |     516 K  |
|       from small pool |     464    |     557    |     479 K  |     478 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2859288454055786
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3845539391040802
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31036514043807983
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.982544422149658
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4932782053947449
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4250364303588867
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2966454029083252
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31165 GiB |  31158 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31045 GiB |  31038 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31165 GiB |  31158 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31045 GiB |  31038 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31165 GiB |  31157 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31045 GiB |  31038 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |     999 K  |     998 K  |
|       from large pool |      93    |     178    |     518 K  |     518 K  |
|       from small pool |     464    |     557    |     481 K  |     480 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |     999 K  |     998 K  |
|       from large pool |      93    |     178    |     518 K  |     518 K  |
|       from small pool |     464    |     557    |     481 K  |     480 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2986525893211365
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6313495635986328
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30833685398101807
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46955808997154236
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3583366572856903
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37499508261680603
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31285 GiB |  31278 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31165 GiB |  31158 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31285 GiB |  31278 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31165 GiB |  31158 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31285 GiB |  31278 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31165 GiB |  31158 GiB |
|       from small pool |     13 MiB |     36 MiB |    119 GiB |    119 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1003 K  |    1003 K  |
|       from large pool |      93    |     178    |     520 K  |     520 K  |
|       from small pool |     464    |     557    |     483 K  |     482 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1003 K  |    1003 K  |
|       from large pool |      93    |     178    |     520 K  |     520 K  |
|       from small pool |     464    |     557    |     483 K  |     482 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2596176862716675
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.518908977508545
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4426724910736084
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2881893217563629
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29457002878189087
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7104032635688782
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33935871720314026
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6920673847198486
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31406 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31285 GiB |  31278 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31406 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31285 GiB |  31278 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31406 GiB |  31399 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31285 GiB |  31278 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1007 K  |    1007 K  |
|       from large pool |      93    |     178    |     522 K  |     522 K  |
|       from small pool |     464    |     557    |     485 K  |     485 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1007 K  |    1007 K  |
|       from large pool |      93    |     178    |     522 K  |     522 K  |
|       from small pool |     464    |     557    |     485 K  |     485 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.42006558179855347
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7361637949943542
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8761228919029236
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8045116066932678
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30721744894981384
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4349144697189331
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32019585371017456
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31526 GiB |  31519 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31398 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31526 GiB |  31519 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31398 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31526 GiB |  31519 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31406 GiB |  31398 GiB |
|       from small pool |     13 MiB |     36 MiB |    120 GiB |    120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1011 K  |    1011 K  |
|       from large pool |      93    |     178    |     524 K  |     523 K  |
|       from small pool |     464    |     557    |     487 K  |     487 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1011 K  |    1011 K  |
|       from large pool |      93    |     178    |     524 K  |     523 K  |
|       from small pool |     464    |     557    |     487 K  |     487 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4647907316684723
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6221219301223755
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46378180384635925
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3581021726131439
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4509026110172272
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29534807801246643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3429086208343506
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31647 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31518 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31647 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31518 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31647 GiB |  31640 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31526 GiB |  31518 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1015 K  |    1015 K  |
|       from large pool |      93    |     178    |     525 K  |     525 K  |
|       from small pool |     464    |     557    |     489 K  |     489 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1015 K  |    1015 K  |
|       from large pool |      93    |     178    |     525 K  |     525 K  |
|       from small pool |     464    |     557    |     489 K  |     489 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7649170160293579
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2788582742214203
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3115488588809967
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5022445917129517
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2896858751773834
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339032381772995
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31767 GiB |  31760 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31638 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31767 GiB |  31760 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31638 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31767 GiB |  31760 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31646 GiB |  31638 GiB |
|       from small pool |     13 MiB |     36 MiB |    121 GiB |    121 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1019 K  |    1019 K  |
|       from large pool |      93    |     178    |     527 K  |     527 K  |
|       from small pool |     464    |     557    |     491 K  |     491 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1019 K  |    1019 K  |
|       from large pool |      93    |     178    |     527 K  |     527 K  |
|       from small pool |     464    |     557    |     491 K  |     491 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.9852867126464844
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5266013741493225
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5412187576293945
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43140870332717896
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2765684127807617
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43842560052871704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40749555826187134
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  31888 GiB |  31881 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31758 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  31888 GiB |  31881 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31758 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  31888 GiB |  31880 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31766 GiB |  31758 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1023 K  |    1023 K  |
|       from large pool |      93    |     178    |     529 K  |     529 K  |
|       from small pool |     464    |     557    |     493 K  |     493 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1023 K  |    1023 K  |
|       from large pool |      93    |     178    |     529 K  |     529 K  |
|       from small pool |     464    |     557    |     493 K  |     493 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31202223896980286
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30966389179229736
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3586636781692505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3084482252597809
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3757885694503784
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.46557512879371643
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8691501021385193
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.056811809539795
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  32008 GiB |  32001 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31886 GiB |  31878 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  32008 GiB |  32001 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31886 GiB |  31878 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  32008 GiB |  32001 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  31886 GiB |  31878 GiB |
|       from small pool |     13 MiB |     36 MiB |    122 GiB |    122 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1027 K  |    1027 K  |
|       from large pool |      93    |     178    |     531 K  |     531 K  |
|       from small pool |     464    |     557    |     496 K  |     495 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1027 K  |    1027 K  |
|       from large pool |      93    |     178    |     531 K  |     531 K  |
|       from small pool |     464    |     557    |     496 K  |     495 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26584452390670776
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.719364583492279
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.472780466079712
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3277837634086609
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.1056928634643555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3768501877784729
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  32129 GiB |  32122 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  32006 GiB |  31998 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  32129 GiB |  32122 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  32006 GiB |  31998 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  32129 GiB |  32122 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  32006 GiB |  31998 GiB |
|       from small pool |     13 MiB |     36 MiB |    123 GiB |    123 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  42718 MiB |  32764 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  42460 MiB |  32540 MiB |
|       from small pool |     34 MiB |     42 MiB |    258 MiB |    224 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1031 K  |    1031 K  |
|       from large pool |      93    |     178    |     533 K  |     533 K  |
|       from small pool |     464    |     557    |     498 K  |     497 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1031 K  |    1031 K  |
|       from large pool |      93    |     178    |     533 K  |     533 K  |
|       from small pool |     464    |     557    |     498 K  |     497 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4697430729866028
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([8, 21, 1, 360, 360])
0
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5696 MiB |   9627 MiB |  33162 GiB |  33156 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  33035 GiB |  33029 GiB |
|       from small pool |      9 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5696 MiB |   9627 MiB |  33162 GiB |  33156 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  33035 GiB |  33029 GiB |
|       from small pool |      9 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5696 MiB |   9627 MiB |  33162 GiB |  33156 GiB |
|       from large pool |   5687 MiB |   9606 MiB |  33035 GiB |  33029 GiB |
|       from small pool |      8 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5814 MiB |   9962 MiB |  42726 MiB |  36912 MiB |
|       from large pool |   5800 MiB |   9920 MiB |  42460 MiB |  36660 MiB |
|       from small pool |     14 MiB |     42 MiB |    266 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     435    |     688    |    1060 K  |    1060 K  |
|       from large pool |      69    |     178    |     552 K  |     552 K  |
|       from small pool |     366    |     557    |     508 K  |     508 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     435    |     688    |    1060 K  |    1060 K  |
|       from large pool |      69    |     178    |     552 K  |     552 K  |
|       from small pool |     366    |     557    |     508 K  |     508 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.693540632724762
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6579349637031555
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.928483247756958
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1928136348724365
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40681248903274536
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3173936903476715
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2905552089214325
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.136673092842102
1
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33282 GiB |  33275 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33155 GiB |  33147 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33282 GiB |  33275 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33155 GiB |  33147 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33282 GiB |  33275 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33155 GiB |  33147 GiB |
|       from small pool |     13 MiB |     36 MiB |    127 GiB |    127 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1064 K  |    1064 K  |
|       from large pool |      93    |     178    |     554 K  |     554 K  |
|       from small pool |     464    |     557    |     510 K  |     510 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1064 K  |    1064 K  |
|       from large pool |      93    |     178    |     554 K  |     554 K  |
|       from small pool |     464    |     557    |     510 K  |     510 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7322322130203247
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4317569434642792
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5698574185371399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3535853922367096
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.717613935470581
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25894397497177124
2
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33403 GiB |  33396 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33275 GiB |  33267 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33403 GiB |  33396 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33275 GiB |  33267 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33403 GiB |  33395 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33275 GiB |  33267 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1068 K  |    1068 K  |
|       from large pool |      93    |     178    |     556 K  |     556 K  |
|       from small pool |     464    |     557    |     512 K  |     512 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1068 K  |    1068 K  |
|       from large pool |      93    |     178    |     556 K  |     556 K  |
|       from small pool |     464    |     557    |     512 K  |     512 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2580583393573761
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5890412330627441
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29087549448013306
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47456738352775574
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35363325476646423
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7146875262260437
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30186089873313904
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3687035143375397
3
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33523 GiB |  33516 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33395 GiB |  33387 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33523 GiB |  33516 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33395 GiB |  33387 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33523 GiB |  33516 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33395 GiB |  33387 GiB |
|       from small pool |     13 MiB |     36 MiB |    128 GiB |    128 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1072 K  |    1072 K  |
|       from large pool |      93    |     178    |     558 K  |     558 K  |
|       from small pool |     464    |     557    |     514 K  |     514 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1072 K  |    1072 K  |
|       from large pool |      93    |     178    |     558 K  |     558 K  |
|       from small pool |     464    |     557    |     514 K  |     514 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29473981261253357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6211012005805969
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9554638862609863
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5585214495658875
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3318652808666229
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30660611391067505
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2095849514007568
4
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33644 GiB |  33637 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33515 GiB |  33507 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33644 GiB |  33637 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33515 GiB |  33507 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33644 GiB |  33637 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33515 GiB |  33507 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1077 K  |    1076 K  |
|       from large pool |      93    |     178    |     560 K  |     560 K  |
|       from small pool |     464    |     557    |     516 K  |     516 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1077 K  |    1076 K  |
|       from large pool |      93    |     178    |     560 K  |     560 K  |
|       from small pool |     464    |     557    |     516 K  |     516 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26302003860473633
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3856435716152191
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7001263499259949
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39076924324035645
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2909272015094757
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4353330731391907
5
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33764 GiB |  33757 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33635 GiB |  33627 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33764 GiB |  33757 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33635 GiB |  33627 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33764 GiB |  33757 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33635 GiB |  33627 GiB |
|       from small pool |     13 MiB |     36 MiB |    129 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1081 K  |    1080 K  |
|       from large pool |      93    |     178    |     562 K  |     561 K  |
|       from small pool |     464    |     557    |     518 K  |     518 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1081 K  |    1080 K  |
|       from large pool |      93    |     178    |     562 K  |     561 K  |
|       from small pool |     464    |     557    |     518 K  |     518 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934657633304596
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3020230829715729
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5108436346054077
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28752565383911133
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.1144323348999023
6
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  33885 GiB |  33878 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33755 GiB |  33747 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  33885 GiB |  33878 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33755 GiB |  33747 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  33885 GiB |  33877 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33755 GiB |  33747 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    129 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1085 K  |    1084 K  |
|       from large pool |      93    |     178    |     564 K  |     563 K  |
|       from small pool |     464    |     557    |     521 K  |     520 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1085 K  |    1084 K  |
|       from large pool |      93    |     178    |     564 K  |     563 K  |
|       from small pool |     464    |     557    |     521 K  |     520 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7548717856407166
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7015661597251892
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2655992805957794
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4824598729610443
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.339358389377594
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3373473882675171
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5819714665412903
7
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34005 GiB |  33998 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33875 GiB |  33868 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34005 GiB |  33998 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33875 GiB |  33868 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34005 GiB |  33998 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33875 GiB |  33868 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1089 K  |    1088 K  |
|       from large pool |      93    |     178    |     565 K  |     565 K  |
|       from small pool |     464    |     557    |     523 K  |     522 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1089 K  |    1088 K  |
|       from large pool |      93    |     178    |     565 K  |     565 K  |
|       from small pool |     464    |     557    |     523 K  |     522 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2661121189594269
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27563580870628357
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.5024704933166504
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7264050841331482
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.1469216346740723
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6701516509056091
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.9373541474342346
8
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34126 GiB |  34119 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33995 GiB |  33988 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34126 GiB |  34119 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33995 GiB |  33988 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34126 GiB |  34118 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  33995 GiB |  33988 GiB |
|       from small pool |     13 MiB |     36 MiB |    130 GiB |    130 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1093 K  |    1092 K  |
|       from large pool |      93    |     178    |     567 K  |     567 K  |
|       from small pool |     464    |     557    |     525 K  |     524 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1093 K  |    1092 K  |
|       from large pool |      93    |     178    |     567 K  |     567 K  |
|       from small pool |     464    |     557    |     525 K  |     524 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.33666372299194336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7623443603515625
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3192974925041199
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.9725024700164795
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.1234350204467773
9
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34246 GiB |  34239 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34115 GiB |  34108 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34246 GiB |  34239 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34115 GiB |  34108 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34246 GiB |  34239 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34115 GiB |  34108 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1097 K  |    1096 K  |
|       from large pool |      93    |     178    |     569 K  |     569 K  |
|       from small pool |     464    |     557    |     527 K  |     526 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1097 K  |    1096 K  |
|       from large pool |      93    |     178    |     569 K  |     569 K  |
|       from small pool |     464    |     557    |     527 K  |     526 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5868390202522278
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8784924745559692
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28700289130210876
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40265190601348877
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.818615734577179
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6450898051261902
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31625646352767944
10
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34367 GiB |  34360 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34235 GiB |  34228 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34367 GiB |  34360 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34235 GiB |  34228 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34367 GiB |  34359 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34235 GiB |  34228 GiB |
|       from small pool |     13 MiB |     36 MiB |    131 GiB |    131 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1101 K  |    1100 K  |
|       from large pool |      93    |     178    |     571 K  |     571 K  |
|       from small pool |     464    |     557    |     529 K  |     528 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1101 K  |    1100 K  |
|       from large pool |      93    |     178    |     571 K  |     571 K  |
|       from small pool |     464    |     557    |     529 K  |     528 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.23847685754299164
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.34598883986473083
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5259736776351929
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3959523141384125
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31735894083976746
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3372364044189453
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3983061611652374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
11
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34488 GiB |  34480 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34355 GiB |  34348 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34488 GiB |  34480 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34355 GiB |  34348 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34487 GiB |  34480 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34355 GiB |  34348 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1105 K  |    1104 K  |
|       from large pool |      93    |     178    |     573 K  |     573 K  |
|       from small pool |     464    |     557    |     531 K  |     531 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1105 K  |    1104 K  |
|       from large pool |      93    |     178    |     573 K  |     573 K  |
|       from small pool |     464    |     557    |     531 K  |     531 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8612839579582214
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.0949510335922241
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32029056549072266
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3059912919998169
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31798598170280457
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3149357736110687
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6279577016830444
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37705492973327637
12
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34608 GiB |  34601 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34475 GiB |  34468 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34608 GiB |  34601 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34475 GiB |  34468 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34608 GiB |  34601 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34475 GiB |  34468 GiB |
|       from small pool |     13 MiB |     36 MiB |    132 GiB |    132 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1109 K  |    1108 K  |
|       from large pool |      93    |     178    |     575 K  |     575 K  |
|       from small pool |     464    |     557    |     533 K  |     533 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1109 K  |    1108 K  |
|       from large pool |      93    |     178    |     575 K  |     575 K  |
|       from small pool |     464    |     557    |     533 K  |     533 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.38158321380615234
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4312494099140167
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40601539611816406
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25878503918647766
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.47405463457107544
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.30011799931526184
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.8759403228759766
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.43228986859321594
13
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34729 GiB |  34721 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34595 GiB |  34588 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34729 GiB |  34721 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34595 GiB |  34588 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34729 GiB |  34721 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34595 GiB |  34588 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1113 K  |    1112 K  |
|       from large pool |      93    |     178    |     577 K  |     577 K  |
|       from small pool |     464    |     557    |     535 K  |     535 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1113 K  |    1112 K  |
|       from large pool |      93    |     178    |     577 K  |     577 K  |
|       from small pool |     464    |     557    |     535 K  |     535 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.27250176668167114
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.37063175439834595
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29902151226997375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.947033166885376
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.478669673204422
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41550976037979126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2823288142681122
14
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34849 GiB |  34842 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34715 GiB |  34708 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34849 GiB |  34842 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34715 GiB |  34708 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34849 GiB |  34842 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34715 GiB |  34708 GiB |
|       from small pool |     13 MiB |     36 MiB |    133 GiB |    133 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1117 K  |    1116 K  |
|       from large pool |      93    |     178    |     579 K  |     579 K  |
|       from small pool |     464    |     557    |     537 K  |     537 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1117 K  |    1116 K  |
|       from large pool |      93    |     178    |     579 K  |     579 K  |
|       from small pool |     464    |     557    |     537 K  |     537 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2913677394390106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6122833490371704
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29741814732551575
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45951148867607117
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3470873236656189
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36318981647491455
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
15
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  34970 GiB |  34962 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34835 GiB |  34828 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  34970 GiB |  34962 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34835 GiB |  34828 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  34970 GiB |  34962 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34835 GiB |  34828 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1121 K  |    1120 K  |
|       from large pool |      93    |     178    |     581 K  |     581 K  |
|       from small pool |     464    |     557    |     539 K  |     539 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1121 K  |    1120 K  |
|       from large pool |      93    |     178    |     581 K  |     581 K  |
|       from small pool |     464    |     557    |     539 K  |     539 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.2315360307693481
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4951473474502563
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 3.4098076820373535
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2728656232357025
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.28271758556365967
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6820204257965088
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.32747241854667664
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6805041432380676
16
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35090 GiB |  35083 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34955 GiB |  34948 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35090 GiB |  35083 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34955 GiB |  34948 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35090 GiB |  35083 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  34955 GiB |  34948 GiB |
|       from small pool |     13 MiB |     36 MiB |    134 GiB |    134 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1125 K  |    1124 K  |
|       from large pool |      93    |     178    |     583 K  |     583 K  |
|       from small pool |     464    |     557    |     541 K  |     541 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1125 K  |    1124 K  |
|       from large pool |      93    |     178    |     583 K  |     583 K  |
|       from small pool |     464    |     557    |     541 K  |     541 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.40764039754867554
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7225446701049805
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.8893114328384399
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.7829195261001587
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29536300897598267
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.41791871190071106
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.31172215938568115
17
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35211 GiB |  35203 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35075 GiB |  35068 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35211 GiB |  35203 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35075 GiB |  35068 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35211 GiB |  35203 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35075 GiB |  35068 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1129 K  |    1128 K  |
|       from large pool |      93    |     178    |     585 K  |     585 K  |
|       from small pool |     464    |     557    |     544 K  |     543 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1129 K  |    1128 K  |
|       from large pool |      93    |     178    |     585 K  |     585 K  |
|       from small pool |     464    |     557    |     544 K  |     543 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4493716061115265
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.6113709807395935
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45497411489486694
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3454032242298126
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4403054714202881
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2816068232059479
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3324041962623596
18
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35331 GiB |  35324 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35196 GiB |  35188 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35331 GiB |  35324 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35196 GiB |  35188 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35331 GiB |  35324 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35196 GiB |  35188 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1133 K  |    1132 K  |
|       from large pool |      93    |     178    |     587 K  |     587 K  |
|       from small pool |     464    |     557    |     546 K  |     545 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1133 K  |    1132 K  |
|       from large pool |      93    |     178    |     587 K  |     587 K  |
|       from small pool |     464    |     557    |     546 K  |     545 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.711246907711029
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.26826685667037964
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2934325337409973
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4922246038913727
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2767014801502228
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3281143307685852
19
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35452 GiB |  35444 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35316 GiB |  35308 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35452 GiB |  35444 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35316 GiB |  35308 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35451 GiB |  35444 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35316 GiB |  35308 GiB |
|       from small pool |     13 MiB |     36 MiB |    135 GiB |    135 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1137 K  |    1137 K  |
|       from large pool |      93    |     178    |     589 K  |     589 K  |
|       from small pool |     464    |     557    |     548 K  |     547 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1137 K  |    1137 K  |
|       from large pool |      93    |     178    |     589 K  |     589 K  |
|       from small pool |     464    |     557    |     548 K  |     547 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.952993392944336
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.5135407447814941
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 2.5215725898742676
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4196229577064514
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.2626209855079651
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.4253860414028168
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.39951568841934204
20
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35572 GiB |  35565 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35436 GiB |  35428 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35572 GiB |  35565 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35436 GiB |  35428 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35572 GiB |  35565 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35436 GiB |  35428 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1141 K  |    1141 K  |
|       from large pool |      93    |     178    |     591 K  |     591 K  |
|       from small pool |     464    |     557    |     550 K  |     549 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1141 K  |    1141 K  |
|       from large pool |      93    |     178    |     591 K  |     591 K  |
|       from small pool |     464    |     557    |     550 K  |     549 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29863911867141724
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29291844367980957
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.35073089599609375
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.29881617426872253
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.36321255564689636
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.44291359186172485
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.846362829208374
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.039322853088379
21
input size 87091248
target size 4147248
mask size 1036848
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35693 GiB |  35685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35556 GiB |  35548 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35693 GiB |  35685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35556 GiB |  35548 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35693 GiB |  35685 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35556 GiB |  35548 GiB |
|       from small pool |     13 MiB |     36 MiB |    136 GiB |    136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1145 K  |    1145 K  |
|       from large pool |      93    |     178    |     593 K  |     593 K  |
|       from small pool |     464    |     557    |     552 K  |     552 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1145 K  |    1145 K  |
|       from large pool |      93    |     178    |     593 K  |     593 K  |
|       from small pool |     464    |     557    |     552 K  |     552 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.25906282663345337
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.698800802230835
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 1.4358466863632202
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3205110430717468
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 5.070176601409912
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.3621932864189148
22
input size 10886448
target size 518448
mask size 129648
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7606 MiB |   9627 MiB |  35813 GiB |  35806 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35676 GiB |  35668 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7606 MiB |   9627 MiB |  35813 GiB |  35806 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35676 GiB |  35668 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7606 MiB |   9627 MiB |  35813 GiB |  35806 GiB |
|       from large pool |   7593 MiB |   9606 MiB |  35676 GiB |  35668 GiB |
|       from small pool |     13 MiB |     36 MiB |    137 GiB |    137 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   9954 MiB |   9962 MiB |  46866 MiB |  36912 MiB |
|       from large pool |   9920 MiB |   9920 MiB |  46580 MiB |  36660 MiB |
|       from small pool |     34 MiB |     42 MiB |    286 MiB |    252 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     688    |    1149 K  |    1149 K  |
|       from large pool |      93    |     178    |     595 K  |     595 K  |
|       from small pool |     464    |     557    |     554 K  |     554 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     688    |    1149 K  |    1149 K  |
|       from large pool |      93    |     178    |     595 K  |     595 K  |
|       from small pool |     464    |     557    |     554 K  |     554 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

input sub size 10886448
target sub size 518448
mask sub size 129648
train loss item: 0.45830103754997253
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
input sub size 48
target sub size 48
mask sub size 48
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 8 360 done at Thu Nov 14 11:46:31 CET 2024
UNet6 with 1 10 0.0001 32 360 start at Thu Nov 14 11:46:31 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 32
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Epoch 1/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.819812536239624
train loss item: 0.9529114365577698
train loss item: 2.3863213062286377
train loss item: 2.270076036453247
train loss item: 0.6869325637817383
train loss item: 0.46848130226135254
train loss item: 0.5421428680419922
train loss item: 1.5739983320236206
train loss item: 1.2186293601989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5850042104721069
train loss item: 0.7131848931312561
train loss item: 0.5979920029640198
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.130446195602417
train loss item: 0.47118911147117615
train loss item: 0.5719398856163025
train loss item: 1.110304594039917
train loss item: 0.48696455359458923
train loss item: 0.7697487473487854
train loss item: 0.5989560484886169
train loss item: 1.0078785419464111
train loss item: 0.47610917687416077
train loss item: 0.6136468648910522
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4699391722679138
train loss item: 0.8132690191268921
train loss item: 1.3295847177505493
train loss item: 0.6827605366706848
train loss item: 0.4973190426826477
train loss item: 0.585635781288147
train loss item: 1.51414155960083
1
train loss item: 0.45469796657562256
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.624519407749176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9587867259979248
train loss item: 0.6278560161590576
train loss item: 0.49461838603019714
train loss item: 0.7044584155082703
train loss item: 0.5164517164230347
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4544129967689514
train loss item: 1.86475670337677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47753116488456726
train loss item: 2.5423285961151123
train loss item: 1.0763672590255737
train loss item: 1.039473056793213
train loss item: 0.5298306345939636
train loss item: 0.7522132992744446
train loss item: 0.5095365643501282
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48460251092910767
train loss item: 0.8418570160865784
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4620964825153351
train loss item: 0.47385135293006897
train loss item: 1.827709436416626
train loss item: 1.2050328254699707
train loss item: 3.6952083110809326
train loss item: 1.031891942024231
train loss item: 1.2293715476989746
2
train loss item: 0.49924877285957336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0482702255249023
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5716233253479004
train loss item: 4.473301887512207
train loss item: 1.4562150239944458
train loss item: 0.7648544311523438
train loss item: 1.2041324377059937
train loss item: 0.47707146406173706
train loss item: 0.630420446395874
train loss item: 1.144110083580017
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8894302248954773
train loss item: 0.44735756516456604
train loss item: 0.5024728775024414
train loss item: 0.5545372366905212
train loss item: 0.7979448437690735
train loss item: 0.5833857655525208
train loss item: 0.5818025469779968
train loss item: 0.5606418251991272
train loss item: 0.5785847902297974
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.1468136310577393
train loss item: 1.450875163078308
train loss item: 0.6367223858833313
train loss item: 0.5154714584350586
train loss item: 0.5152022838592529
train loss item: 0.528084397315979
train loss item: 0.9421567320823669
train loss item: 0.6088292002677917
3
train loss item: 0.6201375126838684
train loss item: 0.6374879479408264
train loss item: 0.5473155975341797
train loss item: 0.5828478932380676
train loss item: 0.6870982050895691
train loss item: 0.5076937675476074
train loss item: 2.2537639141082764
train loss item: 0.6441835165023804
train loss item: 0.4633548855781555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6354823112487793
train loss item: 0.5546389818191528
train loss item: 4.452296257019043
train loss item: 0.7913306355476379
train loss item: 0.6001733541488647
train loss item: 0.6769973039627075
train loss item: 0.4553399682044983
train loss item: 0.8695197105407715
train loss item: 0.4755610227584839
train loss item: 0.6617066860198975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5238131284713745
train loss item: 0.5245546698570251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5921008586883545
train loss item: 1.9015032052993774
train loss item: 3.9101366996765137
train loss item: 0.6102474927902222
train loss item: 0.46769586205482483
train loss item: 1.5767532587051392
train loss item: 0.5057856440544128
train loss item: 0.9696930050849915
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.587297797203064
train loss item: 1.0258359909057617
train loss item: 1.5137578248977661
train loss item: 1.074904203414917
train loss item: 0.4704446494579315
train loss item: 0.8295745253562927
train loss item: 0.5119169354438782
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7610528469085693
train loss item: 0.9171606302261353
train loss item: 0.6281032562255859
train loss item: 0.5952099561691284
train loss item: 0.6960201859474182
train loss item: 0.6789958477020264
train loss item: 0.4713931977748871
train loss item: 1.4038227796554565
train loss item: 0.578901469707489
train loss item: 0.48654380440711975
train loss item: 0.7137617468833923
train loss item: 0.586050271987915
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4967315196990967
train loss item: 2.397573947906494
train loss item: 0.7835416197776794
train loss item: 2.8879265785217285
train loss item: 0.5795229077339172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46186575293540955
train loss item: 0.6076156497001648
train loss item: 0.6935876607894897
5
train loss item: 0.5685961842536926
train loss item: 0.6882216334342957
train loss item: 0.5235651135444641
train loss item: 0.561565101146698
train loss item: 0.5332809686660767
train loss item: 0.7282124757766724
train loss item: 1.192653775215149
train loss item: 1.4065489768981934
train loss item: 0.482292503118515
train loss item: 1.0171582698822021
train loss item: 2.007269859313965
train loss item: 0.48738574981689453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.58840799331665
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6192532181739807
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9542.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.8054918646812439
train loss item: 0.8987407088279724
train loss item: 2.2919647693634033
train loss item: 1.7529160976409912
train loss item: 0.619989275932312
train loss item: 0.40582361817359924
train loss item: 0.41985389590263367
train loss item: 1.4629015922546387
train loss item: 0.8853329420089722
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5445839762687683
train loss item: 0.674015462398529
train loss item: 0.4879615008831024
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.0255072116851807
train loss item: 0.42342409491539
train loss item: 0.4279136657714844
train loss item: 0.7758976221084595
train loss item: 0.3747066557407379
train loss item: 0.6917065382003784
train loss item: 0.4910371005535126
train loss item: 0.9175930619239807
train loss item: 0.41859519481658936
train loss item: 0.5455162525177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4035603404045105
train loss item: 0.7738136053085327
train loss item: 1.258652925491333
train loss item: 0.6637643575668335
train loss item: 0.4387687146663666
train loss item: 0.5114082098007202
train loss item: 1.4561054706573486
1
train loss item: 0.3829658627510071
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.524093747138977
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9038376212120056
train loss item: 0.5851014256477356
train loss item: 0.4196215569972992
train loss item: 0.6253869533538818
train loss item: 0.46743452548980713
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3872469365596771
train loss item: 1.8338868618011475
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41059255599975586
train loss item: 2.443751335144043
train loss item: 1.0170003175735474
train loss item: 0.995087206363678
train loss item: 0.40507644414901733
train loss item: 0.6749089360237122
train loss item: 0.4420895576477051
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43542855978012085
train loss item: 0.7903597950935364
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.38722386956214905
train loss item: 0.3567829728126526
train loss item: 1.8009729385375977
train loss item: 1.1887037754058838
train loss item: 3.5324246883392334
train loss item: 0.9487202763557434
train loss item: 1.1619105339050293
2
train loss item: 0.4423845112323761
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9855327606201172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008445143699646
train loss item: 4.32944393157959
train loss item: 1.3845133781433105
train loss item: 0.7258349061012268
train loss item: 1.1670548915863037
train loss item: 0.4191601872444153
train loss item: 0.5944328904151917
train loss item: 1.1055978536605835
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8371577262878418
train loss item: 0.39751115441322327
train loss item: 0.35939866304397583
train loss item: 0.48182982206344604
train loss item: 0.7070066332817078
train loss item: 0.5354675054550171
train loss item: 0.49496012926101685
train loss item: 0.4740426540374756
train loss item: 0.530408501625061
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0800422430038452
train loss item: 1.3574137687683105
train loss item: 0.46985873579978943
train loss item: 0.4406193196773529
train loss item: 0.446282297372818
train loss item: 0.4453347325325012
train loss item: 0.8741986751556396
train loss item: 0.5293667912483215
3
train loss item: 0.5353571176528931
train loss item: 0.5791845321655273
train loss item: 0.5059974789619446
train loss item: 0.4314745366573334
train loss item: 0.6558837294578552
train loss item: 0.42855778336524963
train loss item: 2.206753730773926
train loss item: 0.6051461696624756
train loss item: 0.3908587694168091
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5420536398887634
train loss item: 0.3993499279022217
train loss item: 4.305393695831299
train loss item: 0.7225639224052429
train loss item: 0.537074863910675
train loss item: 0.44736871123313904
train loss item: 0.38459938764572144
train loss item: 0.7890965938568115
train loss item: 0.414558082818985
train loss item: 0.603987991809845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46700191497802734
train loss item: 0.4694973826408386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5276029109954834
train loss item: 1.850875973701477
train loss item: 3.771341323852539
train loss item: 0.464836061000824
train loss item: 0.3977920413017273
train loss item: 1.2948168516159058
train loss item: 0.44135576486587524
train loss item: 0.9448678493499756
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5373835563659668
train loss item: 0.9716783761978149
train loss item: 1.4940139055252075
train loss item: 1.019716739654541
train loss item: 0.4043095111846924
train loss item: 0.6526936292648315
train loss item: 0.4361291527748108
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6763297915458679
train loss item: 0.846520721912384
train loss item: 0.5822674632072449
train loss item: 0.5073311924934387
train loss item: 0.6249715685844421
train loss item: 0.4491252601146698
train loss item: 0.41228458285331726
train loss item: 0.9837915897369385
train loss item: 0.43238136172294617
train loss item: 0.3756480813026428
train loss item: 0.6602489352226257
train loss item: 0.43490418791770935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4389401078224182
train loss item: 2.278047800064087
train loss item: 0.7019065022468567
train loss item: 2.877516031265259
train loss item: 0.5246642231941223
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3866238594055176
train loss item: 0.5449886918067932
train loss item: 0.6539317965507507
5
train loss item: 0.4264691472053528
train loss item: 0.45463478565216064
train loss item: 0.45638638734817505
train loss item: 0.4559684693813324
train loss item: 0.47985419631004333
train loss item: 0.6698529720306396
train loss item: 1.1541709899902344
train loss item: 1.3551671504974365
train loss item: 0.42673611640930176
train loss item: 0.969355583190918
train loss item: 1.86638605594635
train loss item: 0.41490432620048523
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.436746597290039
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5215848684310913
train loss item: 0.6882298588752747
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.8051015734672546
train loss item: 0.8529430627822876
train loss item: 2.214339017868042
train loss item: 1.5116938352584839
train loss item: 0.5819724798202515
train loss item: 0.4383721649646759
train loss item: 0.41861456632614136
train loss item: 1.3880025148391724
train loss item: 0.7734600305557251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5285988450050354
train loss item: 0.6681726574897766
train loss item: 0.4541483521461487
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.9507399797439575
train loss item: 0.39212068915367126
train loss item: 0.3957740068435669
train loss item: 0.7045068740844727
train loss item: 0.3592888116836548
train loss item: 0.640126645565033
train loss item: 0.45678287744522095
train loss item: 0.8674015998840332
train loss item: 0.3970751464366913
train loss item: 0.5010831356048584
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37873467803001404
train loss item: 0.7549389600753784
train loss item: 1.209031105041504
train loss item: 0.6678506731987
train loss item: 0.41784077882766724
train loss item: 0.4937847852706909
train loss item: 1.4121454954147339
1
train loss item: 0.35888829827308655
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4921519160270691
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8699957728385925
train loss item: 0.5450640916824341
train loss item: 0.3905563950538635
train loss item: 0.5765966773033142
train loss item: 0.43139874935150146
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3643650412559509
train loss item: 1.7877963781356812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3885669708251953
train loss item: 2.3744027614593506
train loss item: 0.9635235071182251
train loss item: 0.9398651123046875
train loss item: 0.3759452998638153
train loss item: 0.6498486995697021
train loss item: 0.42940425872802734
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4148862063884735
train loss item: 0.7516554594039917
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35976043343544006
train loss item: 0.34368252754211426
train loss item: 1.7625540494918823
train loss item: 1.1395182609558105
train loss item: 3.423069477081299
train loss item: 0.9135857224464417
train loss item: 1.1172702312469482
2
train loss item: 0.4248979389667511
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9466566443443298
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4133960008621216
train loss item: 4.23195743560791
train loss item: 1.3307774066925049
train loss item: 0.7032762765884399
train loss item: 1.1340081691741943
train loss item: 0.390132337808609
train loss item: 0.5579783916473389
train loss item: 1.0716018676757812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.802668571472168
train loss item: 0.38565701246261597
train loss item: 0.32250872254371643
train loss item: 0.47355711460113525
train loss item: 0.661649763584137
train loss item: 0.5043798685073853
train loss item: 0.4497036635875702
train loss item: 0.438198983669281
train loss item: 0.5030548572540283
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0335768461227417
train loss item: 1.2954051494598389
train loss item: 0.44945961236953735
train loss item: 0.41032615303993225
train loss item: 0.44713613390922546
train loss item: 0.4125525653362274
train loss item: 0.8212732076644897
train loss item: 0.5073781609535217
3
train loss item: 0.5154852271080017
train loss item: 0.5469192266464233
train loss item: 0.4909832775592804
train loss item: 0.3931466341018677
train loss item: 0.621256947517395
train loss item: 0.39793649315834045
train loss item: 2.1539275646209717
train loss item: 0.5704979300498962
train loss item: 0.3635222911834717
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.516581118106842
train loss item: 0.403873085975647
train loss item: 4.208215236663818
train loss item: 0.6724585890769958
train loss item: 0.5222636461257935
train loss item: 0.4144033193588257
train loss item: 0.35863155126571655
train loss item: 0.746972918510437
train loss item: 0.3903963267803192
train loss item: 0.5846830606460571
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43731755018234253
train loss item: 0.4497511386871338
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.481804609298706
train loss item: 1.7918583154678345
train loss item: 3.672724723815918
train loss item: 0.42840874195098877
train loss item: 0.36995062232017517
train loss item: 1.1104559898376465
train loss item: 0.41665565967559814
train loss item: 0.9020617604255676
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5116944313049316
train loss item: 0.9252290725708008
train loss item: 1.414633870124817
train loss item: 0.9859626293182373
train loss item: 0.3803067207336426
train loss item: 0.5922043323516846
train loss item: 0.402712345123291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6224695444107056
train loss item: 0.794919490814209
train loss item: 0.5667665600776672
train loss item: 0.4867575764656067
train loss item: 0.5816335678100586
train loss item: 0.4143410921096802
train loss item: 0.44441157579421997
train loss item: 0.8031931519508362
train loss item: 0.40109309554100037
train loss item: 0.3602941930294037
train loss item: 0.627627432346344
train loss item: 0.3945261240005493
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4165565073490143
train loss item: 2.199267625808716
train loss item: 0.6530634164810181
train loss item: 2.8289592266082764
train loss item: 0.5036813020706177
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3602833151817322
train loss item: 0.5181873440742493
train loss item: 0.6069742441177368
5
train loss item: 0.4211292862892151
train loss item: 0.40407049655914307
train loss item: 0.4450536072254181
train loss item: 0.4276082515716553
train loss item: 0.4543696343898773
train loss item: 0.6541560292243958
train loss item: 1.1092151403427124
train loss item: 1.3023735284805298
train loss item: 0.39061033725738525
train loss item: 0.9333477020263672
train loss item: 1.7632112503051758
train loss item: 0.39761194586753845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.3332133293151855
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4968581199645996
train loss item: 0.6446283459663391
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.7930572628974915
train loss item: 0.8106309175491333
train loss item: 2.154629945755005
train loss item: 1.4358925819396973
train loss item: 0.5403582453727722
train loss item: 0.42518410086631775
train loss item: 0.3946791887283325
train loss item: 1.337820291519165
train loss item: 0.7283328771591187
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5086467266082764
train loss item: 0.6587628722190857
train loss item: 0.43243226408958435
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8997114896774292
train loss item: 0.3564055263996124
train loss item: 0.3781545162200928
train loss item: 0.6633870601654053
train loss item: 0.34436315298080444
train loss item: 0.6021005511283875
train loss item: 0.4337024390697479
train loss item: 0.8381946086883545
train loss item: 0.3798515796661377
train loss item: 0.46760791540145874
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36306190490722656
train loss item: 0.7336841821670532
train loss item: 1.1666553020477295
train loss item: 0.6589175462722778
train loss item: 0.40363696217536926
train loss item: 0.4622725248336792
train loss item: 1.3715578317642212
1
train loss item: 0.3419116735458374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46878868341445923
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8391717672348022
train loss item: 0.5013014674186707
train loss item: 0.37441208958625793
train loss item: 0.5385311841964722
train loss item: 0.3904067277908325
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35047394037246704
train loss item: 1.732211947441101
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3668222427368164
train loss item: 2.326054096221924
train loss item: 0.9112567901611328
train loss item: 0.8813654184341431
train loss item: 0.35766473412513733
train loss item: 0.6242033839225769
train loss item: 0.4178542494773865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39821115136146545
train loss item: 0.7165666818618774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34212782979011536
train loss item: 0.3284926116466522
train loss item: 1.7136108875274658
train loss item: 0.9933941960334778
train loss item: 3.3595523834228516
train loss item: 0.8102750778198242
train loss item: 1.0816224813461304
2
train loss item: 0.413299024105072
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9135479927062988
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4067084491252899
train loss item: 4.174579620361328
train loss item: 1.2894893884658813
train loss item: 0.6825628876686096
train loss item: 1.094824194908142
train loss item: 0.36362388730049133
train loss item: 0.5129873752593994
train loss item: 1.030917763710022
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7728220224380493
train loss item: 0.37418532371520996
train loss item: 0.30440935492515564
train loss item: 0.46403172612190247
train loss item: 0.6374162435531616
train loss item: 0.47682198882102966
train loss item: 0.4160236716270447
train loss item: 0.41514167189598083
train loss item: 0.4792505204677582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9984489679336548
train loss item: 1.2547656297683716
train loss item: 0.42159074544906616
train loss item: 0.3940301835536957
train loss item: 0.43876731395721436
train loss item: 0.3962877094745636
train loss item: 0.7742434144020081
train loss item: 0.48457634449005127
3
train loss item: 0.4956094026565552
train loss item: 0.5226385593414307
train loss item: 0.4763917326927185
train loss item: 0.3738737106323242
train loss item: 0.5782414078712463
train loss item: 0.3818342983722687
train loss item: 2.098876714706421
train loss item: 0.5317774415016174
train loss item: 0.34576982259750366
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.49367421865463257
train loss item: 0.38496139645576477
train loss item: 4.151196479797363
train loss item: 0.6276695728302002
train loss item: 0.5083506107330322
train loss item: 0.4003390669822693
train loss item: 0.34301993250846863
train loss item: 0.722851037979126
train loss item: 0.37242257595062256
train loss item: 0.5657562613487244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41457399725914
train loss item: 0.43614786863327026
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4422942399978638
train loss item: 1.7304792404174805
train loss item: 3.612187385559082
train loss item: 0.4083971083164215
train loss item: 0.35246723890304565
train loss item: 0.9530659914016724
train loss item: 0.40092340111732483
train loss item: 0.8486791849136353
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.490337997674942
train loss item: 0.8784583210945129
train loss item: 1.2507680654525757
train loss item: 0.9552468061447144
train loss item: 0.3652568459510803
train loss item: 0.5493290424346924
train loss item: 0.3815479874610901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5802987217903137
train loss item: 0.7484342455863953
train loss item: 0.5494769811630249
train loss item: 0.4643653333187103
train loss item: 0.5457404851913452
train loss item: 0.3989465534687042
train loss item: 0.42997774481773376
train loss item: 0.7423388957977295
train loss item: 0.38405466079711914
train loss item: 0.3448895215988159
train loss item: 0.5970014333724976
train loss item: 0.376468688249588
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40056467056274414
train loss item: 2.1499416828155518
train loss item: 0.6170884370803833
train loss item: 2.7615437507629395
train loss item: 0.4902063310146332
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.342864990234375
train loss item: 0.5018545985221863
train loss item: 0.5526416301727295
5
train loss item: 0.3963841199874878
train loss item: 0.3859878480434418
train loss item: 0.43436458706855774
train loss item: 0.40195322036743164
train loss item: 0.4347972571849823
train loss item: 0.6304241418838501
train loss item: 1.0596929788589478
train loss item: 1.2464430332183838
train loss item: 0.35329416394233704
train loss item: 0.8949295878410339
train loss item: 1.693165898323059
train loss item: 0.38602107763290405
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.273541450500488
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47628358006477356
train loss item: 0.6043571829795837
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.7696083784103394
train loss item: 0.7738329172134399
train loss item: 2.1072099208831787
train loss item: 1.4392237663269043
train loss item: 0.5005015730857849
train loss item: 0.3845720589160919
train loss item: 0.3539958596229553
train loss item: 1.3030188083648682
train loss item: 0.7387155294418335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48472341895103455
train loss item: 0.6403278708457947
train loss item: 0.413040429353714
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8626539707183838
train loss item: 0.324313223361969
train loss item: 0.35225561261177063
train loss item: 0.6438730955123901
train loss item: 0.32586467266082764
train loss item: 0.574292778968811
train loss item: 0.41302573680877686
train loss item: 0.8201944231987
train loss item: 0.36107563972473145
train loss item: 0.4429234266281128
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480510413646698
train loss item: 0.7084197998046875
train loss item: 1.1274973154067993
train loss item: 0.6368315815925598
train loss item: 0.3884425163269043
train loss item: 0.41889122128486633
train loss item: 1.3325780630111694
1
train loss item: 0.32780951261520386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44647303223609924
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.807952344417572
train loss item: 0.4614025950431824
train loss item: 0.3634142279624939
train loss item: 0.507057785987854
train loss item: 0.35348328948020935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3369205892086029
train loss item: 1.6761924028396606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34206584095954895
train loss item: 2.289836883544922
train loss item: 0.8633443713188171
train loss item: 0.8268972635269165
train loss item: 0.33858802914619446
train loss item: 0.5944257974624634
train loss item: 0.39823782444000244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.382181316614151
train loss item: 0.6845089793205261
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32874244451522827
train loss item: 0.3081795275211334
train loss item: 1.6619094610214233
train loss item: 0.8459346890449524
train loss item: 3.321760416030884
train loss item: 0.7155598998069763
train loss item: 1.0504289865493774
2
train loss item: 0.40089112520217896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8821102380752563
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3742945194244385
train loss item: 4.1395344734191895
train loss item: 1.2572300434112549
train loss item: 0.6645398736000061
train loss item: 1.0516414642333984
train loss item: 0.3420185446739197
train loss item: 0.4718320369720459
train loss item: 0.9858909249305725
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7448924779891968
train loss item: 0.3587813079357147
train loss item: 0.2892478406429291
train loss item: 0.446908563375473
train loss item: 0.6241509914398193
train loss item: 0.452237606048584
train loss item: 0.38668879866600037
train loss item: 0.39500245451927185
train loss item: 0.4571174681186676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9703024625778198
train loss item: 1.2268974781036377
train loss item: 0.38222089409828186
train loss item: 0.3834834098815918
train loss item: 0.4158337712287903
train loss item: 0.38689056038856506
train loss item: 0.7324391007423401
train loss item: 0.4568125903606415
3
train loss item: 0.46983617544174194
train loss item: 0.5018084049224854
train loss item: 0.45918580889701843
train loss item: 0.34954211115837097
train loss item: 0.5389177799224854
train loss item: 0.3717734217643738
train loss item: 2.0475189685821533
train loss item: 0.49729806184768677
train loss item: 0.33280983567237854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4671946167945862
train loss item: 0.34541434049606323
train loss item: 4.116434574127197
train loss item: 0.5871601700782776
train loss item: 0.4871812164783478
train loss item: 0.3709505498409271
train loss item: 0.3285726010799408
train loss item: 0.7077078819274902
train loss item: 0.3541874587535858
train loss item: 0.540101170539856
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39517709612846375
train loss item: 0.4215240776538849
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4052671194076538
train loss item: 1.6727595329284668
train loss item: 3.5740201473236084
train loss item: 0.3823288679122925
train loss item: 0.33647620677948
train loss item: 0.8517757058143616
train loss item: 0.38571423292160034
train loss item: 0.7971600890159607
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47017186880111694
train loss item: 0.8344438076019287
train loss item: 1.068676471710205
train loss item: 0.9240391254425049
train loss item: 0.35040900111198425
train loss item: 0.511786937713623
train loss item: 0.36324790120124817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5441670417785645
train loss item: 0.7062374949455261
train loss item: 0.5278030037879944
train loss item: 0.43699127435684204
train loss item: 0.5143771767616272
train loss item: 0.3693526089191437
train loss item: 0.3911777138710022
train loss item: 0.763845682144165
train loss item: 0.35922425985336304
train loss item: 0.3260841965675354
train loss item: 0.566985011100769
train loss item: 0.3556440770626068
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3841143846511841
train loss item: 2.1170198917388916
train loss item: 0.5884301662445068
train loss item: 2.694685697555542
train loss item: 0.4767865240573883
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.328854501247406
train loss item: 0.4874052405357361
train loss item: 0.501418948173523
5
train loss item: 0.35631272196769714
train loss item: 0.3638763725757599
train loss item: 0.415113240480423
train loss item: 0.3737080991268158
train loss item: 0.41739779710769653
train loss item: 0.5961752533912659
train loss item: 1.011290192604065
train loss item: 1.192165732383728
train loss item: 0.3219052255153656
train loss item: 0.8539865016937256
train loss item: 1.6443272829055786
train loss item: 0.3701934218406677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.238527774810791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.45275771617889404
train loss item: 0.564845860004425
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.7437087893486023
train loss item: 0.7437713742256165
train loss item: 2.0666611194610596
train loss item: 1.4547584056854248
train loss item: 0.4739750623703003
train loss item: 0.3508828282356262
train loss item: 0.3234092891216278
train loss item: 1.2739440202713013
train loss item: 0.7835104465484619
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647943675518036
train loss item: 0.6195951104164124
train loss item: 0.3989918529987335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.83207368850708
train loss item: 0.30287811160087585
train loss item: 0.32705992460250854
train loss item: 0.6540850400924683
train loss item: 0.32307741045951843
train loss item: 0.553713858127594
train loss item: 0.3983871340751648
train loss item: 0.8048974275588989
train loss item: 0.34606677293777466
train loss item: 0.42535436153411865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33705025911331177
train loss item: 0.6835212707519531
train loss item: 1.089398980140686
train loss item: 0.6109908223152161
train loss item: 0.37597376108169556
train loss item: 0.38276466727256775
train loss item: 1.2975618839263916
1
train loss item: 0.3183952271938324
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4295913279056549
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7786715626716614
train loss item: 0.43221718072891235
train loss item: 0.3559081554412842
train loss item: 0.48468106985092163
train loss item: 0.32916566729545593
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3274155557155609
train loss item: 1.625609278678894
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32250678539276123
train loss item: 2.256333589553833
train loss item: 0.8248248100280762
train loss item: 0.7831247448921204
train loss item: 0.32505783438682556
train loss item: 0.5658968687057495
train loss item: 0.37843772768974304
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37125566601753235
train loss item: 0.657664954662323
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3204960823059082
train loss item: 0.3045646548271179
train loss item: 1.614041805267334
train loss item: 0.7644869685173035
train loss item: 3.2923824787139893
train loss item: 0.6829583048820496
train loss item: 1.0228385925292969
2
train loss item: 0.38931605219841003
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8528540134429932
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3485627770423889
train loss item: 4.111616611480713
train loss item: 1.2297002077102661
train loss item: 0.6492116451263428
train loss item: 1.008128046989441
train loss item: 0.3284187912940979
train loss item: 0.4428568184375763
train loss item: 0.9412129521369934
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7195854187011719
train loss item: 0.34543299674987793
train loss item: 0.2819531559944153
train loss item: 0.4309505522251129
train loss item: 0.6133702993392944
train loss item: 0.43492189049720764
train loss item: 0.3658623695373535
train loss item: 0.37986767292022705
train loss item: 0.44018375873565674
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9464237093925476
train loss item: 1.2035741806030273
train loss item: 0.3545955717563629
train loss item: 0.3758346438407898
train loss item: 0.39175179600715637
train loss item: 0.3806363046169281
train loss item: 0.6995801329612732
train loss item: 0.43269583582878113
3
train loss item: 0.44496119022369385
train loss item: 0.4859105348587036
train loss item: 0.4437786638736725
train loss item: 0.3284643292427063
train loss item: 0.5112730264663696
train loss item: 0.36504316329956055
train loss item: 2.0017402172088623
train loss item: 0.47355973720550537
train loss item: 0.32535889744758606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4425390660762787
train loss item: 0.3178510069847107
train loss item: 4.0886030197143555
train loss item: 0.5539808869361877
train loss item: 0.4657462239265442
train loss item: 0.35042551159858704
train loss item: 0.318915456533432
train loss item: 0.6950581073760986
train loss item: 0.34033575654029846
train loss item: 0.5144366025924683
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3827149271965027
train loss item: 0.4091763198375702
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.3682557344436646
train loss item: 1.6217763423919678
train loss item: 3.543980598449707
train loss item: 0.35708898305892944
train loss item: 0.3252008557319641
train loss item: 0.8107115626335144
train loss item: 0.37360048294067383
train loss item: 0.7553129196166992
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4545861482620239
train loss item: 0.7977326512336731
train loss item: 0.9332625269889832
train loss item: 0.8923819065093994
train loss item: 0.339046835899353
train loss item: 0.4856336712837219
train loss item: 0.3496454358100891
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5165325999259949
train loss item: 0.6721661686897278
train loss item: 0.5066771507263184
train loss item: 0.41250136494636536
train loss item: 0.4908815622329712
train loss item: 0.3487595319747925
train loss item: 0.3607846796512604
train loss item: 0.8139474987983704
train loss item: 0.33619898557662964
train loss item: 0.3233568072319031
train loss item: 0.5422070026397705
train loss item: 0.33855047821998596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3711854815483093
train loss item: 2.088186502456665
train loss item: 0.5678302049636841
train loss item: 2.637929677963257
train loss item: 0.46539825201034546
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31939923763275146
train loss item: 0.47557511925697327
train loss item: 0.46110841631889343
5
train loss item: 0.3283836245536804
train loss item: 0.35422033071517944
train loss item: 0.39511236548423767
train loss item: 0.35176724195480347
train loss item: 0.4055427610874176
train loss item: 0.5598140954971313
train loss item: 0.9668205976486206
train loss item: 1.1445995569229126
train loss item: 0.3026847243309021
train loss item: 0.8137850761413574
train loss item: 1.6032146215438843
train loss item: 0.35565489530563354
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.211021900177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43184077739715576
train loss item: 0.5301486849784851
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.723175048828125
train loss item: 0.718856155872345
train loss item: 2.028942108154297
train loss item: 1.4304053783416748
train loss item: 0.45900553464889526
train loss item: 0.33748161792755127
train loss item: 0.31310099363327026
train loss item: 1.2421724796295166
train loss item: 0.8151156306266785
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4519675076007843
train loss item: 0.6022875308990479
train loss item: 0.38473716378211975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8026916980743408
train loss item: 0.287600040435791
train loss item: 0.30573081970214844
train loss item: 0.652103841304779
train loss item: 0.3306933641433716
train loss item: 0.5344435572624207
train loss item: 0.38471439480781555
train loss item: 0.7849844098091125
train loss item: 0.33515018224716187
train loss item: 0.40964803099632263
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3287726640701294
train loss item: 0.6621514558792114
train loss item: 1.0514967441558838
train loss item: 0.5896925330162048
train loss item: 0.36614593863487244
train loss item: 0.36037692427635193
train loss item: 1.2676422595977783
1
train loss item: 0.3083057403564453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41466179490089417
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7532024383544922
train loss item: 0.41358983516693115
train loss item: 0.3455303907394409
train loss item: 0.4698421061038971
train loss item: 0.3146267831325531
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3215275704860687
train loss item: 1.5843149423599243
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3101251423358917
train loss item: 2.220048666000366
train loss item: 0.7976096272468567
train loss item: 0.7521964311599731
train loss item: 0.31254225969314575
train loss item: 0.5406280159950256
train loss item: 0.36393192410469055
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3654620349407196
train loss item: 0.636022686958313
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3111319839954376
train loss item: 0.3127814531326294
train loss item: 1.5739250183105469
train loss item: 0.735058069229126
train loss item: 3.2600882053375244
train loss item: 0.6824032664299011
train loss item: 0.9979923367500305
2
train loss item: 0.3777829110622406
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.826256513595581
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3405210077762604
train loss item: 4.080611228942871
train loss item: 1.2025891542434692
train loss item: 0.6337785124778748
train loss item: 0.9671251177787781
train loss item: 0.3173796534538269
train loss item: 0.4255298674106598
train loss item: 0.9008482694625854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.69732666015625
train loss item: 0.33567777276039124
train loss item: 0.27587974071502686
train loss item: 0.4161907136440277
train loss item: 0.5964747071266174
train loss item: 0.42475447058677673
train loss item: 0.35216233134269714
train loss item: 0.36862891912460327
train loss item: 0.42884722352027893
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.924312174320221
train loss item: 1.1783323287963867
train loss item: 0.34544917941093445
train loss item: 0.3645091652870178
train loss item: 0.3730444312095642
train loss item: 0.3705114424228668
train loss item: 0.6758893728256226
train loss item: 0.41454723477363586
3
train loss item: 0.4214242398738861
train loss item: 0.4737102687358856
train loss item: 0.4317299723625183
train loss item: 0.3111536204814911
train loss item: 0.49499887228012085
train loss item: 0.35472050309181213
train loss item: 1.961248755455017
train loss item: 0.45868903398513794
train loss item: 0.3169795572757721
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4208192527294159
train loss item: 0.3132786750793457
train loss item: 4.057366371154785
train loss item: 0.5287954807281494
train loss item: 0.4487692713737488
train loss item: 0.33699437975883484
train loss item: 0.3130371570587158
train loss item: 0.6779537200927734
train loss item: 0.3303520083427429
train loss item: 0.4945813715457916
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37621408700942993
train loss item: 0.3988354504108429
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.330076813697815
train loss item: 1.579289197921753
train loss item: 3.5126287937164307
train loss item: 0.3340296745300293
train loss item: 0.3169589936733246
train loss item: 0.7846478223800659
train loss item: 0.3635338246822357
train loss item: 0.725496232509613
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44399502873420715
train loss item: 0.7699281573295593
train loss item: 0.8696199655532837
train loss item: 0.8602725863456726
train loss item: 0.3302028179168701
train loss item: 0.4687436521053314
train loss item: 0.33963802456855774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4965958893299103
train loss item: 0.6479334235191345
train loss item: 0.48864591121673584
train loss item: 0.39237332344055176
train loss item: 0.47472578287124634
train loss item: 0.33520302176475525
train loss item: 0.3509271442890167
train loss item: 0.8338758945465088
train loss item: 0.31649288535118103
train loss item: 0.33143237233161926
train loss item: 0.5244999527931213
train loss item: 0.324046790599823
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36128175258636475
train loss item: 2.0560989379882812
train loss item: 0.553006112575531
train loss item: 2.594550609588623
train loss item: 0.45530781149864197
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3091706931591034
train loss item: 0.4647732377052307
train loss item: 0.43392854928970337
5
train loss item: 0.321036696434021
train loss item: 0.34806233644485474
train loss item: 0.37958210706710815
train loss item: 0.3358091115951538
train loss item: 0.3980853259563446
train loss item: 0.526502251625061
train loss item: 0.9276179671287537
train loss item: 1.1062926054000854
train loss item: 0.2902069091796875
train loss item: 0.7763500809669495
train loss item: 1.5605475902557373
train loss item: 0.3448650538921356
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.180288791656494
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4129044711589813
train loss item: 0.5026814937591553
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.7098458409309387
train loss item: 0.6970778703689575
train loss item: 1.993215560913086
train loss item: 1.361167550086975
train loss item: 0.4433552026748657
train loss item: 0.3333328068256378
train loss item: 0.3102828562259674
train loss item: 1.2063350677490234
train loss item: 0.8118047714233398
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4439007639884949
train loss item: 0.5893954634666443
train loss item: 0.3698454797267914
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7727218866348267
train loss item: 0.27374371886253357
train loss item: 0.2851434350013733
train loss item: 0.6276633143424988
train loss item: 0.3264438509941101
train loss item: 0.5133658647537231
train loss item: 0.37052497267723083
train loss item: 0.7600528001785278
train loss item: 0.324270099401474
train loss item: 0.39370864629745483
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3186584711074829
train loss item: 0.6454132795333862
train loss item: 1.0152084827423096
train loss item: 0.575340986251831
train loss item: 0.3553259074687958
train loss item: 0.34137189388275146
train loss item: 1.2435381412506104
1
train loss item: 0.29306724667549133
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008773863315582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.731844425201416
train loss item: 0.4023657441139221
train loss item: 0.3284552991390228
train loss item: 0.45803284645080566
train loss item: 0.30404379963874817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31538671255111694
train loss item: 1.5533117055892944
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3011203706264496
train loss item: 2.1825239658355713
train loss item: 0.7800406217575073
train loss item: 0.7315957546234131
train loss item: 0.29639318585395813
train loss item: 0.5183584690093994
train loss item: 0.3537620007991791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583802580833435
train loss item: 0.6166451573371887
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2961908280849457
train loss item: 0.3096919357776642
train loss item: 1.5434669256210327
train loss item: 0.7250176072120667
train loss item: 3.2225394248962402
train loss item: 0.6801353096961975
train loss item: 0.975432276725769
2
train loss item: 0.36429905891418457
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8020622134208679
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33765748143196106
train loss item: 4.044615268707275
train loss item: 1.174917459487915
train loss item: 0.6165820956230164
train loss item: 0.9317919611930847
train loss item: 0.30421990156173706
train loss item: 0.41483116149902344
train loss item: 0.8679857850074768
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6773892045021057
train loss item: 0.3277986943721771
train loss item: 0.26407402753829956
train loss item: 0.3954724073410034
train loss item: 0.5719655156135559
train loss item: 0.41636985540390015
train loss item: 0.34038442373275757
train loss item: 0.35828423500061035
train loss item: 0.4188620150089264
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9020735025405884
train loss item: 1.1499011516571045
train loss item: 0.3417537212371826
train loss item: 0.34626662731170654
train loss item: 0.35472482442855835
train loss item: 0.35314419865608215
train loss item: 0.6580479145050049
train loss item: 0.3996224105358124
3
train loss item: 0.4013262093067169
train loss item: 0.46032166481018066
train loss item: 0.42160987854003906
train loss item: 0.2922847867012024
train loss item: 0.48536011576652527
train loss item: 0.3375800549983978
train loss item: 1.9268697500228882
train loss item: 0.44759947061538696
train loss item: 0.30262506008148193
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.401305228471756
train loss item: 0.3150266408920288
train loss item: 4.020753860473633
train loss item: 0.509464681148529
train loss item: 0.43568670749664307
train loss item: 0.31719741225242615
train loss item: 0.30639827251434326
train loss item: 0.6550703048706055
train loss item: 0.3199657201766968
train loss item: 0.4804512858390808
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3688831031322479
train loss item: 0.3875214755535126
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2929304838180542
train loss item: 1.545644760131836
train loss item: 3.4781038761138916
train loss item: 0.30991798639297485
train loss item: 0.3069058656692505
train loss item: 0.7484599947929382
train loss item: 0.3521009385585785
train loss item: 0.7055948972702026
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43298038840293884
train loss item: 0.7503966093063354
train loss item: 0.8610623478889465
train loss item: 0.8302368521690369
train loss item: 0.3196645975112915
train loss item: 0.45290619134902954
train loss item: 0.3298962116241455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4801141321659088
train loss item: 0.632495105266571
train loss item: 0.47458669543266296
train loss item: 0.374237596988678
train loss item: 0.4621663987636566
train loss item: 0.31554439663887024
train loss item: 0.34858933091163635
train loss item: 0.8112183809280396
train loss item: 0.2961934208869934
train loss item: 0.3277743458747864
train loss item: 0.512164831161499
train loss item: 0.30690136551856995
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35072124004364014
train loss item: 2.020768642425537
train loss item: 0.5399312376976013
train loss item: 2.5637624263763428
train loss item: 0.44393324851989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2937313914299011
train loss item: 0.4522640109062195
train loss item: 0.417385071516037
5
train loss item: 0.3195478916168213
train loss item: 0.3309571444988251
train loss item: 0.3678264617919922
train loss item: 0.32141485810279846
train loss item: 0.3885186016559601
train loss item: 0.4946769177913666
train loss item: 0.8951320648193359
train loss item: 1.077818751335144
train loss item: 0.2774108350276947
train loss item: 0.744400680065155
train loss item: 1.5157862901687622
train loss item: 0.33590614795684814
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.143923282623291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3940907418727875
train loss item: 0.4830005466938019
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.7012327909469604
train loss item: 0.6768987774848938
train loss item: 1.959564447402954
train loss item: 1.2730965614318848
train loss item: 0.4245123267173767
train loss item: 0.32746371626853943
train loss item: 0.30321088433265686
train loss item: 1.1697438955307007
train loss item: 0.7816647887229919
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4375529885292053
train loss item: 0.5793851613998413
train loss item: 0.36056557297706604
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7435319423675537
train loss item: 0.2636568248271942
train loss item: 0.26824524998664856
train loss item: 0.6041659712791443
train loss item: 0.30960673093795776
train loss item: 0.4925594627857208
train loss item: 0.3610459864139557
train loss item: 0.7348750233650208
train loss item: 0.31261447072029114
train loss item: 0.37968042492866516
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3064850866794586
train loss item: 0.6322617530822754
train loss item: 0.9828314185142517
train loss item: 0.5660059452056885
train loss item: 0.34321141242980957
train loss item: 0.3221050202846527
train loss item: 1.2249256372451782
1
train loss item: 0.27635854482650757
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39237332344055176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.71439528465271
train loss item: 0.3958813548088074
train loss item: 0.3083411157131195
train loss item: 0.44660109281539917
train loss item: 0.2972389757633209
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3084021806716919
train loss item: 1.530341625213623
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2934279143810272
train loss item: 2.146493673324585
train loss item: 0.767556369304657
train loss item: 0.7163669466972351
train loss item: 0.27946630120277405
train loss item: 0.49904075264930725
train loss item: 0.3460235297679901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480775058269501
train loss item: 0.5983378291130066
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.27943864464759827
train loss item: 0.2939455211162567
train loss item: 1.5210046768188477
train loss item: 0.7247592210769653
train loss item: 3.1832032203674316
train loss item: 0.6760433912277222
train loss item: 0.9549425840377808
2
train loss item: 0.3498036563396454
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7805810570716858
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3302747905254364
train loss item: 4.007093906402588
train loss item: 1.1479820013046265
train loss item: 0.5999115705490112
train loss item: 0.9031261205673218
train loss item: 0.2931276857852936
train loss item: 0.4080217480659485
train loss item: 0.8418792486190796
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6597893238067627
train loss item: 0.32146796584129333
train loss item: 0.24960766732692719
train loss item: 0.3697932958602905
train loss item: 0.5459722876548767
train loss item: 0.4065341055393219
train loss item: 0.3288898468017578
train loss item: 0.3475848436355591
train loss item: 0.40844011306762695
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.880405843257904
train loss item: 1.121046543121338
train loss item: 0.3334875702857971
train loss item: 0.32480448484420776
train loss item: 0.33540695905685425
train loss item: 0.33273300528526306
train loss item: 0.6428158283233643
train loss item: 0.38700729608535767
3
train loss item: 0.38971251249313354
train loss item: 0.44530007243156433
train loss item: 0.4129522740840912
train loss item: 0.27337580919265747
train loss item: 0.47931110858917236
train loss item: 0.31752562522888184
train loss item: 1.8990013599395752
train loss item: 0.43906450271606445
train loss item: 0.2859288454055786
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3845539391040802
train loss item: 0.31036514043807983
train loss item: 3.982544422149658
train loss item: 0.4932782053947449
train loss item: 0.4250364303588867
train loss item: 0.2966454029083252
train loss item: 0.2986525893211365
train loss item: 0.6313495635986328
train loss item: 0.30833685398101807
train loss item: 0.46955808997154236
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583366572856903
train loss item: 0.37499508261680603
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2596176862716675
train loss item: 1.518908977508545
train loss item: 3.4426724910736084
train loss item: 0.2881893217563629
train loss item: 0.29457002878189087
train loss item: 0.7104032635688782
train loss item: 0.33935871720314026
train loss item: 0.6920673847198486
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.42006558179855347
train loss item: 0.7361637949943542
train loss item: 0.8761228919029236
train loss item: 0.8045116066932678
train loss item: 0.30721744894981384
train loss item: 0.4349144697189331
train loss item: 0.32019585371017456
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647907316684723
train loss item: 0.6221219301223755
train loss item: 0.46378180384635925
train loss item: 0.3581021726131439
train loss item: 0.4509026110172272
train loss item: 0.29534807801246643
train loss item: 0.3429086208343506
train loss item: 0.7649170160293579
train loss item: 0.2788582742214203
train loss item: 0.3115488588809967
train loss item: 0.5022445917129517
train loss item: 0.2896858751773834
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.339032381772995
train loss item: 1.9852867126464844
train loss item: 0.5266013741493225
train loss item: 2.5412187576293945
train loss item: 0.43140870332717896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2765684127807617
train loss item: 0.43842560052871704
train loss item: 0.40749555826187134
5
train loss item: 0.31202223896980286
train loss item: 0.30966389179229736
train loss item: 0.3586636781692505
train loss item: 0.3084482252597809
train loss item: 0.3757885694503784
train loss item: 0.46557512879371643
train loss item: 0.8691501021385193
train loss item: 1.056811809539795
train loss item: 0.26584452390670776
train loss item: 0.719364583492279
train loss item: 1.472780466079712
train loss item: 0.3277837634086609
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.1056928634643555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3768501877784729
train loss item: 0.4697430729866028
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 0.693540632724762
train loss item: 0.6579349637031555
train loss item: 1.928483247756958
train loss item: 1.1928136348724365
train loss item: 0.40681248903274536
train loss item: 0.3173936903476715
train loss item: 0.2905552089214325
train loss item: 1.136673092842102
train loss item: 0.7322322130203247
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4317569434642792
train loss item: 0.5698574185371399
train loss item: 0.3535853922367096
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.717613935470581
train loss item: 0.25894397497177124
train loss item: 0.2580583393573761
train loss item: 0.5890412330627441
train loss item: 0.29087549448013306
train loss item: 0.47456738352775574
train loss item: 0.35363325476646423
train loss item: 0.7146875262260437
train loss item: 0.30186089873313904
train loss item: 0.3687035143375397
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.29473981261253357
train loss item: 0.6211012005805969
train loss item: 0.9554638862609863
train loss item: 0.5585214495658875
train loss item: 0.3318652808666229
train loss item: 0.30660611391067505
train loss item: 1.2095849514007568
1
train loss item: 0.26302003860473633
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3856435716152191
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7001263499259949
train loss item: 0.39076924324035645
train loss item: 0.2909272015094757
train loss item: 0.4353330731391907
train loss item: 0.2934657633304596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3020230829715729
train loss item: 1.5108436346054077
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.28752565383911133
train loss item: 2.1144323348999023
train loss item: 0.7548717856407166
train loss item: 0.7015661597251892
train loss item: 0.2655992805957794
train loss item: 0.4824598729610443
train loss item: 0.339358389377594
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3373473882675171
train loss item: 0.5819714665412903
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2661121189594269
train loss item: 0.27563580870628357
train loss item: 1.5024704933166504
train loss item: 0.7264050841331482
train loss item: 3.1469216346740723
train loss item: 0.6701516509056091
train loss item: 0.9373541474342346
2
train loss item: 0.33666372299194336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7623443603515625
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3192974925041199
train loss item: 3.9725024700164795
train loss item: 1.1234350204467773
train loss item: 0.5868390202522278
train loss item: 0.8784924745559692
train loss item: 0.28700289130210876
train loss item: 0.40265190601348877
train loss item: 0.818615734577179
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6450898051261902
train loss item: 0.31625646352767944
train loss item: 0.23847685754299164
train loss item: 0.34598883986473083
train loss item: 0.5259736776351929
train loss item: 0.3959523141384125
train loss item: 0.31735894083976746
train loss item: 0.3372364044189453
train loss item: 0.3983061611652374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8612839579582214
train loss item: 1.0949510335922241
train loss item: 0.32029056549072266
train loss item: 0.3059912919998169
train loss item: 0.31798598170280457
train loss item: 0.3149357736110687
train loss item: 0.6279577016830444
train loss item: 0.37705492973327637
3
train loss item: 0.38158321380615234
train loss item: 0.4312494099140167
train loss item: 0.40601539611816406
train loss item: 0.25878503918647766
train loss item: 0.47405463457107544
train loss item: 0.30011799931526184
train loss item: 1.8759403228759766
train loss item: 0.43228986859321594
train loss item: 0.27250176668167114
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37063175439834595
train loss item: 0.29902151226997375
train loss item: 3.947033166885376
train loss item: 0.478669673204422
train loss item: 0.41550976037979126
train loss item: 0.2823288142681122
train loss item: 0.2913677394390106
train loss item: 0.6122833490371704
train loss item: 0.29741814732551575
train loss item: 0.45951148867607117
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3470873236656189
train loss item: 0.36318981647491455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2315360307693481
train loss item: 1.4951473474502563
train loss item: 3.4098076820373535
train loss item: 0.2728656232357025
train loss item: 0.28271758556365967
train loss item: 0.6820204257965088
train loss item: 0.32747241854667664
train loss item: 0.6805041432380676
4
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40764039754867554
train loss item: 0.7225446701049805
train loss item: 0.8893114328384399
train loss item: 0.7829195261001587
train loss item: 0.29536300897598267
train loss item: 0.41791871190071106
train loss item: 0.31172215938568115
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4493716061115265
train loss item: 0.6113709807395935
train loss item: 0.45497411489486694
train loss item: 0.3454032242298126
train loss item: 0.4403054714202881
train loss item: 0.2816068232059479
train loss item: 0.3324041962623596
train loss item: 0.711246907711029
train loss item: 0.26826685667037964
train loss item: 0.2934325337409973
train loss item: 0.4922246038913727
train loss item: 0.2767014801502228
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3281143307685852
train loss item: 1.952993392944336
train loss item: 0.5135407447814941
train loss item: 2.5215725898742676
train loss item: 0.4196229577064514
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2626209855079651
train loss item: 0.4253860414028168
train loss item: 0.39951568841934204
5
train loss item: 0.29863911867141724
train loss item: 0.29291844367980957
train loss item: 0.35073089599609375
train loss item: 0.29881617426872253
train loss item: 0.36321255564689636
train loss item: 0.44291359186172485
train loss item: 0.846362829208374
train loss item: 1.039322853088379
train loss item: 0.25906282663345337
train loss item: 0.698800802230835
train loss item: 1.4358466863632202
train loss item: 0.3205110430717468
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.070176601409912
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3621932864189148
train loss item: 0.45830103754997253
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 32 360 done at Thu Nov 14 11:55:26 CET 2024
UNet6 with 1 10 0.0001 64 360 start at Thu Nov 14 11:55:26 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 64
memory after loading model
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Epoch 1/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.819812536239624
train loss item: 0.9529114365577698
train loss item: 2.3863213062286377
train loss item: 2.270076036453247
train loss item: 0.6869325637817383
train loss item: 0.46848130226135254
train loss item: 0.5421428680419922
train loss item: 1.5739983320236206
train loss item: 1.2186293601989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5850042104721069
train loss item: 0.7131848931312561
train loss item: 0.5979920029640198
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.130446195602417
train loss item: 0.47118911147117615
train loss item: 0.5719398856163025
train loss item: 1.110304594039917
train loss item: 0.48696455359458923
train loss item: 0.7697487473487854
train loss item: 0.5989560484886169
train loss item: 1.0078785419464111
train loss item: 0.47610917687416077
train loss item: 0.6136468648910522
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4699391722679138
train loss item: 0.8132690191268921
train loss item: 1.3295847177505493
train loss item: 0.6827605366706848
train loss item: 0.4973190426826477
train loss item: 0.585635781288147
train loss item: 1.51414155960083
train loss item: 0.45469796657562256
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.624519407749176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9587867259979248
train loss item: 0.6278560161590576
train loss item: 0.49461838603019714
train loss item: 0.7044584155082703
train loss item: 0.5164517164230347
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4544129967689514
train loss item: 1.86475670337677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47753116488456726
train loss item: 2.5423285961151123
train loss item: 1.0763672590255737
train loss item: 1.039473056793213
train loss item: 0.5298306345939636
train loss item: 0.7522132992744446
train loss item: 0.5095365643501282
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48460251092910767
train loss item: 0.8418570160865784
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4620964825153351
train loss item: 0.47385135293006897
train loss item: 1.827709436416626
train loss item: 1.2050328254699707
train loss item: 3.6952083110809326
train loss item: 1.031891942024231
train loss item: 1.2293715476989746
1
train loss item: 0.49924877285957336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0482702255249023
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5716233253479004
train loss item: 4.473301887512207
train loss item: 1.4562150239944458
train loss item: 0.7648544311523438
train loss item: 1.2041324377059937
train loss item: 0.47707146406173706
train loss item: 0.630420446395874
train loss item: 1.144110083580017
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8894302248954773
train loss item: 0.44735756516456604
train loss item: 0.5024728775024414
train loss item: 0.5545372366905212
train loss item: 0.7979448437690735
train loss item: 0.5833857655525208
train loss item: 0.5818025469779968
train loss item: 0.5606418251991272
train loss item: 0.5785847902297974
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.1468136310577393
train loss item: 1.450875163078308
train loss item: 0.6367223858833313
train loss item: 0.5154714584350586
train loss item: 0.5152022838592529
train loss item: 0.528084397315979
train loss item: 0.9421567320823669
train loss item: 0.6088292002677917
train loss item: 0.6201375126838684
train loss item: 0.6374879479408264
train loss item: 0.5473155975341797
train loss item: 0.5828478932380676
train loss item: 0.6870982050895691
train loss item: 0.5076937675476074
train loss item: 2.2537639141082764
train loss item: 0.6441835165023804
train loss item: 0.4633548855781555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6354823112487793
train loss item: 0.5546389818191528
train loss item: 4.452296257019043
train loss item: 0.7913306355476379
train loss item: 0.6001733541488647
train loss item: 0.6769973039627075
train loss item: 0.4553399682044983
train loss item: 0.8695197105407715
train loss item: 0.4755610227584839
train loss item: 0.6617066860198975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5238131284713745
train loss item: 0.5245546698570251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5921008586883545
train loss item: 1.9015032052993774
train loss item: 3.9101366996765137
train loss item: 0.6102474927902222
train loss item: 0.46769586205482483
train loss item: 1.5767532587051392
train loss item: 0.5057856440544128
train loss item: 0.9696930050849915
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.587297797203064
train loss item: 1.0258359909057617
train loss item: 1.5137578248977661
train loss item: 1.074904203414917
train loss item: 0.4704446494579315
train loss item: 0.8295745253562927
train loss item: 0.5119169354438782
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7610528469085693
train loss item: 0.9171606302261353
train loss item: 0.6281032562255859
train loss item: 0.5952099561691284
train loss item: 0.6960201859474182
train loss item: 0.6789958477020264
train loss item: 0.4713931977748871
train loss item: 1.4038227796554565
train loss item: 0.578901469707489
train loss item: 0.48654380440711975
train loss item: 0.7137617468833923
train loss item: 0.586050271987915
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4967315196990967
train loss item: 2.397573947906494
train loss item: 0.7835416197776794
train loss item: 2.8879265785217285
train loss item: 0.5795229077339172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46186575293540955
train loss item: 0.6076156497001648
train loss item: 0.6935876607894897
train loss item: 0.5685961842536926
train loss item: 0.6882216334342957
train loss item: 0.5235651135444641
train loss item: 0.561565101146698
train loss item: 0.5332809686660767
train loss item: 0.7282124757766724
train loss item: 1.192653775215149
train loss item: 1.4065489768981934
train loss item: 0.482292503118515
train loss item: 1.0171582698822021
train loss item: 2.007269859313965
train loss item: 0.48738574981689453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.58840799331665
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6192532181739807
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9542.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.8054918646812439
train loss item: 0.8987407088279724
train loss item: 2.2919647693634033
train loss item: 1.7529160976409912
train loss item: 0.619989275932312
train loss item: 0.40582361817359924
train loss item: 0.41985389590263367
train loss item: 1.4629015922546387
train loss item: 0.8853329420089722
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5445839762687683
train loss item: 0.674015462398529
train loss item: 0.4879615008831024
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.0255072116851807
train loss item: 0.42342409491539
train loss item: 0.4279136657714844
train loss item: 0.7758976221084595
train loss item: 0.3747066557407379
train loss item: 0.6917065382003784
train loss item: 0.4910371005535126
train loss item: 0.9175930619239807
train loss item: 0.41859519481658936
train loss item: 0.5455162525177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4035603404045105
train loss item: 0.7738136053085327
train loss item: 1.258652925491333
train loss item: 0.6637643575668335
train loss item: 0.4387687146663666
train loss item: 0.5114082098007202
train loss item: 1.4561054706573486
train loss item: 0.3829658627510071
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.524093747138977
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9038376212120056
train loss item: 0.5851014256477356
train loss item: 0.4196215569972992
train loss item: 0.6253869533538818
train loss item: 0.46743452548980713
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3872469365596771
train loss item: 1.8338868618011475
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41059255599975586
train loss item: 2.443751335144043
train loss item: 1.0170003175735474
train loss item: 0.995087206363678
train loss item: 0.40507644414901733
train loss item: 0.6749089360237122
train loss item: 0.4420895576477051
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43542855978012085
train loss item: 0.7903597950935364
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.38722386956214905
train loss item: 0.3567829728126526
train loss item: 1.8009729385375977
train loss item: 1.1887037754058838
train loss item: 3.5324246883392334
train loss item: 0.9487202763557434
train loss item: 1.1619105339050293
1
train loss item: 0.4423845112323761
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9855327606201172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008445143699646
train loss item: 4.32944393157959
train loss item: 1.3845133781433105
train loss item: 0.7258349061012268
train loss item: 1.1670548915863037
train loss item: 0.4191601872444153
train loss item: 0.5944328904151917
train loss item: 1.1055978536605835
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8371577262878418
train loss item: 0.39751115441322327
train loss item: 0.35939866304397583
train loss item: 0.48182982206344604
train loss item: 0.7070066332817078
train loss item: 0.5354675054550171
train loss item: 0.49496012926101685
train loss item: 0.4740426540374756
train loss item: 0.530408501625061
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0800422430038452
train loss item: 1.3574137687683105
train loss item: 0.46985873579978943
train loss item: 0.4406193196773529
train loss item: 0.446282297372818
train loss item: 0.4453347325325012
train loss item: 0.8741986751556396
train loss item: 0.5293667912483215
train loss item: 0.5353571176528931
train loss item: 0.5791845321655273
train loss item: 0.5059974789619446
train loss item: 0.4314745366573334
train loss item: 0.6558837294578552
train loss item: 0.42855778336524963
train loss item: 2.206753730773926
train loss item: 0.6051461696624756
train loss item: 0.3908587694168091
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5420536398887634
train loss item: 0.3993499279022217
train loss item: 4.305393695831299
train loss item: 0.7225639224052429
train loss item: 0.537074863910675
train loss item: 0.44736871123313904
train loss item: 0.38459938764572144
train loss item: 0.7890965938568115
train loss item: 0.414558082818985
train loss item: 0.603987991809845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46700191497802734
train loss item: 0.4694973826408386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5276029109954834
train loss item: 1.850875973701477
train loss item: 3.771341323852539
train loss item: 0.464836061000824
train loss item: 0.3977920413017273
train loss item: 1.2948168516159058
train loss item: 0.44135576486587524
train loss item: 0.9448678493499756
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5373835563659668
train loss item: 0.9716783761978149
train loss item: 1.4940139055252075
train loss item: 1.019716739654541
train loss item: 0.4043095111846924
train loss item: 0.6526936292648315
train loss item: 0.4361291527748108
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6763297915458679
train loss item: 0.846520721912384
train loss item: 0.5822674632072449
train loss item: 0.5073311924934387
train loss item: 0.6249715685844421
train loss item: 0.4491252601146698
train loss item: 0.41228458285331726
train loss item: 0.9837915897369385
train loss item: 0.43238136172294617
train loss item: 0.3756480813026428
train loss item: 0.6602489352226257
train loss item: 0.43490418791770935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4389401078224182
train loss item: 2.278047800064087
train loss item: 0.7019065022468567
train loss item: 2.877516031265259
train loss item: 0.5246642231941223
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3866238594055176
train loss item: 0.5449886918067932
train loss item: 0.6539317965507507
train loss item: 0.4264691472053528
train loss item: 0.45463478565216064
train loss item: 0.45638638734817505
train loss item: 0.4559684693813324
train loss item: 0.47985419631004333
train loss item: 0.6698529720306396
train loss item: 1.1541709899902344
train loss item: 1.3551671504974365
train loss item: 0.42673611640930176
train loss item: 0.969355583190918
train loss item: 1.86638605594635
train loss item: 0.41490432620048523
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.436746597290039
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5215848684310913
train loss item: 0.6882298588752747
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.8051015734672546
train loss item: 0.8529430627822876
train loss item: 2.214339017868042
train loss item: 1.5116938352584839
train loss item: 0.5819724798202515
train loss item: 0.4383721649646759
train loss item: 0.41861456632614136
train loss item: 1.3880025148391724
train loss item: 0.7734600305557251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5285988450050354
train loss item: 0.6681726574897766
train loss item: 0.4541483521461487
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.9507399797439575
train loss item: 0.39212068915367126
train loss item: 0.3957740068435669
train loss item: 0.7045068740844727
train loss item: 0.3592888116836548
train loss item: 0.640126645565033
train loss item: 0.45678287744522095
train loss item: 0.8674015998840332
train loss item: 0.3970751464366913
train loss item: 0.5010831356048584
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37873467803001404
train loss item: 0.7549389600753784
train loss item: 1.209031105041504
train loss item: 0.6678506731987
train loss item: 0.41784077882766724
train loss item: 0.4937847852706909
train loss item: 1.4121454954147339
train loss item: 0.35888829827308655
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4921519160270691
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8699957728385925
train loss item: 0.5450640916824341
train loss item: 0.3905563950538635
train loss item: 0.5765966773033142
train loss item: 0.43139874935150146
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3643650412559509
train loss item: 1.7877963781356812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3885669708251953
train loss item: 2.3744027614593506
train loss item: 0.9635235071182251
train loss item: 0.9398651123046875
train loss item: 0.3759452998638153
train loss item: 0.6498486995697021
train loss item: 0.42940425872802734
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4148862063884735
train loss item: 0.7516554594039917
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35976043343544006
train loss item: 0.34368252754211426
train loss item: 1.7625540494918823
train loss item: 1.1395182609558105
train loss item: 3.423069477081299
train loss item: 0.9135857224464417
train loss item: 1.1172702312469482
1
train loss item: 0.4248979389667511
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9466566443443298
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4133960008621216
train loss item: 4.23195743560791
train loss item: 1.3307774066925049
train loss item: 0.7032762765884399
train loss item: 1.1340081691741943
train loss item: 0.390132337808609
train loss item: 0.5579783916473389
train loss item: 1.0716018676757812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.802668571472168
train loss item: 0.38565701246261597
train loss item: 0.32250872254371643
train loss item: 0.47355711460113525
train loss item: 0.661649763584137
train loss item: 0.5043798685073853
train loss item: 0.4497036635875702
train loss item: 0.438198983669281
train loss item: 0.5030548572540283
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0335768461227417
train loss item: 1.2954051494598389
train loss item: 0.44945961236953735
train loss item: 0.41032615303993225
train loss item: 0.44713613390922546
train loss item: 0.4125525653362274
train loss item: 0.8212732076644897
train loss item: 0.5073781609535217
train loss item: 0.5154852271080017
train loss item: 0.5469192266464233
train loss item: 0.4909832775592804
train loss item: 0.3931466341018677
train loss item: 0.621256947517395
train loss item: 0.39793649315834045
train loss item: 2.1539275646209717
train loss item: 0.5704979300498962
train loss item: 0.3635222911834717
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.516581118106842
train loss item: 0.403873085975647
train loss item: 4.208215236663818
train loss item: 0.6724585890769958
train loss item: 0.5222636461257935
train loss item: 0.4144033193588257
train loss item: 0.35863155126571655
train loss item: 0.746972918510437
train loss item: 0.3903963267803192
train loss item: 0.5846830606460571
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43731755018234253
train loss item: 0.4497511386871338
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.481804609298706
train loss item: 1.7918583154678345
train loss item: 3.672724723815918
train loss item: 0.42840874195098877
train loss item: 0.36995062232017517
train loss item: 1.1104559898376465
train loss item: 0.41665565967559814
train loss item: 0.9020617604255676
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5116944313049316
train loss item: 0.9252290725708008
train loss item: 1.414633870124817
train loss item: 0.9859626293182373
train loss item: 0.3803067207336426
train loss item: 0.5922043323516846
train loss item: 0.402712345123291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6224695444107056
train loss item: 0.794919490814209
train loss item: 0.5667665600776672
train loss item: 0.4867575764656067
train loss item: 0.5816335678100586
train loss item: 0.4143410921096802
train loss item: 0.44441157579421997
train loss item: 0.8031931519508362
train loss item: 0.40109309554100037
train loss item: 0.3602941930294037
train loss item: 0.627627432346344
train loss item: 0.3945261240005493
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4165565073490143
train loss item: 2.199267625808716
train loss item: 0.6530634164810181
train loss item: 2.8289592266082764
train loss item: 0.5036813020706177
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3602833151817322
train loss item: 0.5181873440742493
train loss item: 0.6069742441177368
train loss item: 0.4211292862892151
train loss item: 0.40407049655914307
train loss item: 0.4450536072254181
train loss item: 0.4276082515716553
train loss item: 0.4543696343898773
train loss item: 0.6541560292243958
train loss item: 1.1092151403427124
train loss item: 1.3023735284805298
train loss item: 0.39061033725738525
train loss item: 0.9333477020263672
train loss item: 1.7632112503051758
train loss item: 0.39761194586753845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.3332133293151855
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4968581199645996
train loss item: 0.6446283459663391
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.7930572628974915
train loss item: 0.8106309175491333
train loss item: 2.154629945755005
train loss item: 1.4358925819396973
train loss item: 0.5403582453727722
train loss item: 0.42518410086631775
train loss item: 0.3946791887283325
train loss item: 1.337820291519165
train loss item: 0.7283328771591187
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5086467266082764
train loss item: 0.6587628722190857
train loss item: 0.43243226408958435
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8997114896774292
train loss item: 0.3564055263996124
train loss item: 0.3781545162200928
train loss item: 0.6633870601654053
train loss item: 0.34436315298080444
train loss item: 0.6021005511283875
train loss item: 0.4337024390697479
train loss item: 0.8381946086883545
train loss item: 0.3798515796661377
train loss item: 0.46760791540145874
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36306190490722656
train loss item: 0.7336841821670532
train loss item: 1.1666553020477295
train loss item: 0.6589175462722778
train loss item: 0.40363696217536926
train loss item: 0.4622725248336792
train loss item: 1.3715578317642212
train loss item: 0.3419116735458374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46878868341445923
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8391717672348022
train loss item: 0.5013014674186707
train loss item: 0.37441208958625793
train loss item: 0.5385311841964722
train loss item: 0.3904067277908325
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35047394037246704
train loss item: 1.732211947441101
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3668222427368164
train loss item: 2.326054096221924
train loss item: 0.9112567901611328
train loss item: 0.8813654184341431
train loss item: 0.35766473412513733
train loss item: 0.6242033839225769
train loss item: 0.4178542494773865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39821115136146545
train loss item: 0.7165666818618774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34212782979011536
train loss item: 0.3284926116466522
train loss item: 1.7136108875274658
train loss item: 0.9933941960334778
train loss item: 3.3595523834228516
train loss item: 0.8102750778198242
train loss item: 1.0816224813461304
1
train loss item: 0.413299024105072
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9135479927062988
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4067084491252899
train loss item: 4.174579620361328
train loss item: 1.2894893884658813
train loss item: 0.6825628876686096
train loss item: 1.094824194908142
train loss item: 0.36362388730049133
train loss item: 0.5129873752593994
train loss item: 1.030917763710022
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7728220224380493
train loss item: 0.37418532371520996
train loss item: 0.30440935492515564
train loss item: 0.46403172612190247
train loss item: 0.6374162435531616
train loss item: 0.47682198882102966
train loss item: 0.4160236716270447
train loss item: 0.41514167189598083
train loss item: 0.4792505204677582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9984489679336548
train loss item: 1.2547656297683716
train loss item: 0.42159074544906616
train loss item: 0.3940301835536957
train loss item: 0.43876731395721436
train loss item: 0.3962877094745636
train loss item: 0.7742434144020081
train loss item: 0.48457634449005127
train loss item: 0.4956094026565552
train loss item: 0.5226385593414307
train loss item: 0.4763917326927185
train loss item: 0.3738737106323242
train loss item: 0.5782414078712463
train loss item: 0.3818342983722687
train loss item: 2.098876714706421
train loss item: 0.5317774415016174
train loss item: 0.34576982259750366
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.49367421865463257
train loss item: 0.38496139645576477
train loss item: 4.151196479797363
train loss item: 0.6276695728302002
train loss item: 0.5083506107330322
train loss item: 0.4003390669822693
train loss item: 0.34301993250846863
train loss item: 0.722851037979126
train loss item: 0.37242257595062256
train loss item: 0.5657562613487244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41457399725914
train loss item: 0.43614786863327026
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4422942399978638
train loss item: 1.7304792404174805
train loss item: 3.612187385559082
train loss item: 0.4083971083164215
train loss item: 0.35246723890304565
train loss item: 0.9530659914016724
train loss item: 0.40092340111732483
train loss item: 0.8486791849136353
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.490337997674942
train loss item: 0.8784583210945129
train loss item: 1.2507680654525757
train loss item: 0.9552468061447144
train loss item: 0.3652568459510803
train loss item: 0.5493290424346924
train loss item: 0.3815479874610901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5802987217903137
train loss item: 0.7484342455863953
train loss item: 0.5494769811630249
train loss item: 0.4643653333187103
train loss item: 0.5457404851913452
train loss item: 0.3989465534687042
train loss item: 0.42997774481773376
train loss item: 0.7423388957977295
train loss item: 0.38405466079711914
train loss item: 0.3448895215988159
train loss item: 0.5970014333724976
train loss item: 0.376468688249588
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40056467056274414
train loss item: 2.1499416828155518
train loss item: 0.6170884370803833
train loss item: 2.7615437507629395
train loss item: 0.4902063310146332
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.342864990234375
train loss item: 0.5018545985221863
train loss item: 0.5526416301727295
train loss item: 0.3963841199874878
train loss item: 0.3859878480434418
train loss item: 0.43436458706855774
train loss item: 0.40195322036743164
train loss item: 0.4347972571849823
train loss item: 0.6304241418838501
train loss item: 1.0596929788589478
train loss item: 1.2464430332183838
train loss item: 0.35329416394233704
train loss item: 0.8949295878410339
train loss item: 1.693165898323059
train loss item: 0.38602107763290405
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.273541450500488
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47628358006477356
train loss item: 0.6043571829795837
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.7696083784103394
train loss item: 0.7738329172134399
train loss item: 2.1072099208831787
train loss item: 1.4392237663269043
train loss item: 0.5005015730857849
train loss item: 0.3845720589160919
train loss item: 0.3539958596229553
train loss item: 1.3030188083648682
train loss item: 0.7387155294418335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48472341895103455
train loss item: 0.6403278708457947
train loss item: 0.413040429353714
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8626539707183838
train loss item: 0.324313223361969
train loss item: 0.35225561261177063
train loss item: 0.6438730955123901
train loss item: 0.32586467266082764
train loss item: 0.574292778968811
train loss item: 0.41302573680877686
train loss item: 0.8201944231987
train loss item: 0.36107563972473145
train loss item: 0.4429234266281128
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480510413646698
train loss item: 0.7084197998046875
train loss item: 1.1274973154067993
train loss item: 0.6368315815925598
train loss item: 0.3884425163269043
train loss item: 0.41889122128486633
train loss item: 1.3325780630111694
train loss item: 0.32780951261520386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44647303223609924
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.807952344417572
train loss item: 0.4614025950431824
train loss item: 0.3634142279624939
train loss item: 0.507057785987854
train loss item: 0.35348328948020935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3369205892086029
train loss item: 1.6761924028396606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34206584095954895
train loss item: 2.289836883544922
train loss item: 0.8633443713188171
train loss item: 0.8268972635269165
train loss item: 0.33858802914619446
train loss item: 0.5944257974624634
train loss item: 0.39823782444000244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.382181316614151
train loss item: 0.6845089793205261
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32874244451522827
train loss item: 0.3081795275211334
train loss item: 1.6619094610214233
train loss item: 0.8459346890449524
train loss item: 3.321760416030884
train loss item: 0.7155598998069763
train loss item: 1.0504289865493774
1
train loss item: 0.40089112520217896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8821102380752563
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3742945194244385
train loss item: 4.1395344734191895
train loss item: 1.2572300434112549
train loss item: 0.6645398736000061
train loss item: 1.0516414642333984
train loss item: 0.3420185446739197
train loss item: 0.4718320369720459
train loss item: 0.9858909249305725
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7448924779891968
train loss item: 0.3587813079357147
train loss item: 0.2892478406429291
train loss item: 0.446908563375473
train loss item: 0.6241509914398193
train loss item: 0.452237606048584
train loss item: 0.38668879866600037
train loss item: 0.39500245451927185
train loss item: 0.4571174681186676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9703024625778198
train loss item: 1.2268974781036377
train loss item: 0.38222089409828186
train loss item: 0.3834834098815918
train loss item: 0.4158337712287903
train loss item: 0.38689056038856506
train loss item: 0.7324391007423401
train loss item: 0.4568125903606415
train loss item: 0.46983617544174194
train loss item: 0.5018084049224854
train loss item: 0.45918580889701843
train loss item: 0.34954211115837097
train loss item: 0.5389177799224854
train loss item: 0.3717734217643738
train loss item: 2.0475189685821533
train loss item: 0.49729806184768677
train loss item: 0.33280983567237854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4671946167945862
train loss item: 0.34541434049606323
train loss item: 4.116434574127197
train loss item: 0.5871601700782776
train loss item: 0.4871812164783478
train loss item: 0.3709505498409271
train loss item: 0.3285726010799408
train loss item: 0.7077078819274902
train loss item: 0.3541874587535858
train loss item: 0.540101170539856
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39517709612846375
train loss item: 0.4215240776538849
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4052671194076538
train loss item: 1.6727595329284668
train loss item: 3.5740201473236084
train loss item: 0.3823288679122925
train loss item: 0.33647620677948
train loss item: 0.8517757058143616
train loss item: 0.38571423292160034
train loss item: 0.7971600890159607
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47017186880111694
train loss item: 0.8344438076019287
train loss item: 1.068676471710205
train loss item: 0.9240391254425049
train loss item: 0.35040900111198425
train loss item: 0.511786937713623
train loss item: 0.36324790120124817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5441670417785645
train loss item: 0.7062374949455261
train loss item: 0.5278030037879944
train loss item: 0.43699127435684204
train loss item: 0.5143771767616272
train loss item: 0.3693526089191437
train loss item: 0.3911777138710022
train loss item: 0.763845682144165
train loss item: 0.35922425985336304
train loss item: 0.3260841965675354
train loss item: 0.566985011100769
train loss item: 0.3556440770626068
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3841143846511841
train loss item: 2.1170198917388916
train loss item: 0.5884301662445068
train loss item: 2.694685697555542
train loss item: 0.4767865240573883
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.328854501247406
train loss item: 0.4874052405357361
train loss item: 0.501418948173523
train loss item: 0.35631272196769714
train loss item: 0.3638763725757599
train loss item: 0.415113240480423
train loss item: 0.3737080991268158
train loss item: 0.41739779710769653
train loss item: 0.5961752533912659
train loss item: 1.011290192604065
train loss item: 1.192165732383728
train loss item: 0.3219052255153656
train loss item: 0.8539865016937256
train loss item: 1.6443272829055786
train loss item: 0.3701934218406677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.238527774810791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.45275771617889404
train loss item: 0.564845860004425
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.7437087893486023
train loss item: 0.7437713742256165
train loss item: 2.0666611194610596
train loss item: 1.4547584056854248
train loss item: 0.4739750623703003
train loss item: 0.3508828282356262
train loss item: 0.3234092891216278
train loss item: 1.2739440202713013
train loss item: 0.7835104465484619
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647943675518036
train loss item: 0.6195951104164124
train loss item: 0.3989918529987335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.83207368850708
train loss item: 0.30287811160087585
train loss item: 0.32705992460250854
train loss item: 0.6540850400924683
train loss item: 0.32307741045951843
train loss item: 0.553713858127594
train loss item: 0.3983871340751648
train loss item: 0.8048974275588989
train loss item: 0.34606677293777466
train loss item: 0.42535436153411865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33705025911331177
train loss item: 0.6835212707519531
train loss item: 1.089398980140686
train loss item: 0.6109908223152161
train loss item: 0.37597376108169556
train loss item: 0.38276466727256775
train loss item: 1.2975618839263916
train loss item: 0.3183952271938324
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4295913279056549
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7786715626716614
train loss item: 0.43221718072891235
train loss item: 0.3559081554412842
train loss item: 0.48468106985092163
train loss item: 0.32916566729545593
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3274155557155609
train loss item: 1.625609278678894
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32250678539276123
train loss item: 2.256333589553833
train loss item: 0.8248248100280762
train loss item: 0.7831247448921204
train loss item: 0.32505783438682556
train loss item: 0.5658968687057495
train loss item: 0.37843772768974304
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37125566601753235
train loss item: 0.657664954662323
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3204960823059082
train loss item: 0.3045646548271179
train loss item: 1.614041805267334
train loss item: 0.7644869685173035
train loss item: 3.2923824787139893
train loss item: 0.6829583048820496
train loss item: 1.0228385925292969
1
train loss item: 0.38931605219841003
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8528540134429932
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3485627770423889
train loss item: 4.111616611480713
train loss item: 1.2297002077102661
train loss item: 0.6492116451263428
train loss item: 1.008128046989441
train loss item: 0.3284187912940979
train loss item: 0.4428568184375763
train loss item: 0.9412129521369934
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7195854187011719
train loss item: 0.34543299674987793
train loss item: 0.2819531559944153
train loss item: 0.4309505522251129
train loss item: 0.6133702993392944
train loss item: 0.43492189049720764
train loss item: 0.3658623695373535
train loss item: 0.37986767292022705
train loss item: 0.44018375873565674
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9464237093925476
train loss item: 1.2035741806030273
train loss item: 0.3545955717563629
train loss item: 0.3758346438407898
train loss item: 0.39175179600715637
train loss item: 0.3806363046169281
train loss item: 0.6995801329612732
train loss item: 0.43269583582878113
train loss item: 0.44496119022369385
train loss item: 0.4859105348587036
train loss item: 0.4437786638736725
train loss item: 0.3284643292427063
train loss item: 0.5112730264663696
train loss item: 0.36504316329956055
train loss item: 2.0017402172088623
train loss item: 0.47355973720550537
train loss item: 0.32535889744758606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4425390660762787
train loss item: 0.3178510069847107
train loss item: 4.0886030197143555
train loss item: 0.5539808869361877
train loss item: 0.4657462239265442
train loss item: 0.35042551159858704
train loss item: 0.318915456533432
train loss item: 0.6950581073760986
train loss item: 0.34033575654029846
train loss item: 0.5144366025924683
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3827149271965027
train loss item: 0.4091763198375702
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.3682557344436646
train loss item: 1.6217763423919678
train loss item: 3.543980598449707
train loss item: 0.35708898305892944
train loss item: 0.3252008557319641
train loss item: 0.8107115626335144
train loss item: 0.37360048294067383
train loss item: 0.7553129196166992
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4545861482620239
train loss item: 0.7977326512336731
train loss item: 0.9332625269889832
train loss item: 0.8923819065093994
train loss item: 0.339046835899353
train loss item: 0.4856336712837219
train loss item: 0.3496454358100891
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5165325999259949
train loss item: 0.6721661686897278
train loss item: 0.5066771507263184
train loss item: 0.41250136494636536
train loss item: 0.4908815622329712
train loss item: 0.3487595319747925
train loss item: 0.3607846796512604
train loss item: 0.8139474987983704
train loss item: 0.33619898557662964
train loss item: 0.3233568072319031
train loss item: 0.5422070026397705
train loss item: 0.33855047821998596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3711854815483093
train loss item: 2.088186502456665
train loss item: 0.5678302049636841
train loss item: 2.637929677963257
train loss item: 0.46539825201034546
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31939923763275146
train loss item: 0.47557511925697327
train loss item: 0.46110841631889343
train loss item: 0.3283836245536804
train loss item: 0.35422033071517944
train loss item: 0.39511236548423767
train loss item: 0.35176724195480347
train loss item: 0.4055427610874176
train loss item: 0.5598140954971313
train loss item: 0.9668205976486206
train loss item: 1.1445995569229126
train loss item: 0.3026847243309021
train loss item: 0.8137850761413574
train loss item: 1.6032146215438843
train loss item: 0.35565489530563354
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.211021900177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43184077739715576
train loss item: 0.5301486849784851
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.723175048828125
train loss item: 0.718856155872345
train loss item: 2.028942108154297
train loss item: 1.4304053783416748
train loss item: 0.45900553464889526
train loss item: 0.33748161792755127
train loss item: 0.31310099363327026
train loss item: 1.2421724796295166
train loss item: 0.8151156306266785
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4519675076007843
train loss item: 0.6022875308990479
train loss item: 0.38473716378211975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8026916980743408
train loss item: 0.287600040435791
train loss item: 0.30573081970214844
train loss item: 0.652103841304779
train loss item: 0.3306933641433716
train loss item: 0.5344435572624207
train loss item: 0.38471439480781555
train loss item: 0.7849844098091125
train loss item: 0.33515018224716187
train loss item: 0.40964803099632263
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3287726640701294
train loss item: 0.6621514558792114
train loss item: 1.0514967441558838
train loss item: 0.5896925330162048
train loss item: 0.36614593863487244
train loss item: 0.36037692427635193
train loss item: 1.2676422595977783
train loss item: 0.3083057403564453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41466179490089417
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7532024383544922
train loss item: 0.41358983516693115
train loss item: 0.3455303907394409
train loss item: 0.4698421061038971
train loss item: 0.3146267831325531
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3215275704860687
train loss item: 1.5843149423599243
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3101251423358917
train loss item: 2.220048666000366
train loss item: 0.7976096272468567
train loss item: 0.7521964311599731
train loss item: 0.31254225969314575
train loss item: 0.5406280159950256
train loss item: 0.36393192410469055
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3654620349407196
train loss item: 0.636022686958313
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3111319839954376
train loss item: 0.3127814531326294
train loss item: 1.5739250183105469
train loss item: 0.735058069229126
train loss item: 3.2600882053375244
train loss item: 0.6824032664299011
train loss item: 0.9979923367500305
1
train loss item: 0.3777829110622406
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.826256513595581
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3405210077762604
train loss item: 4.080611228942871
train loss item: 1.2025891542434692
train loss item: 0.6337785124778748
train loss item: 0.9671251177787781
train loss item: 0.3173796534538269
train loss item: 0.4255298674106598
train loss item: 0.9008482694625854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.69732666015625
train loss item: 0.33567777276039124
train loss item: 0.27587974071502686
train loss item: 0.4161907136440277
train loss item: 0.5964747071266174
train loss item: 0.42475447058677673
train loss item: 0.35216233134269714
train loss item: 0.36862891912460327
train loss item: 0.42884722352027893
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.924312174320221
train loss item: 1.1783323287963867
train loss item: 0.34544917941093445
train loss item: 0.3645091652870178
train loss item: 0.3730444312095642
train loss item: 0.3705114424228668
train loss item: 0.6758893728256226
train loss item: 0.41454723477363586
train loss item: 0.4214242398738861
train loss item: 0.4737102687358856
train loss item: 0.4317299723625183
train loss item: 0.3111536204814911
train loss item: 0.49499887228012085
train loss item: 0.35472050309181213
train loss item: 1.961248755455017
train loss item: 0.45868903398513794
train loss item: 0.3169795572757721
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4208192527294159
train loss item: 0.3132786750793457
train loss item: 4.057366371154785
train loss item: 0.5287954807281494
train loss item: 0.4487692713737488
train loss item: 0.33699437975883484
train loss item: 0.3130371570587158
train loss item: 0.6779537200927734
train loss item: 0.3303520083427429
train loss item: 0.4945813715457916
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37621408700942993
train loss item: 0.3988354504108429
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.330076813697815
train loss item: 1.579289197921753
train loss item: 3.5126287937164307
train loss item: 0.3340296745300293
train loss item: 0.3169589936733246
train loss item: 0.7846478223800659
train loss item: 0.3635338246822357
train loss item: 0.725496232509613
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44399502873420715
train loss item: 0.7699281573295593
train loss item: 0.8696199655532837
train loss item: 0.8602725863456726
train loss item: 0.3302028179168701
train loss item: 0.4687436521053314
train loss item: 0.33963802456855774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4965958893299103
train loss item: 0.6479334235191345
train loss item: 0.48864591121673584
train loss item: 0.39237332344055176
train loss item: 0.47472578287124634
train loss item: 0.33520302176475525
train loss item: 0.3509271442890167
train loss item: 0.8338758945465088
train loss item: 0.31649288535118103
train loss item: 0.33143237233161926
train loss item: 0.5244999527931213
train loss item: 0.324046790599823
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36128175258636475
train loss item: 2.0560989379882812
train loss item: 0.553006112575531
train loss item: 2.594550609588623
train loss item: 0.45530781149864197
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3091706931591034
train loss item: 0.4647732377052307
train loss item: 0.43392854928970337
train loss item: 0.321036696434021
train loss item: 0.34806233644485474
train loss item: 0.37958210706710815
train loss item: 0.3358091115951538
train loss item: 0.3980853259563446
train loss item: 0.526502251625061
train loss item: 0.9276179671287537
train loss item: 1.1062926054000854
train loss item: 0.2902069091796875
train loss item: 0.7763500809669495
train loss item: 1.5605475902557373
train loss item: 0.3448650538921356
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.180288791656494
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4129044711589813
train loss item: 0.5026814937591553
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.7098458409309387
train loss item: 0.6970778703689575
train loss item: 1.993215560913086
train loss item: 1.361167550086975
train loss item: 0.4433552026748657
train loss item: 0.3333328068256378
train loss item: 0.3102828562259674
train loss item: 1.2063350677490234
train loss item: 0.8118047714233398
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4439007639884949
train loss item: 0.5893954634666443
train loss item: 0.3698454797267914
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7727218866348267
train loss item: 0.27374371886253357
train loss item: 0.2851434350013733
train loss item: 0.6276633143424988
train loss item: 0.3264438509941101
train loss item: 0.5133658647537231
train loss item: 0.37052497267723083
train loss item: 0.7600528001785278
train loss item: 0.324270099401474
train loss item: 0.39370864629745483
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3186584711074829
train loss item: 0.6454132795333862
train loss item: 1.0152084827423096
train loss item: 0.575340986251831
train loss item: 0.3553259074687958
train loss item: 0.34137189388275146
train loss item: 1.2435381412506104
train loss item: 0.29306724667549133
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008773863315582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.731844425201416
train loss item: 0.4023657441139221
train loss item: 0.3284552991390228
train loss item: 0.45803284645080566
train loss item: 0.30404379963874817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31538671255111694
train loss item: 1.5533117055892944
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3011203706264496
train loss item: 2.1825239658355713
train loss item: 0.7800406217575073
train loss item: 0.7315957546234131
train loss item: 0.29639318585395813
train loss item: 0.5183584690093994
train loss item: 0.3537620007991791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583802580833435
train loss item: 0.6166451573371887
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2961908280849457
train loss item: 0.3096919357776642
train loss item: 1.5434669256210327
train loss item: 0.7250176072120667
train loss item: 3.2225394248962402
train loss item: 0.6801353096961975
train loss item: 0.975432276725769
1
train loss item: 0.36429905891418457
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8020622134208679
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33765748143196106
train loss item: 4.044615268707275
train loss item: 1.174917459487915
train loss item: 0.6165820956230164
train loss item: 0.9317919611930847
train loss item: 0.30421990156173706
train loss item: 0.41483116149902344
train loss item: 0.8679857850074768
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6773892045021057
train loss item: 0.3277986943721771
train loss item: 0.26407402753829956
train loss item: 0.3954724073410034
train loss item: 0.5719655156135559
train loss item: 0.41636985540390015
train loss item: 0.34038442373275757
train loss item: 0.35828423500061035
train loss item: 0.4188620150089264
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9020735025405884
train loss item: 1.1499011516571045
train loss item: 0.3417537212371826
train loss item: 0.34626662731170654
train loss item: 0.35472482442855835
train loss item: 0.35314419865608215
train loss item: 0.6580479145050049
train loss item: 0.3996224105358124
train loss item: 0.4013262093067169
train loss item: 0.46032166481018066
train loss item: 0.42160987854003906
train loss item: 0.2922847867012024
train loss item: 0.48536011576652527
train loss item: 0.3375800549983978
train loss item: 1.9268697500228882
train loss item: 0.44759947061538696
train loss item: 0.30262506008148193
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.401305228471756
train loss item: 0.3150266408920288
train loss item: 4.020753860473633
train loss item: 0.509464681148529
train loss item: 0.43568670749664307
train loss item: 0.31719741225242615
train loss item: 0.30639827251434326
train loss item: 0.6550703048706055
train loss item: 0.3199657201766968
train loss item: 0.4804512858390808
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3688831031322479
train loss item: 0.3875214755535126
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2929304838180542
train loss item: 1.545644760131836
train loss item: 3.4781038761138916
train loss item: 0.30991798639297485
train loss item: 0.3069058656692505
train loss item: 0.7484599947929382
train loss item: 0.3521009385585785
train loss item: 0.7055948972702026
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43298038840293884
train loss item: 0.7503966093063354
train loss item: 0.8610623478889465
train loss item: 0.8302368521690369
train loss item: 0.3196645975112915
train loss item: 0.45290619134902954
train loss item: 0.3298962116241455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4801141321659088
train loss item: 0.632495105266571
train loss item: 0.47458669543266296
train loss item: 0.374237596988678
train loss item: 0.4621663987636566
train loss item: 0.31554439663887024
train loss item: 0.34858933091163635
train loss item: 0.8112183809280396
train loss item: 0.2961934208869934
train loss item: 0.3277743458747864
train loss item: 0.512164831161499
train loss item: 0.30690136551856995
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35072124004364014
train loss item: 2.020768642425537
train loss item: 0.5399312376976013
train loss item: 2.5637624263763428
train loss item: 0.44393324851989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2937313914299011
train loss item: 0.4522640109062195
train loss item: 0.417385071516037
train loss item: 0.3195478916168213
train loss item: 0.3309571444988251
train loss item: 0.3678264617919922
train loss item: 0.32141485810279846
train loss item: 0.3885186016559601
train loss item: 0.4946769177913666
train loss item: 0.8951320648193359
train loss item: 1.077818751335144
train loss item: 0.2774108350276947
train loss item: 0.744400680065155
train loss item: 1.5157862901687622
train loss item: 0.33590614795684814
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.143923282623291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3940907418727875
train loss item: 0.4830005466938019
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.7012327909469604
train loss item: 0.6768987774848938
train loss item: 1.959564447402954
train loss item: 1.2730965614318848
train loss item: 0.4245123267173767
train loss item: 0.32746371626853943
train loss item: 0.30321088433265686
train loss item: 1.1697438955307007
train loss item: 0.7816647887229919
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4375529885292053
train loss item: 0.5793851613998413
train loss item: 0.36056557297706604
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7435319423675537
train loss item: 0.2636568248271942
train loss item: 0.26824524998664856
train loss item: 0.6041659712791443
train loss item: 0.30960673093795776
train loss item: 0.4925594627857208
train loss item: 0.3610459864139557
train loss item: 0.7348750233650208
train loss item: 0.31261447072029114
train loss item: 0.37968042492866516
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3064850866794586
train loss item: 0.6322617530822754
train loss item: 0.9828314185142517
train loss item: 0.5660059452056885
train loss item: 0.34321141242980957
train loss item: 0.3221050202846527
train loss item: 1.2249256372451782
train loss item: 0.27635854482650757
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39237332344055176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.71439528465271
train loss item: 0.3958813548088074
train loss item: 0.3083411157131195
train loss item: 0.44660109281539917
train loss item: 0.2972389757633209
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3084021806716919
train loss item: 1.530341625213623
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2934279143810272
train loss item: 2.146493673324585
train loss item: 0.767556369304657
train loss item: 0.7163669466972351
train loss item: 0.27946630120277405
train loss item: 0.49904075264930725
train loss item: 0.3460235297679901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480775058269501
train loss item: 0.5983378291130066
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.27943864464759827
train loss item: 0.2939455211162567
train loss item: 1.5210046768188477
train loss item: 0.7247592210769653
train loss item: 3.1832032203674316
train loss item: 0.6760433912277222
train loss item: 0.9549425840377808
1
train loss item: 0.3498036563396454
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7805810570716858
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3302747905254364
train loss item: 4.007093906402588
train loss item: 1.1479820013046265
train loss item: 0.5999115705490112
train loss item: 0.9031261205673218
train loss item: 0.2931276857852936
train loss item: 0.4080217480659485
train loss item: 0.8418792486190796
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6597893238067627
train loss item: 0.32146796584129333
train loss item: 0.24960766732692719
train loss item: 0.3697932958602905
train loss item: 0.5459722876548767
train loss item: 0.4065341055393219
train loss item: 0.3288898468017578
train loss item: 0.3475848436355591
train loss item: 0.40844011306762695
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.880405843257904
train loss item: 1.121046543121338
train loss item: 0.3334875702857971
train loss item: 0.32480448484420776
train loss item: 0.33540695905685425
train loss item: 0.33273300528526306
train loss item: 0.6428158283233643
train loss item: 0.38700729608535767
train loss item: 0.38971251249313354
train loss item: 0.44530007243156433
train loss item: 0.4129522740840912
train loss item: 0.27337580919265747
train loss item: 0.47931110858917236
train loss item: 0.31752562522888184
train loss item: 1.8990013599395752
train loss item: 0.43906450271606445
train loss item: 0.2859288454055786
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3845539391040802
train loss item: 0.31036514043807983
train loss item: 3.982544422149658
train loss item: 0.4932782053947449
train loss item: 0.4250364303588867
train loss item: 0.2966454029083252
train loss item: 0.2986525893211365
train loss item: 0.6313495635986328
train loss item: 0.30833685398101807
train loss item: 0.46955808997154236
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583366572856903
train loss item: 0.37499508261680603
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2596176862716675
train loss item: 1.518908977508545
train loss item: 3.4426724910736084
train loss item: 0.2881893217563629
train loss item: 0.29457002878189087
train loss item: 0.7104032635688782
train loss item: 0.33935871720314026
train loss item: 0.6920673847198486
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.42006558179855347
train loss item: 0.7361637949943542
train loss item: 0.8761228919029236
train loss item: 0.8045116066932678
train loss item: 0.30721744894981384
train loss item: 0.4349144697189331
train loss item: 0.32019585371017456
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647907316684723
train loss item: 0.6221219301223755
train loss item: 0.46378180384635925
train loss item: 0.3581021726131439
train loss item: 0.4509026110172272
train loss item: 0.29534807801246643
train loss item: 0.3429086208343506
train loss item: 0.7649170160293579
train loss item: 0.2788582742214203
train loss item: 0.3115488588809967
train loss item: 0.5022445917129517
train loss item: 0.2896858751773834
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.339032381772995
train loss item: 1.9852867126464844
train loss item: 0.5266013741493225
train loss item: 2.5412187576293945
train loss item: 0.43140870332717896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2765684127807617
train loss item: 0.43842560052871704
train loss item: 0.40749555826187134
train loss item: 0.31202223896980286
train loss item: 0.30966389179229736
train loss item: 0.3586636781692505
train loss item: 0.3084482252597809
train loss item: 0.3757885694503784
train loss item: 0.46557512879371643
train loss item: 0.8691501021385193
train loss item: 1.056811809539795
train loss item: 0.26584452390670776
train loss item: 0.719364583492279
train loss item: 1.472780466079712
train loss item: 0.3277837634086609
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.1056928634643555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3768501877784729
train loss item: 0.4697430729866028
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 0.693540632724762
train loss item: 0.6579349637031555
train loss item: 1.928483247756958
train loss item: 1.1928136348724365
train loss item: 0.40681248903274536
train loss item: 0.3173936903476715
train loss item: 0.2905552089214325
train loss item: 1.136673092842102
train loss item: 0.7322322130203247
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4317569434642792
train loss item: 0.5698574185371399
train loss item: 0.3535853922367096
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.717613935470581
train loss item: 0.25894397497177124
train loss item: 0.2580583393573761
train loss item: 0.5890412330627441
train loss item: 0.29087549448013306
train loss item: 0.47456738352775574
train loss item: 0.35363325476646423
train loss item: 0.7146875262260437
train loss item: 0.30186089873313904
train loss item: 0.3687035143375397
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.29473981261253357
train loss item: 0.6211012005805969
train loss item: 0.9554638862609863
train loss item: 0.5585214495658875
train loss item: 0.3318652808666229
train loss item: 0.30660611391067505
train loss item: 1.2095849514007568
train loss item: 0.26302003860473633
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3856435716152191
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7001263499259949
train loss item: 0.39076924324035645
train loss item: 0.2909272015094757
train loss item: 0.4353330731391907
train loss item: 0.2934657633304596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3020230829715729
train loss item: 1.5108436346054077
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.28752565383911133
train loss item: 2.1144323348999023
train loss item: 0.7548717856407166
train loss item: 0.7015661597251892
train loss item: 0.2655992805957794
train loss item: 0.4824598729610443
train loss item: 0.339358389377594
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3373473882675171
train loss item: 0.5819714665412903
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2661121189594269
train loss item: 0.27563580870628357
train loss item: 1.5024704933166504
train loss item: 0.7264050841331482
train loss item: 3.1469216346740723
train loss item: 0.6701516509056091
train loss item: 0.9373541474342346
1
train loss item: 0.33666372299194336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7623443603515625
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3192974925041199
train loss item: 3.9725024700164795
train loss item: 1.1234350204467773
train loss item: 0.5868390202522278
train loss item: 0.8784924745559692
train loss item: 0.28700289130210876
train loss item: 0.40265190601348877
train loss item: 0.818615734577179
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6450898051261902
train loss item: 0.31625646352767944
train loss item: 0.23847685754299164
train loss item: 0.34598883986473083
train loss item: 0.5259736776351929
train loss item: 0.3959523141384125
train loss item: 0.31735894083976746
train loss item: 0.3372364044189453
train loss item: 0.3983061611652374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8612839579582214
train loss item: 1.0949510335922241
train loss item: 0.32029056549072266
train loss item: 0.3059912919998169
train loss item: 0.31798598170280457
train loss item: 0.3149357736110687
train loss item: 0.6279577016830444
train loss item: 0.37705492973327637
train loss item: 0.38158321380615234
train loss item: 0.4312494099140167
train loss item: 0.40601539611816406
train loss item: 0.25878503918647766
train loss item: 0.47405463457107544
train loss item: 0.30011799931526184
train loss item: 1.8759403228759766
train loss item: 0.43228986859321594
train loss item: 0.27250176668167114
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37063175439834595
train loss item: 0.29902151226997375
train loss item: 3.947033166885376
train loss item: 0.478669673204422
train loss item: 0.41550976037979126
train loss item: 0.2823288142681122
train loss item: 0.2913677394390106
train loss item: 0.6122833490371704
train loss item: 0.29741814732551575
train loss item: 0.45951148867607117
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3470873236656189
train loss item: 0.36318981647491455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2315360307693481
train loss item: 1.4951473474502563
train loss item: 3.4098076820373535
train loss item: 0.2728656232357025
train loss item: 0.28271758556365967
train loss item: 0.6820204257965088
train loss item: 0.32747241854667664
train loss item: 0.6805041432380676
2
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40764039754867554
train loss item: 0.7225446701049805
train loss item: 0.8893114328384399
train loss item: 0.7829195261001587
train loss item: 0.29536300897598267
train loss item: 0.41791871190071106
train loss item: 0.31172215938568115
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4493716061115265
train loss item: 0.6113709807395935
train loss item: 0.45497411489486694
train loss item: 0.3454032242298126
train loss item: 0.4403054714202881
train loss item: 0.2816068232059479
train loss item: 0.3324041962623596
train loss item: 0.711246907711029
train loss item: 0.26826685667037964
train loss item: 0.2934325337409973
train loss item: 0.4922246038913727
train loss item: 0.2767014801502228
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3281143307685852
train loss item: 1.952993392944336
train loss item: 0.5135407447814941
train loss item: 2.5215725898742676
train loss item: 0.4196229577064514
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2626209855079651
train loss item: 0.4253860414028168
train loss item: 0.39951568841934204
train loss item: 0.29863911867141724
train loss item: 0.29291844367980957
train loss item: 0.35073089599609375
train loss item: 0.29881617426872253
train loss item: 0.36321255564689636
train loss item: 0.44291359186172485
train loss item: 0.846362829208374
train loss item: 1.039322853088379
train loss item: 0.25906282663345337
train loss item: 0.698800802230835
train loss item: 1.4358466863632202
train loss item: 0.3205110430717468
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.070176601409912
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3621932864189148
train loss item: 0.45830103754997253
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 64 360 done at Thu Nov 14 12:04:22 CET 2024
UNet6 with 1 10 0.0001 128 360 start at Thu Nov 14 12:04:22 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 128
memory after loading model
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Epoch 1/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.819812536239624
train loss item: 0.9529114365577698
train loss item: 2.3863213062286377
train loss item: 2.270076036453247
train loss item: 0.6869325637817383
train loss item: 0.46848130226135254
train loss item: 0.5421428680419922
train loss item: 1.5739983320236206
train loss item: 1.2186293601989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5850042104721069
train loss item: 0.7131848931312561
train loss item: 0.5979920029640198
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.130446195602417
train loss item: 0.47118911147117615
train loss item: 0.5719398856163025
train loss item: 1.110304594039917
train loss item: 0.48696455359458923
train loss item: 0.7697487473487854
train loss item: 0.5989560484886169
train loss item: 1.0078785419464111
train loss item: 0.47610917687416077
train loss item: 0.6136468648910522
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4699391722679138
train loss item: 0.8132690191268921
train loss item: 1.3295847177505493
train loss item: 0.6827605366706848
train loss item: 0.4973190426826477
train loss item: 0.585635781288147
train loss item: 1.51414155960083
train loss item: 0.45469796657562256
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.624519407749176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9587867259979248
train loss item: 0.6278560161590576
train loss item: 0.49461838603019714
train loss item: 0.7044584155082703
train loss item: 0.5164517164230347
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4544129967689514
train loss item: 1.86475670337677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47753116488456726
train loss item: 2.5423285961151123
train loss item: 1.0763672590255737
train loss item: 1.039473056793213
train loss item: 0.5298306345939636
train loss item: 0.7522132992744446
train loss item: 0.5095365643501282
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48460251092910767
train loss item: 0.8418570160865784
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4620964825153351
train loss item: 0.47385135293006897
train loss item: 1.827709436416626
train loss item: 1.2050328254699707
train loss item: 3.6952083110809326
train loss item: 1.031891942024231
train loss item: 1.2293715476989746
train loss item: 0.49924877285957336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0482702255249023
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5716233253479004
train loss item: 4.473301887512207
train loss item: 1.4562150239944458
train loss item: 0.7648544311523438
train loss item: 1.2041324377059937
train loss item: 0.47707146406173706
train loss item: 0.630420446395874
train loss item: 1.144110083580017
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8894302248954773
train loss item: 0.44735756516456604
train loss item: 0.5024728775024414
train loss item: 0.5545372366905212
train loss item: 0.7979448437690735
train loss item: 0.5833857655525208
train loss item: 0.5818025469779968
train loss item: 0.5606418251991272
train loss item: 0.5785847902297974
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.1468136310577393
train loss item: 1.450875163078308
train loss item: 0.6367223858833313
train loss item: 0.5154714584350586
train loss item: 0.5152022838592529
train loss item: 0.528084397315979
train loss item: 0.9421567320823669
train loss item: 0.6088292002677917
train loss item: 0.6201375126838684
train loss item: 0.6374879479408264
train loss item: 0.5473155975341797
train loss item: 0.5828478932380676
train loss item: 0.6870982050895691
train loss item: 0.5076937675476074
train loss item: 2.2537639141082764
train loss item: 0.6441835165023804
train loss item: 0.4633548855781555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6354823112487793
train loss item: 0.5546389818191528
train loss item: 4.452296257019043
train loss item: 0.7913306355476379
train loss item: 0.6001733541488647
train loss item: 0.6769973039627075
train loss item: 0.4553399682044983
train loss item: 0.8695197105407715
train loss item: 0.4755610227584839
train loss item: 0.6617066860198975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5238131284713745
train loss item: 0.5245546698570251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5921008586883545
train loss item: 1.9015032052993774
train loss item: 3.9101366996765137
train loss item: 0.6102474927902222
train loss item: 0.46769586205482483
train loss item: 1.5767532587051392
train loss item: 0.5057856440544128
train loss item: 0.9696930050849915
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.587297797203064
train loss item: 1.0258359909057617
train loss item: 1.5137578248977661
train loss item: 1.074904203414917
train loss item: 0.4704446494579315
train loss item: 0.8295745253562927
train loss item: 0.5119169354438782
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7610528469085693
train loss item: 0.9171606302261353
train loss item: 0.6281032562255859
train loss item: 0.5952099561691284
train loss item: 0.6960201859474182
train loss item: 0.6789958477020264
train loss item: 0.4713931977748871
train loss item: 1.4038227796554565
train loss item: 0.578901469707489
train loss item: 0.48654380440711975
train loss item: 0.7137617468833923
train loss item: 0.586050271987915
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4967315196990967
train loss item: 2.397573947906494
train loss item: 0.7835416197776794
train loss item: 2.8879265785217285
train loss item: 0.5795229077339172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46186575293540955
train loss item: 0.6076156497001648
train loss item: 0.6935876607894897
train loss item: 0.5685961842536926
train loss item: 0.6882216334342957
train loss item: 0.5235651135444641
train loss item: 0.561565101146698
train loss item: 0.5332809686660767
train loss item: 0.7282124757766724
train loss item: 1.192653775215149
train loss item: 1.4065489768981934
train loss item: 0.482292503118515
train loss item: 1.0171582698822021
train loss item: 2.007269859313965
train loss item: 0.48738574981689453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.58840799331665
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6192532181739807
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9542.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.8054918646812439
train loss item: 0.8987407088279724
train loss item: 2.2919647693634033
train loss item: 1.7529160976409912
train loss item: 0.619989275932312
train loss item: 0.40582361817359924
train loss item: 0.41985389590263367
train loss item: 1.4629015922546387
train loss item: 0.8853329420089722
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5445839762687683
train loss item: 0.674015462398529
train loss item: 0.4879615008831024
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.0255072116851807
train loss item: 0.42342409491539
train loss item: 0.4279136657714844
train loss item: 0.7758976221084595
train loss item: 0.3747066557407379
train loss item: 0.6917065382003784
train loss item: 0.4910371005535126
train loss item: 0.9175930619239807
train loss item: 0.41859519481658936
train loss item: 0.5455162525177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4035603404045105
train loss item: 0.7738136053085327
train loss item: 1.258652925491333
train loss item: 0.6637643575668335
train loss item: 0.4387687146663666
train loss item: 0.5114082098007202
train loss item: 1.4561054706573486
train loss item: 0.3829658627510071
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.524093747138977
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9038376212120056
train loss item: 0.5851014256477356
train loss item: 0.4196215569972992
train loss item: 0.6253869533538818
train loss item: 0.46743452548980713
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3872469365596771
train loss item: 1.8338868618011475
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41059255599975586
train loss item: 2.443751335144043
train loss item: 1.0170003175735474
train loss item: 0.995087206363678
train loss item: 0.40507644414901733
train loss item: 0.6749089360237122
train loss item: 0.4420895576477051
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43542855978012085
train loss item: 0.7903597950935364
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.38722386956214905
train loss item: 0.3567829728126526
train loss item: 1.8009729385375977
train loss item: 1.1887037754058838
train loss item: 3.5324246883392334
train loss item: 0.9487202763557434
train loss item: 1.1619105339050293
train loss item: 0.4423845112323761
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9855327606201172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008445143699646
train loss item: 4.32944393157959
train loss item: 1.3845133781433105
train loss item: 0.7258349061012268
train loss item: 1.1670548915863037
train loss item: 0.4191601872444153
train loss item: 0.5944328904151917
train loss item: 1.1055978536605835
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8371577262878418
train loss item: 0.39751115441322327
train loss item: 0.35939866304397583
train loss item: 0.48182982206344604
train loss item: 0.7070066332817078
train loss item: 0.5354675054550171
train loss item: 0.49496012926101685
train loss item: 0.4740426540374756
train loss item: 0.530408501625061
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0800422430038452
train loss item: 1.3574137687683105
train loss item: 0.46985873579978943
train loss item: 0.4406193196773529
train loss item: 0.446282297372818
train loss item: 0.4453347325325012
train loss item: 0.8741986751556396
train loss item: 0.5293667912483215
train loss item: 0.5353571176528931
train loss item: 0.5791845321655273
train loss item: 0.5059974789619446
train loss item: 0.4314745366573334
train loss item: 0.6558837294578552
train loss item: 0.42855778336524963
train loss item: 2.206753730773926
train loss item: 0.6051461696624756
train loss item: 0.3908587694168091
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5420536398887634
train loss item: 0.3993499279022217
train loss item: 4.305393695831299
train loss item: 0.7225639224052429
train loss item: 0.537074863910675
train loss item: 0.44736871123313904
train loss item: 0.38459938764572144
train loss item: 0.7890965938568115
train loss item: 0.414558082818985
train loss item: 0.603987991809845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46700191497802734
train loss item: 0.4694973826408386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5276029109954834
train loss item: 1.850875973701477
train loss item: 3.771341323852539
train loss item: 0.464836061000824
train loss item: 0.3977920413017273
train loss item: 1.2948168516159058
train loss item: 0.44135576486587524
train loss item: 0.9448678493499756
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5373835563659668
train loss item: 0.9716783761978149
train loss item: 1.4940139055252075
train loss item: 1.019716739654541
train loss item: 0.4043095111846924
train loss item: 0.6526936292648315
train loss item: 0.4361291527748108
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6763297915458679
train loss item: 0.846520721912384
train loss item: 0.5822674632072449
train loss item: 0.5073311924934387
train loss item: 0.6249715685844421
train loss item: 0.4491252601146698
train loss item: 0.41228458285331726
train loss item: 0.9837915897369385
train loss item: 0.43238136172294617
train loss item: 0.3756480813026428
train loss item: 0.6602489352226257
train loss item: 0.43490418791770935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4389401078224182
train loss item: 2.278047800064087
train loss item: 0.7019065022468567
train loss item: 2.877516031265259
train loss item: 0.5246642231941223
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3866238594055176
train loss item: 0.5449886918067932
train loss item: 0.6539317965507507
train loss item: 0.4264691472053528
train loss item: 0.45463478565216064
train loss item: 0.45638638734817505
train loss item: 0.4559684693813324
train loss item: 0.47985419631004333
train loss item: 0.6698529720306396
train loss item: 1.1541709899902344
train loss item: 1.3551671504974365
train loss item: 0.42673611640930176
train loss item: 0.969355583190918
train loss item: 1.86638605594635
train loss item: 0.41490432620048523
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.436746597290039
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5215848684310913
train loss item: 0.6882298588752747
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.8051015734672546
train loss item: 0.8529430627822876
train loss item: 2.214339017868042
train loss item: 1.5116938352584839
train loss item: 0.5819724798202515
train loss item: 0.4383721649646759
train loss item: 0.41861456632614136
train loss item: 1.3880025148391724
train loss item: 0.7734600305557251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5285988450050354
train loss item: 0.6681726574897766
train loss item: 0.4541483521461487
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.9507399797439575
train loss item: 0.39212068915367126
train loss item: 0.3957740068435669
train loss item: 0.7045068740844727
train loss item: 0.3592888116836548
train loss item: 0.640126645565033
train loss item: 0.45678287744522095
train loss item: 0.8674015998840332
train loss item: 0.3970751464366913
train loss item: 0.5010831356048584
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37873467803001404
train loss item: 0.7549389600753784
train loss item: 1.209031105041504
train loss item: 0.6678506731987
train loss item: 0.41784077882766724
train loss item: 0.4937847852706909
train loss item: 1.4121454954147339
train loss item: 0.35888829827308655
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4921519160270691
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8699957728385925
train loss item: 0.5450640916824341
train loss item: 0.3905563950538635
train loss item: 0.5765966773033142
train loss item: 0.43139874935150146
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3643650412559509
train loss item: 1.7877963781356812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3885669708251953
train loss item: 2.3744027614593506
train loss item: 0.9635235071182251
train loss item: 0.9398651123046875
train loss item: 0.3759452998638153
train loss item: 0.6498486995697021
train loss item: 0.42940425872802734
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4148862063884735
train loss item: 0.7516554594039917
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35976043343544006
train loss item: 0.34368252754211426
train loss item: 1.7625540494918823
train loss item: 1.1395182609558105
train loss item: 3.423069477081299
train loss item: 0.9135857224464417
train loss item: 1.1172702312469482
train loss item: 0.4248979389667511
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9466566443443298
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4133960008621216
train loss item: 4.23195743560791
train loss item: 1.3307774066925049
train loss item: 0.7032762765884399
train loss item: 1.1340081691741943
train loss item: 0.390132337808609
train loss item: 0.5579783916473389
train loss item: 1.0716018676757812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.802668571472168
train loss item: 0.38565701246261597
train loss item: 0.32250872254371643
train loss item: 0.47355711460113525
train loss item: 0.661649763584137
train loss item: 0.5043798685073853
train loss item: 0.4497036635875702
train loss item: 0.438198983669281
train loss item: 0.5030548572540283
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0335768461227417
train loss item: 1.2954051494598389
train loss item: 0.44945961236953735
train loss item: 0.41032615303993225
train loss item: 0.44713613390922546
train loss item: 0.4125525653362274
train loss item: 0.8212732076644897
train loss item: 0.5073781609535217
train loss item: 0.5154852271080017
train loss item: 0.5469192266464233
train loss item: 0.4909832775592804
train loss item: 0.3931466341018677
train loss item: 0.621256947517395
train loss item: 0.39793649315834045
train loss item: 2.1539275646209717
train loss item: 0.5704979300498962
train loss item: 0.3635222911834717
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.516581118106842
train loss item: 0.403873085975647
train loss item: 4.208215236663818
train loss item: 0.6724585890769958
train loss item: 0.5222636461257935
train loss item: 0.4144033193588257
train loss item: 0.35863155126571655
train loss item: 0.746972918510437
train loss item: 0.3903963267803192
train loss item: 0.5846830606460571
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43731755018234253
train loss item: 0.4497511386871338
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.481804609298706
train loss item: 1.7918583154678345
train loss item: 3.672724723815918
train loss item: 0.42840874195098877
train loss item: 0.36995062232017517
train loss item: 1.1104559898376465
train loss item: 0.41665565967559814
train loss item: 0.9020617604255676
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5116944313049316
train loss item: 0.9252290725708008
train loss item: 1.414633870124817
train loss item: 0.9859626293182373
train loss item: 0.3803067207336426
train loss item: 0.5922043323516846
train loss item: 0.402712345123291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6224695444107056
train loss item: 0.794919490814209
train loss item: 0.5667665600776672
train loss item: 0.4867575764656067
train loss item: 0.5816335678100586
train loss item: 0.4143410921096802
train loss item: 0.44441157579421997
train loss item: 0.8031931519508362
train loss item: 0.40109309554100037
train loss item: 0.3602941930294037
train loss item: 0.627627432346344
train loss item: 0.3945261240005493
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4165565073490143
train loss item: 2.199267625808716
train loss item: 0.6530634164810181
train loss item: 2.8289592266082764
train loss item: 0.5036813020706177
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3602833151817322
train loss item: 0.5181873440742493
train loss item: 0.6069742441177368
train loss item: 0.4211292862892151
train loss item: 0.40407049655914307
train loss item: 0.4450536072254181
train loss item: 0.4276082515716553
train loss item: 0.4543696343898773
train loss item: 0.6541560292243958
train loss item: 1.1092151403427124
train loss item: 1.3023735284805298
train loss item: 0.39061033725738525
train loss item: 0.9333477020263672
train loss item: 1.7632112503051758
train loss item: 0.39761194586753845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.3332133293151855
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4968581199645996
train loss item: 0.6446283459663391
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.7930572628974915
train loss item: 0.8106309175491333
train loss item: 2.154629945755005
train loss item: 1.4358925819396973
train loss item: 0.5403582453727722
train loss item: 0.42518410086631775
train loss item: 0.3946791887283325
train loss item: 1.337820291519165
train loss item: 0.7283328771591187
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5086467266082764
train loss item: 0.6587628722190857
train loss item: 0.43243226408958435
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8997114896774292
train loss item: 0.3564055263996124
train loss item: 0.3781545162200928
train loss item: 0.6633870601654053
train loss item: 0.34436315298080444
train loss item: 0.6021005511283875
train loss item: 0.4337024390697479
train loss item: 0.8381946086883545
train loss item: 0.3798515796661377
train loss item: 0.46760791540145874
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36306190490722656
train loss item: 0.7336841821670532
train loss item: 1.1666553020477295
train loss item: 0.6589175462722778
train loss item: 0.40363696217536926
train loss item: 0.4622725248336792
train loss item: 1.3715578317642212
train loss item: 0.3419116735458374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46878868341445923
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8391717672348022
train loss item: 0.5013014674186707
train loss item: 0.37441208958625793
train loss item: 0.5385311841964722
train loss item: 0.3904067277908325
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35047394037246704
train loss item: 1.732211947441101
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3668222427368164
train loss item: 2.326054096221924
train loss item: 0.9112567901611328
train loss item: 0.8813654184341431
train loss item: 0.35766473412513733
train loss item: 0.6242033839225769
train loss item: 0.4178542494773865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39821115136146545
train loss item: 0.7165666818618774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34212782979011536
train loss item: 0.3284926116466522
train loss item: 1.7136108875274658
train loss item: 0.9933941960334778
train loss item: 3.3595523834228516
train loss item: 0.8102750778198242
train loss item: 1.0816224813461304
train loss item: 0.413299024105072
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9135479927062988
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4067084491252899
train loss item: 4.174579620361328
train loss item: 1.2894893884658813
train loss item: 0.6825628876686096
train loss item: 1.094824194908142
train loss item: 0.36362388730049133
train loss item: 0.5129873752593994
train loss item: 1.030917763710022
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7728220224380493
train loss item: 0.37418532371520996
train loss item: 0.30440935492515564
train loss item: 0.46403172612190247
train loss item: 0.6374162435531616
train loss item: 0.47682198882102966
train loss item: 0.4160236716270447
train loss item: 0.41514167189598083
train loss item: 0.4792505204677582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9984489679336548
train loss item: 1.2547656297683716
train loss item: 0.42159074544906616
train loss item: 0.3940301835536957
train loss item: 0.43876731395721436
train loss item: 0.3962877094745636
train loss item: 0.7742434144020081
train loss item: 0.48457634449005127
train loss item: 0.4956094026565552
train loss item: 0.5226385593414307
train loss item: 0.4763917326927185
train loss item: 0.3738737106323242
train loss item: 0.5782414078712463
train loss item: 0.3818342983722687
train loss item: 2.098876714706421
train loss item: 0.5317774415016174
train loss item: 0.34576982259750366
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.49367421865463257
train loss item: 0.38496139645576477
train loss item: 4.151196479797363
train loss item: 0.6276695728302002
train loss item: 0.5083506107330322
train loss item: 0.4003390669822693
train loss item: 0.34301993250846863
train loss item: 0.722851037979126
train loss item: 0.37242257595062256
train loss item: 0.5657562613487244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41457399725914
train loss item: 0.43614786863327026
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4422942399978638
train loss item: 1.7304792404174805
train loss item: 3.612187385559082
train loss item: 0.4083971083164215
train loss item: 0.35246723890304565
train loss item: 0.9530659914016724
train loss item: 0.40092340111732483
train loss item: 0.8486791849136353
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.490337997674942
train loss item: 0.8784583210945129
train loss item: 1.2507680654525757
train loss item: 0.9552468061447144
train loss item: 0.3652568459510803
train loss item: 0.5493290424346924
train loss item: 0.3815479874610901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5802987217903137
train loss item: 0.7484342455863953
train loss item: 0.5494769811630249
train loss item: 0.4643653333187103
train loss item: 0.5457404851913452
train loss item: 0.3989465534687042
train loss item: 0.42997774481773376
train loss item: 0.7423388957977295
train loss item: 0.38405466079711914
train loss item: 0.3448895215988159
train loss item: 0.5970014333724976
train loss item: 0.376468688249588
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40056467056274414
train loss item: 2.1499416828155518
train loss item: 0.6170884370803833
train loss item: 2.7615437507629395
train loss item: 0.4902063310146332
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.342864990234375
train loss item: 0.5018545985221863
train loss item: 0.5526416301727295
train loss item: 0.3963841199874878
train loss item: 0.3859878480434418
train loss item: 0.43436458706855774
train loss item: 0.40195322036743164
train loss item: 0.4347972571849823
train loss item: 0.6304241418838501
train loss item: 1.0596929788589478
train loss item: 1.2464430332183838
train loss item: 0.35329416394233704
train loss item: 0.8949295878410339
train loss item: 1.693165898323059
train loss item: 0.38602107763290405
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.273541450500488
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47628358006477356
train loss item: 0.6043571829795837
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.7696083784103394
train loss item: 0.7738329172134399
train loss item: 2.1072099208831787
train loss item: 1.4392237663269043
train loss item: 0.5005015730857849
train loss item: 0.3845720589160919
train loss item: 0.3539958596229553
train loss item: 1.3030188083648682
train loss item: 0.7387155294418335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48472341895103455
train loss item: 0.6403278708457947
train loss item: 0.413040429353714
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8626539707183838
train loss item: 0.324313223361969
train loss item: 0.35225561261177063
train loss item: 0.6438730955123901
train loss item: 0.32586467266082764
train loss item: 0.574292778968811
train loss item: 0.41302573680877686
train loss item: 0.8201944231987
train loss item: 0.36107563972473145
train loss item: 0.4429234266281128
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480510413646698
train loss item: 0.7084197998046875
train loss item: 1.1274973154067993
train loss item: 0.6368315815925598
train loss item: 0.3884425163269043
train loss item: 0.41889122128486633
train loss item: 1.3325780630111694
train loss item: 0.32780951261520386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44647303223609924
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.807952344417572
train loss item: 0.4614025950431824
train loss item: 0.3634142279624939
train loss item: 0.507057785987854
train loss item: 0.35348328948020935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3369205892086029
train loss item: 1.6761924028396606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34206584095954895
train loss item: 2.289836883544922
train loss item: 0.8633443713188171
train loss item: 0.8268972635269165
train loss item: 0.33858802914619446
train loss item: 0.5944257974624634
train loss item: 0.39823782444000244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.382181316614151
train loss item: 0.6845089793205261
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32874244451522827
train loss item: 0.3081795275211334
train loss item: 1.6619094610214233
train loss item: 0.8459346890449524
train loss item: 3.321760416030884
train loss item: 0.7155598998069763
train loss item: 1.0504289865493774
train loss item: 0.40089112520217896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8821102380752563
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3742945194244385
train loss item: 4.1395344734191895
train loss item: 1.2572300434112549
train loss item: 0.6645398736000061
train loss item: 1.0516414642333984
train loss item: 0.3420185446739197
train loss item: 0.4718320369720459
train loss item: 0.9858909249305725
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7448924779891968
train loss item: 0.3587813079357147
train loss item: 0.2892478406429291
train loss item: 0.446908563375473
train loss item: 0.6241509914398193
train loss item: 0.452237606048584
train loss item: 0.38668879866600037
train loss item: 0.39500245451927185
train loss item: 0.4571174681186676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9703024625778198
train loss item: 1.2268974781036377
train loss item: 0.38222089409828186
train loss item: 0.3834834098815918
train loss item: 0.4158337712287903
train loss item: 0.38689056038856506
train loss item: 0.7324391007423401
train loss item: 0.4568125903606415
train loss item: 0.46983617544174194
train loss item: 0.5018084049224854
train loss item: 0.45918580889701843
train loss item: 0.34954211115837097
train loss item: 0.5389177799224854
train loss item: 0.3717734217643738
train loss item: 2.0475189685821533
train loss item: 0.49729806184768677
train loss item: 0.33280983567237854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4671946167945862
train loss item: 0.34541434049606323
train loss item: 4.116434574127197
train loss item: 0.5871601700782776
train loss item: 0.4871812164783478
train loss item: 0.3709505498409271
train loss item: 0.3285726010799408
train loss item: 0.7077078819274902
train loss item: 0.3541874587535858
train loss item: 0.540101170539856
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39517709612846375
train loss item: 0.4215240776538849
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4052671194076538
train loss item: 1.6727595329284668
train loss item: 3.5740201473236084
train loss item: 0.3823288679122925
train loss item: 0.33647620677948
train loss item: 0.8517757058143616
train loss item: 0.38571423292160034
train loss item: 0.7971600890159607
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47017186880111694
train loss item: 0.8344438076019287
train loss item: 1.068676471710205
train loss item: 0.9240391254425049
train loss item: 0.35040900111198425
train loss item: 0.511786937713623
train loss item: 0.36324790120124817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5441670417785645
train loss item: 0.7062374949455261
train loss item: 0.5278030037879944
train loss item: 0.43699127435684204
train loss item: 0.5143771767616272
train loss item: 0.3693526089191437
train loss item: 0.3911777138710022
train loss item: 0.763845682144165
train loss item: 0.35922425985336304
train loss item: 0.3260841965675354
train loss item: 0.566985011100769
train loss item: 0.3556440770626068
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3841143846511841
train loss item: 2.1170198917388916
train loss item: 0.5884301662445068
train loss item: 2.694685697555542
train loss item: 0.4767865240573883
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.328854501247406
train loss item: 0.4874052405357361
train loss item: 0.501418948173523
train loss item: 0.35631272196769714
train loss item: 0.3638763725757599
train loss item: 0.415113240480423
train loss item: 0.3737080991268158
train loss item: 0.41739779710769653
train loss item: 0.5961752533912659
train loss item: 1.011290192604065
train loss item: 1.192165732383728
train loss item: 0.3219052255153656
train loss item: 0.8539865016937256
train loss item: 1.6443272829055786
train loss item: 0.3701934218406677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.238527774810791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.45275771617889404
train loss item: 0.564845860004425
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.7437087893486023
train loss item: 0.7437713742256165
train loss item: 2.0666611194610596
train loss item: 1.4547584056854248
train loss item: 0.4739750623703003
train loss item: 0.3508828282356262
train loss item: 0.3234092891216278
train loss item: 1.2739440202713013
train loss item: 0.7835104465484619
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647943675518036
train loss item: 0.6195951104164124
train loss item: 0.3989918529987335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.83207368850708
train loss item: 0.30287811160087585
train loss item: 0.32705992460250854
train loss item: 0.6540850400924683
train loss item: 0.32307741045951843
train loss item: 0.553713858127594
train loss item: 0.3983871340751648
train loss item: 0.8048974275588989
train loss item: 0.34606677293777466
train loss item: 0.42535436153411865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33705025911331177
train loss item: 0.6835212707519531
train loss item: 1.089398980140686
train loss item: 0.6109908223152161
train loss item: 0.37597376108169556
train loss item: 0.38276466727256775
train loss item: 1.2975618839263916
train loss item: 0.3183952271938324
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4295913279056549
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7786715626716614
train loss item: 0.43221718072891235
train loss item: 0.3559081554412842
train loss item: 0.48468106985092163
train loss item: 0.32916566729545593
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3274155557155609
train loss item: 1.625609278678894
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32250678539276123
train loss item: 2.256333589553833
train loss item: 0.8248248100280762
train loss item: 0.7831247448921204
train loss item: 0.32505783438682556
train loss item: 0.5658968687057495
train loss item: 0.37843772768974304
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37125566601753235
train loss item: 0.657664954662323
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3204960823059082
train loss item: 0.3045646548271179
train loss item: 1.614041805267334
train loss item: 0.7644869685173035
train loss item: 3.2923824787139893
train loss item: 0.6829583048820496
train loss item: 1.0228385925292969
train loss item: 0.38931605219841003
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8528540134429932
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3485627770423889
train loss item: 4.111616611480713
train loss item: 1.2297002077102661
train loss item: 0.6492116451263428
train loss item: 1.008128046989441
train loss item: 0.3284187912940979
train loss item: 0.4428568184375763
train loss item: 0.9412129521369934
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7195854187011719
train loss item: 0.34543299674987793
train loss item: 0.2819531559944153
train loss item: 0.4309505522251129
train loss item: 0.6133702993392944
train loss item: 0.43492189049720764
train loss item: 0.3658623695373535
train loss item: 0.37986767292022705
train loss item: 0.44018375873565674
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9464237093925476
train loss item: 1.2035741806030273
train loss item: 0.3545955717563629
train loss item: 0.3758346438407898
train loss item: 0.39175179600715637
train loss item: 0.3806363046169281
train loss item: 0.6995801329612732
train loss item: 0.43269583582878113
train loss item: 0.44496119022369385
train loss item: 0.4859105348587036
train loss item: 0.4437786638736725
train loss item: 0.3284643292427063
train loss item: 0.5112730264663696
train loss item: 0.36504316329956055
train loss item: 2.0017402172088623
train loss item: 0.47355973720550537
train loss item: 0.32535889744758606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4425390660762787
train loss item: 0.3178510069847107
train loss item: 4.0886030197143555
train loss item: 0.5539808869361877
train loss item: 0.4657462239265442
train loss item: 0.35042551159858704
train loss item: 0.318915456533432
train loss item: 0.6950581073760986
train loss item: 0.34033575654029846
train loss item: 0.5144366025924683
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3827149271965027
train loss item: 0.4091763198375702
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.3682557344436646
train loss item: 1.6217763423919678
train loss item: 3.543980598449707
train loss item: 0.35708898305892944
train loss item: 0.3252008557319641
train loss item: 0.8107115626335144
train loss item: 0.37360048294067383
train loss item: 0.7553129196166992
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4545861482620239
train loss item: 0.7977326512336731
train loss item: 0.9332625269889832
train loss item: 0.8923819065093994
train loss item: 0.339046835899353
train loss item: 0.4856336712837219
train loss item: 0.3496454358100891
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5165325999259949
train loss item: 0.6721661686897278
train loss item: 0.5066771507263184
train loss item: 0.41250136494636536
train loss item: 0.4908815622329712
train loss item: 0.3487595319747925
train loss item: 0.3607846796512604
train loss item: 0.8139474987983704
train loss item: 0.33619898557662964
train loss item: 0.3233568072319031
train loss item: 0.5422070026397705
train loss item: 0.33855047821998596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3711854815483093
train loss item: 2.088186502456665
train loss item: 0.5678302049636841
train loss item: 2.637929677963257
train loss item: 0.46539825201034546
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31939923763275146
train loss item: 0.47557511925697327
train loss item: 0.46110841631889343
train loss item: 0.3283836245536804
train loss item: 0.35422033071517944
train loss item: 0.39511236548423767
train loss item: 0.35176724195480347
train loss item: 0.4055427610874176
train loss item: 0.5598140954971313
train loss item: 0.9668205976486206
train loss item: 1.1445995569229126
train loss item: 0.3026847243309021
train loss item: 0.8137850761413574
train loss item: 1.6032146215438843
train loss item: 0.35565489530563354
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.211021900177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43184077739715576
train loss item: 0.5301486849784851
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.723175048828125
train loss item: 0.718856155872345
train loss item: 2.028942108154297
train loss item: 1.4304053783416748
train loss item: 0.45900553464889526
train loss item: 0.33748161792755127
train loss item: 0.31310099363327026
train loss item: 1.2421724796295166
train loss item: 0.8151156306266785
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4519675076007843
train loss item: 0.6022875308990479
train loss item: 0.38473716378211975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8026916980743408
train loss item: 0.287600040435791
train loss item: 0.30573081970214844
train loss item: 0.652103841304779
train loss item: 0.3306933641433716
train loss item: 0.5344435572624207
train loss item: 0.38471439480781555
train loss item: 0.7849844098091125
train loss item: 0.33515018224716187
train loss item: 0.40964803099632263
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3287726640701294
train loss item: 0.6621514558792114
train loss item: 1.0514967441558838
train loss item: 0.5896925330162048
train loss item: 0.36614593863487244
train loss item: 0.36037692427635193
train loss item: 1.2676422595977783
train loss item: 0.3083057403564453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41466179490089417
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7532024383544922
train loss item: 0.41358983516693115
train loss item: 0.3455303907394409
train loss item: 0.4698421061038971
train loss item: 0.3146267831325531
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3215275704860687
train loss item: 1.5843149423599243
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3101251423358917
train loss item: 2.220048666000366
train loss item: 0.7976096272468567
train loss item: 0.7521964311599731
train loss item: 0.31254225969314575
train loss item: 0.5406280159950256
train loss item: 0.36393192410469055
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3654620349407196
train loss item: 0.636022686958313
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3111319839954376
train loss item: 0.3127814531326294
train loss item: 1.5739250183105469
train loss item: 0.735058069229126
train loss item: 3.2600882053375244
train loss item: 0.6824032664299011
train loss item: 0.9979923367500305
train loss item: 0.3777829110622406
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.826256513595581
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3405210077762604
train loss item: 4.080611228942871
train loss item: 1.2025891542434692
train loss item: 0.6337785124778748
train loss item: 0.9671251177787781
train loss item: 0.3173796534538269
train loss item: 0.4255298674106598
train loss item: 0.9008482694625854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.69732666015625
train loss item: 0.33567777276039124
train loss item: 0.27587974071502686
train loss item: 0.4161907136440277
train loss item: 0.5964747071266174
train loss item: 0.42475447058677673
train loss item: 0.35216233134269714
train loss item: 0.36862891912460327
train loss item: 0.42884722352027893
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.924312174320221
train loss item: 1.1783323287963867
train loss item: 0.34544917941093445
train loss item: 0.3645091652870178
train loss item: 0.3730444312095642
train loss item: 0.3705114424228668
train loss item: 0.6758893728256226
train loss item: 0.41454723477363586
train loss item: 0.4214242398738861
train loss item: 0.4737102687358856
train loss item: 0.4317299723625183
train loss item: 0.3111536204814911
train loss item: 0.49499887228012085
train loss item: 0.35472050309181213
train loss item: 1.961248755455017
train loss item: 0.45868903398513794
train loss item: 0.3169795572757721
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4208192527294159
train loss item: 0.3132786750793457
train loss item: 4.057366371154785
train loss item: 0.5287954807281494
train loss item: 0.4487692713737488
train loss item: 0.33699437975883484
train loss item: 0.3130371570587158
train loss item: 0.6779537200927734
train loss item: 0.3303520083427429
train loss item: 0.4945813715457916
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37621408700942993
train loss item: 0.3988354504108429
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.330076813697815
train loss item: 1.579289197921753
train loss item: 3.5126287937164307
train loss item: 0.3340296745300293
train loss item: 0.3169589936733246
train loss item: 0.7846478223800659
train loss item: 0.3635338246822357
train loss item: 0.725496232509613
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44399502873420715
train loss item: 0.7699281573295593
train loss item: 0.8696199655532837
train loss item: 0.8602725863456726
train loss item: 0.3302028179168701
train loss item: 0.4687436521053314
train loss item: 0.33963802456855774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4965958893299103
train loss item: 0.6479334235191345
train loss item: 0.48864591121673584
train loss item: 0.39237332344055176
train loss item: 0.47472578287124634
train loss item: 0.33520302176475525
train loss item: 0.3509271442890167
train loss item: 0.8338758945465088
train loss item: 0.31649288535118103
train loss item: 0.33143237233161926
train loss item: 0.5244999527931213
train loss item: 0.324046790599823
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36128175258636475
train loss item: 2.0560989379882812
train loss item: 0.553006112575531
train loss item: 2.594550609588623
train loss item: 0.45530781149864197
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3091706931591034
train loss item: 0.4647732377052307
train loss item: 0.43392854928970337
train loss item: 0.321036696434021
train loss item: 0.34806233644485474
train loss item: 0.37958210706710815
train loss item: 0.3358091115951538
train loss item: 0.3980853259563446
train loss item: 0.526502251625061
train loss item: 0.9276179671287537
train loss item: 1.1062926054000854
train loss item: 0.2902069091796875
train loss item: 0.7763500809669495
train loss item: 1.5605475902557373
train loss item: 0.3448650538921356
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.180288791656494
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4129044711589813
train loss item: 0.5026814937591553
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.7098458409309387
train loss item: 0.6970778703689575
train loss item: 1.993215560913086
train loss item: 1.361167550086975
train loss item: 0.4433552026748657
train loss item: 0.3333328068256378
train loss item: 0.3102828562259674
train loss item: 1.2063350677490234
train loss item: 0.8118047714233398
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4439007639884949
train loss item: 0.5893954634666443
train loss item: 0.3698454797267914
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7727218866348267
train loss item: 0.27374371886253357
train loss item: 0.2851434350013733
train loss item: 0.6276633143424988
train loss item: 0.3264438509941101
train loss item: 0.5133658647537231
train loss item: 0.37052497267723083
train loss item: 0.7600528001785278
train loss item: 0.324270099401474
train loss item: 0.39370864629745483
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3186584711074829
train loss item: 0.6454132795333862
train loss item: 1.0152084827423096
train loss item: 0.575340986251831
train loss item: 0.3553259074687958
train loss item: 0.34137189388275146
train loss item: 1.2435381412506104
train loss item: 0.29306724667549133
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008773863315582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.731844425201416
train loss item: 0.4023657441139221
train loss item: 0.3284552991390228
train loss item: 0.45803284645080566
train loss item: 0.30404379963874817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31538671255111694
train loss item: 1.5533117055892944
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3011203706264496
train loss item: 2.1825239658355713
train loss item: 0.7800406217575073
train loss item: 0.7315957546234131
train loss item: 0.29639318585395813
train loss item: 0.5183584690093994
train loss item: 0.3537620007991791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583802580833435
train loss item: 0.6166451573371887
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2961908280849457
train loss item: 0.3096919357776642
train loss item: 1.5434669256210327
train loss item: 0.7250176072120667
train loss item: 3.2225394248962402
train loss item: 0.6801353096961975
train loss item: 0.975432276725769
train loss item: 0.36429905891418457
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8020622134208679
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33765748143196106
train loss item: 4.044615268707275
train loss item: 1.174917459487915
train loss item: 0.6165820956230164
train loss item: 0.9317919611930847
train loss item: 0.30421990156173706
train loss item: 0.41483116149902344
train loss item: 0.8679857850074768
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6773892045021057
train loss item: 0.3277986943721771
train loss item: 0.26407402753829956
train loss item: 0.3954724073410034
train loss item: 0.5719655156135559
train loss item: 0.41636985540390015
train loss item: 0.34038442373275757
train loss item: 0.35828423500061035
train loss item: 0.4188620150089264
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9020735025405884
train loss item: 1.1499011516571045
train loss item: 0.3417537212371826
train loss item: 0.34626662731170654
train loss item: 0.35472482442855835
train loss item: 0.35314419865608215
train loss item: 0.6580479145050049
train loss item: 0.3996224105358124
train loss item: 0.4013262093067169
train loss item: 0.46032166481018066
train loss item: 0.42160987854003906
train loss item: 0.2922847867012024
train loss item: 0.48536011576652527
train loss item: 0.3375800549983978
train loss item: 1.9268697500228882
train loss item: 0.44759947061538696
train loss item: 0.30262506008148193
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.401305228471756
train loss item: 0.3150266408920288
train loss item: 4.020753860473633
train loss item: 0.509464681148529
train loss item: 0.43568670749664307
train loss item: 0.31719741225242615
train loss item: 0.30639827251434326
train loss item: 0.6550703048706055
train loss item: 0.3199657201766968
train loss item: 0.4804512858390808
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3688831031322479
train loss item: 0.3875214755535126
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2929304838180542
train loss item: 1.545644760131836
train loss item: 3.4781038761138916
train loss item: 0.30991798639297485
train loss item: 0.3069058656692505
train loss item: 0.7484599947929382
train loss item: 0.3521009385585785
train loss item: 0.7055948972702026
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43298038840293884
train loss item: 0.7503966093063354
train loss item: 0.8610623478889465
train loss item: 0.8302368521690369
train loss item: 0.3196645975112915
train loss item: 0.45290619134902954
train loss item: 0.3298962116241455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4801141321659088
train loss item: 0.632495105266571
train loss item: 0.47458669543266296
train loss item: 0.374237596988678
train loss item: 0.4621663987636566
train loss item: 0.31554439663887024
train loss item: 0.34858933091163635
train loss item: 0.8112183809280396
train loss item: 0.2961934208869934
train loss item: 0.3277743458747864
train loss item: 0.512164831161499
train loss item: 0.30690136551856995
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35072124004364014
train loss item: 2.020768642425537
train loss item: 0.5399312376976013
train loss item: 2.5637624263763428
train loss item: 0.44393324851989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2937313914299011
train loss item: 0.4522640109062195
train loss item: 0.417385071516037
train loss item: 0.3195478916168213
train loss item: 0.3309571444988251
train loss item: 0.3678264617919922
train loss item: 0.32141485810279846
train loss item: 0.3885186016559601
train loss item: 0.4946769177913666
train loss item: 0.8951320648193359
train loss item: 1.077818751335144
train loss item: 0.2774108350276947
train loss item: 0.744400680065155
train loss item: 1.5157862901687622
train loss item: 0.33590614795684814
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.143923282623291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3940907418727875
train loss item: 0.4830005466938019
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.7012327909469604
train loss item: 0.6768987774848938
train loss item: 1.959564447402954
train loss item: 1.2730965614318848
train loss item: 0.4245123267173767
train loss item: 0.32746371626853943
train loss item: 0.30321088433265686
train loss item: 1.1697438955307007
train loss item: 0.7816647887229919
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4375529885292053
train loss item: 0.5793851613998413
train loss item: 0.36056557297706604
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7435319423675537
train loss item: 0.2636568248271942
train loss item: 0.26824524998664856
train loss item: 0.6041659712791443
train loss item: 0.30960673093795776
train loss item: 0.4925594627857208
train loss item: 0.3610459864139557
train loss item: 0.7348750233650208
train loss item: 0.31261447072029114
train loss item: 0.37968042492866516
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3064850866794586
train loss item: 0.6322617530822754
train loss item: 0.9828314185142517
train loss item: 0.5660059452056885
train loss item: 0.34321141242980957
train loss item: 0.3221050202846527
train loss item: 1.2249256372451782
train loss item: 0.27635854482650757
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39237332344055176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.71439528465271
train loss item: 0.3958813548088074
train loss item: 0.3083411157131195
train loss item: 0.44660109281539917
train loss item: 0.2972389757633209
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3084021806716919
train loss item: 1.530341625213623
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2934279143810272
train loss item: 2.146493673324585
train loss item: 0.767556369304657
train loss item: 0.7163669466972351
train loss item: 0.27946630120277405
train loss item: 0.49904075264930725
train loss item: 0.3460235297679901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480775058269501
train loss item: 0.5983378291130066
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.27943864464759827
train loss item: 0.2939455211162567
train loss item: 1.5210046768188477
train loss item: 0.7247592210769653
train loss item: 3.1832032203674316
train loss item: 0.6760433912277222
train loss item: 0.9549425840377808
train loss item: 0.3498036563396454
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7805810570716858
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3302747905254364
train loss item: 4.007093906402588
train loss item: 1.1479820013046265
train loss item: 0.5999115705490112
train loss item: 0.9031261205673218
train loss item: 0.2931276857852936
train loss item: 0.4080217480659485
train loss item: 0.8418792486190796
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6597893238067627
train loss item: 0.32146796584129333
train loss item: 0.24960766732692719
train loss item: 0.3697932958602905
train loss item: 0.5459722876548767
train loss item: 0.4065341055393219
train loss item: 0.3288898468017578
train loss item: 0.3475848436355591
train loss item: 0.40844011306762695
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.880405843257904
train loss item: 1.121046543121338
train loss item: 0.3334875702857971
train loss item: 0.32480448484420776
train loss item: 0.33540695905685425
train loss item: 0.33273300528526306
train loss item: 0.6428158283233643
train loss item: 0.38700729608535767
train loss item: 0.38971251249313354
train loss item: 0.44530007243156433
train loss item: 0.4129522740840912
train loss item: 0.27337580919265747
train loss item: 0.47931110858917236
train loss item: 0.31752562522888184
train loss item: 1.8990013599395752
train loss item: 0.43906450271606445
train loss item: 0.2859288454055786
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3845539391040802
train loss item: 0.31036514043807983
train loss item: 3.982544422149658
train loss item: 0.4932782053947449
train loss item: 0.4250364303588867
train loss item: 0.2966454029083252
train loss item: 0.2986525893211365
train loss item: 0.6313495635986328
train loss item: 0.30833685398101807
train loss item: 0.46955808997154236
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583366572856903
train loss item: 0.37499508261680603
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2596176862716675
train loss item: 1.518908977508545
train loss item: 3.4426724910736084
train loss item: 0.2881893217563629
train loss item: 0.29457002878189087
train loss item: 0.7104032635688782
train loss item: 0.33935871720314026
train loss item: 0.6920673847198486
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.42006558179855347
train loss item: 0.7361637949943542
train loss item: 0.8761228919029236
train loss item: 0.8045116066932678
train loss item: 0.30721744894981384
train loss item: 0.4349144697189331
train loss item: 0.32019585371017456
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647907316684723
train loss item: 0.6221219301223755
train loss item: 0.46378180384635925
train loss item: 0.3581021726131439
train loss item: 0.4509026110172272
train loss item: 0.29534807801246643
train loss item: 0.3429086208343506
train loss item: 0.7649170160293579
train loss item: 0.2788582742214203
train loss item: 0.3115488588809967
train loss item: 0.5022445917129517
train loss item: 0.2896858751773834
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.339032381772995
train loss item: 1.9852867126464844
train loss item: 0.5266013741493225
train loss item: 2.5412187576293945
train loss item: 0.43140870332717896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2765684127807617
train loss item: 0.43842560052871704
train loss item: 0.40749555826187134
train loss item: 0.31202223896980286
train loss item: 0.30966389179229736
train loss item: 0.3586636781692505
train loss item: 0.3084482252597809
train loss item: 0.3757885694503784
train loss item: 0.46557512879371643
train loss item: 0.8691501021385193
train loss item: 1.056811809539795
train loss item: 0.26584452390670776
train loss item: 0.719364583492279
train loss item: 1.472780466079712
train loss item: 0.3277837634086609
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.1056928634643555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3768501877784729
train loss item: 0.4697430729866028
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 0.693540632724762
train loss item: 0.6579349637031555
train loss item: 1.928483247756958
train loss item: 1.1928136348724365
train loss item: 0.40681248903274536
train loss item: 0.3173936903476715
train loss item: 0.2905552089214325
train loss item: 1.136673092842102
train loss item: 0.7322322130203247
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4317569434642792
train loss item: 0.5698574185371399
train loss item: 0.3535853922367096
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.717613935470581
train loss item: 0.25894397497177124
train loss item: 0.2580583393573761
train loss item: 0.5890412330627441
train loss item: 0.29087549448013306
train loss item: 0.47456738352775574
train loss item: 0.35363325476646423
train loss item: 0.7146875262260437
train loss item: 0.30186089873313904
train loss item: 0.3687035143375397
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.29473981261253357
train loss item: 0.6211012005805969
train loss item: 0.9554638862609863
train loss item: 0.5585214495658875
train loss item: 0.3318652808666229
train loss item: 0.30660611391067505
train loss item: 1.2095849514007568
train loss item: 0.26302003860473633
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3856435716152191
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7001263499259949
train loss item: 0.39076924324035645
train loss item: 0.2909272015094757
train loss item: 0.4353330731391907
train loss item: 0.2934657633304596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3020230829715729
train loss item: 1.5108436346054077
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.28752565383911133
train loss item: 2.1144323348999023
train loss item: 0.7548717856407166
train loss item: 0.7015661597251892
train loss item: 0.2655992805957794
train loss item: 0.4824598729610443
train loss item: 0.339358389377594
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3373473882675171
train loss item: 0.5819714665412903
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2661121189594269
train loss item: 0.27563580870628357
train loss item: 1.5024704933166504
train loss item: 0.7264050841331482
train loss item: 3.1469216346740723
train loss item: 0.6701516509056091
train loss item: 0.9373541474342346
train loss item: 0.33666372299194336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7623443603515625
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3192974925041199
train loss item: 3.9725024700164795
train loss item: 1.1234350204467773
train loss item: 0.5868390202522278
train loss item: 0.8784924745559692
train loss item: 0.28700289130210876
train loss item: 0.40265190601348877
train loss item: 0.818615734577179
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6450898051261902
train loss item: 0.31625646352767944
train loss item: 0.23847685754299164
train loss item: 0.34598883986473083
train loss item: 0.5259736776351929
train loss item: 0.3959523141384125
train loss item: 0.31735894083976746
train loss item: 0.3372364044189453
train loss item: 0.3983061611652374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8612839579582214
train loss item: 1.0949510335922241
train loss item: 0.32029056549072266
train loss item: 0.3059912919998169
train loss item: 0.31798598170280457
train loss item: 0.3149357736110687
train loss item: 0.6279577016830444
train loss item: 0.37705492973327637
train loss item: 0.38158321380615234
train loss item: 0.4312494099140167
train loss item: 0.40601539611816406
train loss item: 0.25878503918647766
train loss item: 0.47405463457107544
train loss item: 0.30011799931526184
train loss item: 1.8759403228759766
train loss item: 0.43228986859321594
train loss item: 0.27250176668167114
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37063175439834595
train loss item: 0.29902151226997375
train loss item: 3.947033166885376
train loss item: 0.478669673204422
train loss item: 0.41550976037979126
train loss item: 0.2823288142681122
train loss item: 0.2913677394390106
train loss item: 0.6122833490371704
train loss item: 0.29741814732551575
train loss item: 0.45951148867607117
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3470873236656189
train loss item: 0.36318981647491455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2315360307693481
train loss item: 1.4951473474502563
train loss item: 3.4098076820373535
train loss item: 0.2728656232357025
train loss item: 0.28271758556365967
train loss item: 0.6820204257965088
train loss item: 0.32747241854667664
train loss item: 0.6805041432380676
1
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40764039754867554
train loss item: 0.7225446701049805
train loss item: 0.8893114328384399
train loss item: 0.7829195261001587
train loss item: 0.29536300897598267
train loss item: 0.41791871190071106
train loss item: 0.31172215938568115
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4493716061115265
train loss item: 0.6113709807395935
train loss item: 0.45497411489486694
train loss item: 0.3454032242298126
train loss item: 0.4403054714202881
train loss item: 0.2816068232059479
train loss item: 0.3324041962623596
train loss item: 0.711246907711029
train loss item: 0.26826685667037964
train loss item: 0.2934325337409973
train loss item: 0.4922246038913727
train loss item: 0.2767014801502228
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3281143307685852
train loss item: 1.952993392944336
train loss item: 0.5135407447814941
train loss item: 2.5215725898742676
train loss item: 0.4196229577064514
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2626209855079651
train loss item: 0.4253860414028168
train loss item: 0.39951568841934204
train loss item: 0.29863911867141724
train loss item: 0.29291844367980957
train loss item: 0.35073089599609375
train loss item: 0.29881617426872253
train loss item: 0.36321255564689636
train loss item: 0.44291359186172485
train loss item: 0.846362829208374
train loss item: 1.039322853088379
train loss item: 0.25906282663345337
train loss item: 0.698800802230835
train loss item: 1.4358466863632202
train loss item: 0.3205110430717468
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.070176601409912
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3621932864189148
train loss item: 0.45830103754997253
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 128 360 done at Thu Nov 14 12:13:44 CET 2024
UNet6 with 1 10 0.0001 256 360 start at Thu Nov 14 12:13:44 CET 2024
CUDA is available! Using GPU.
device: cuda
sub_batch_size: 1
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 256
memory after loading model
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from large pool |   1895 MiB |   1895 MiB |   1895 MiB |      0 B   |
|       from small pool |      3 MiB |      3 MiB |      3 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from large pool |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     196    |     196    |     196    |       0    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     173    |     173    |     173    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Epoch 1/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.819812536239624
train loss item: 0.9529114365577698
train loss item: 2.3863213062286377
train loss item: 2.270076036453247
train loss item: 0.6869325637817383
train loss item: 0.46848130226135254
train loss item: 0.5421428680419922
train loss item: 1.5739983320236206
train loss item: 1.2186293601989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5850042104721069
train loss item: 0.7131848931312561
train loss item: 0.5979920029640198
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.130446195602417
train loss item: 0.47118911147117615
train loss item: 0.5719398856163025
train loss item: 1.110304594039917
train loss item: 0.48696455359458923
train loss item: 0.7697487473487854
train loss item: 0.5989560484886169
train loss item: 1.0078785419464111
train loss item: 0.47610917687416077
train loss item: 0.6136468648910522
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4699391722679138
train loss item: 0.8132690191268921
train loss item: 1.3295847177505493
train loss item: 0.6827605366706848
train loss item: 0.4973190426826477
train loss item: 0.585635781288147
train loss item: 1.51414155960083
train loss item: 0.45469796657562256
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.624519407749176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9587867259979248
train loss item: 0.6278560161590576
train loss item: 0.49461838603019714
train loss item: 0.7044584155082703
train loss item: 0.5164517164230347
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4544129967689514
train loss item: 1.86475670337677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47753116488456726
train loss item: 2.5423285961151123
train loss item: 1.0763672590255737
train loss item: 1.039473056793213
train loss item: 0.5298306345939636
train loss item: 0.7522132992744446
train loss item: 0.5095365643501282
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48460251092910767
train loss item: 0.8418570160865784
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4620964825153351
train loss item: 0.47385135293006897
train loss item: 1.827709436416626
train loss item: 1.2050328254699707
train loss item: 3.6952083110809326
train loss item: 1.031891942024231
train loss item: 1.2293715476989746
train loss item: 0.49924877285957336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0482702255249023
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5716233253479004
train loss item: 4.473301887512207
train loss item: 1.4562150239944458
train loss item: 0.7648544311523438
train loss item: 1.2041324377059937
train loss item: 0.47707146406173706
train loss item: 0.630420446395874
train loss item: 1.144110083580017
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8894302248954773
train loss item: 0.44735756516456604
train loss item: 0.5024728775024414
train loss item: 0.5545372366905212
train loss item: 0.7979448437690735
train loss item: 0.5833857655525208
train loss item: 0.5818025469779968
train loss item: 0.5606418251991272
train loss item: 0.5785847902297974
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.1468136310577393
train loss item: 1.450875163078308
train loss item: 0.6367223858833313
train loss item: 0.5154714584350586
train loss item: 0.5152022838592529
train loss item: 0.528084397315979
train loss item: 0.9421567320823669
train loss item: 0.6088292002677917
train loss item: 0.6201375126838684
train loss item: 0.6374879479408264
train loss item: 0.5473155975341797
train loss item: 0.5828478932380676
train loss item: 0.6870982050895691
train loss item: 0.5076937675476074
train loss item: 2.2537639141082764
train loss item: 0.6441835165023804
train loss item: 0.4633548855781555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6354823112487793
train loss item: 0.5546389818191528
train loss item: 4.452296257019043
train loss item: 0.7913306355476379
train loss item: 0.6001733541488647
train loss item: 0.6769973039627075
train loss item: 0.4553399682044983
train loss item: 0.8695197105407715
train loss item: 0.4755610227584839
train loss item: 0.6617066860198975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5238131284713745
train loss item: 0.5245546698570251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5921008586883545
train loss item: 1.9015032052993774
train loss item: 3.9101366996765137
train loss item: 0.6102474927902222
train loss item: 0.46769586205482483
train loss item: 1.5767532587051392
train loss item: 0.5057856440544128
train loss item: 0.9696930050849915
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.587297797203064
train loss item: 1.0258359909057617
train loss item: 1.5137578248977661
train loss item: 1.074904203414917
train loss item: 0.4704446494579315
train loss item: 0.8295745253562927
train loss item: 0.5119169354438782
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7610528469085693
train loss item: 0.9171606302261353
train loss item: 0.6281032562255859
train loss item: 0.5952099561691284
train loss item: 0.6960201859474182
train loss item: 0.6789958477020264
train loss item: 0.4713931977748871
train loss item: 1.4038227796554565
train loss item: 0.578901469707489
train loss item: 0.48654380440711975
train loss item: 0.7137617468833923
train loss item: 0.586050271987915
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4967315196990967
train loss item: 2.397573947906494
train loss item: 0.7835416197776794
train loss item: 2.8879265785217285
train loss item: 0.5795229077339172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46186575293540955
train loss item: 0.6076156497001648
train loss item: 0.6935876607894897
train loss item: 0.5685961842536926
train loss item: 0.6882216334342957
train loss item: 0.5235651135444641
train loss item: 0.561565101146698
train loss item: 0.5332809686660767
train loss item: 0.7282124757766724
train loss item: 1.192653775215149
train loss item: 1.4065489768981934
train loss item: 0.482292503118515
train loss item: 1.0171582698822021
train loss item: 2.007269859313965
train loss item: 0.48738574981689453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.58840799331665
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6192532181739807
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.9620572001134094
testing phase
test loss item: 0.30700448155403137
test loss item: 0.3406241536140442
test loss item: 0.3142494261264801
test loss item: 0.33716198801994324
test loss item: 1.785476565361023
test loss item: 0.47348830103874207
test loss item: 0.5485752820968628
test loss item: 0.340224951505661
test loss item: 0.3938576281070709
test loss item: 0.6535168290138245
test loss item: 0.31019723415374756
test loss item: 0.2676251232624054
test loss item: 3.5799756050109863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.565757393836975
test loss item: 0.26068979501724243
test loss item: 0.3318127393722534
test loss item: 0.5955690741539001
test loss item: 0.8363478779792786
test loss item: 0.7259860634803772
test loss item: 0.2798157334327698
test loss item: 2.509932041168213
test loss item: 0.2846217453479767
test loss item: 0.40899658203125
test loss item: 0.35745885968208313
test loss item: 0.3996308743953705
test loss item: 0.5522034764289856
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44153961539268494
test loss item: 0.2876865267753601
test loss item: 0.3112681806087494
test loss item: 0.33096328377723694
test loss item: 0.3602879047393799
test loss item: 0.6492605805397034
test loss item: 0.9702422022819519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.288961797952652
test loss item: 1.448490858078003
test loss item: 0.7130475044250488
test loss item: 0.2787633538246155
test loss item: 1.5889075994491577
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4888222813606262
test loss item: 0.9393210411071777
test loss item: 0.40530553460121155
test loss item: 0.7099846601486206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3897227942943573
test loss item: 0.45554205775260925
test loss item: 0.31107282638549805
test loss item: 0.3411215841770172
test loss item: 0.4289405643939972
test loss item: 0.32115212082862854
test loss item: 0.8526934385299683
test loss item: 0.4736865758895874
test loss item: 0.3118109107017517
test loss item: 1.1526641845703125
test loss item: 0.5507254600524902
test loss item: 0.6491563320159912
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.247267007827759
test loss item: 0.23944135010242462
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31663045287132263
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3552955687046051
test loss item: 1.4349113702774048
test loss item: 0.5468447208404541
test loss item: 0.3253821134567261
test loss item: 1.1189672946929932
test loss item: 0.6269294023513794
test loss item: 1.3700172901153564
test loss item: 0.8468562364578247
test loss item: 2.030183792114258
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.177152633666992
test loss item: 0.6106455326080322
test loss item: 1.208946943283081
test loss item: 0.6529620885848999
test loss item: 0.3285670280456543
test loss item: 0.6448493003845215
test loss item: 0.3131295144557953
test loss item: 0.34905707836151123
test loss item: 0.3355085253715515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6913067102432251
test loss item: 0.4760951101779938
test loss item: 0.47110098600387573
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2514488697052002
test loss item: 0.975771427154541
test loss item: 0.31265589594841003
test loss item: 0.4637056291103363
test loss item: 0.6420323848724365
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42700302600860596
test loss item: 0.5958372354507446
test loss item: 1.3047126531600952
test loss item: 1.6106274127960205
test loss item: 0.4408532977104187
test loss item: 1.196992039680481
test loss item: 0.5842834711074829
test loss item: 0.3279908001422882
test loss item: 0.3108018636703491
test loss item: 0.437457412481308
test loss item: 0.5206288695335388
test loss item: 0.4721603989601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4369902610778809
test loss item: 0.5191566348075867
test loss item: 0.30221399664878845
test loss item: 2.314314126968384
test loss item: 0.3045101463794708
test loss item: 1.7270123958587646
test loss item: 0.6381760239601135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30443423986434937
test loss item: 0.5151978731155396
test loss item: 0.4572257399559021
test loss item: 0.3200843930244446
test loss item: 0.30178847908973694
test loss item: 0.930814802646637
test loss item: 0.3240758776664734
test loss item: 0.6097821593284607
test loss item: 0.325261652469635
test loss item: 0.41945645213127136
test loss item: 0.4520036578178406
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5544935464859009
test loss item: 2.867772102355957
test loss item: 0.5985177755355835
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.563450038433075
test loss item: 0.7165866494178772
test loss item: 0.549558162689209
test loss item: 0.2455824613571167
test loss item: 1.2389148473739624
test loss item: 0.3256556987762451
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9184989333152771
test loss item: 0.3167290985584259
test loss item: 0.22759725153446198
test loss item: 0.2929801046848297
test loss item: 2.2794742584228516
test loss item: 0.3319101929664612
test loss item: 1.3680620193481445
test loss item: 0.8382603526115417
test loss item: 0.3499408960342407
test loss item: 0.34308305382728577
test loss item: 0.23289255797863007
test loss item: 0.38227248191833496
test loss item: 0.25725919008255005
test loss item: 0.2660255432128906
test loss item: 0.40560081601142883
test loss item: 4.938460826873779
test loss item: 0.301708459854126
test loss item: 0.8617050647735596
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30878475308418274
test loss item: 0.38532063364982605
test loss item: 0.3175783157348633
test loss item: 0.24404272437095642
test loss item: 0.3636820614337921
test loss item: 2.5288453102111816
test loss item: 1.1675666570663452
test loss item: 1.9713983535766602
test loss item: 0.5098727345466614
test loss item: 3.3850016593933105
test loss item: 0.38600391149520874
test loss item: 0.8558758497238159
test loss item: 0.3959777355194092
test loss item: 0.4422975182533264
test loss item: 0.2590189576148987
test loss item: 0.31822469830513
test loss item: 0.31177300214767456
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30703553557395935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [1/10], Training Loss: 0.9621, Testing Loss: 0.7408
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9542.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 2/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.8054918646812439
train loss item: 0.8987407088279724
train loss item: 2.2919647693634033
train loss item: 1.7529160976409912
train loss item: 0.619989275932312
train loss item: 0.40582361817359924
train loss item: 0.41985389590263367
train loss item: 1.4629015922546387
train loss item: 0.8853329420089722
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5445839762687683
train loss item: 0.674015462398529
train loss item: 0.4879615008831024
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 2.0255072116851807
train loss item: 0.42342409491539
train loss item: 0.4279136657714844
train loss item: 0.7758976221084595
train loss item: 0.3747066557407379
train loss item: 0.6917065382003784
train loss item: 0.4910371005535126
train loss item: 0.9175930619239807
train loss item: 0.41859519481658936
train loss item: 0.5455162525177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4035603404045105
train loss item: 0.7738136053085327
train loss item: 1.258652925491333
train loss item: 0.6637643575668335
train loss item: 0.4387687146663666
train loss item: 0.5114082098007202
train loss item: 1.4561054706573486
train loss item: 0.3829658627510071
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.524093747138977
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9038376212120056
train loss item: 0.5851014256477356
train loss item: 0.4196215569972992
train loss item: 0.6253869533538818
train loss item: 0.46743452548980713
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3872469365596771
train loss item: 1.8338868618011475
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41059255599975586
train loss item: 2.443751335144043
train loss item: 1.0170003175735474
train loss item: 0.995087206363678
train loss item: 0.40507644414901733
train loss item: 0.6749089360237122
train loss item: 0.4420895576477051
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43542855978012085
train loss item: 0.7903597950935364
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.38722386956214905
train loss item: 0.3567829728126526
train loss item: 1.8009729385375977
train loss item: 1.1887037754058838
train loss item: 3.5324246883392334
train loss item: 0.9487202763557434
train loss item: 1.1619105339050293
train loss item: 0.4423845112323761
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9855327606201172
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008445143699646
train loss item: 4.32944393157959
train loss item: 1.3845133781433105
train loss item: 0.7258349061012268
train loss item: 1.1670548915863037
train loss item: 0.4191601872444153
train loss item: 0.5944328904151917
train loss item: 1.1055978536605835
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8371577262878418
train loss item: 0.39751115441322327
train loss item: 0.35939866304397583
train loss item: 0.48182982206344604
train loss item: 0.7070066332817078
train loss item: 0.5354675054550171
train loss item: 0.49496012926101685
train loss item: 0.4740426540374756
train loss item: 0.530408501625061
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0800422430038452
train loss item: 1.3574137687683105
train loss item: 0.46985873579978943
train loss item: 0.4406193196773529
train loss item: 0.446282297372818
train loss item: 0.4453347325325012
train loss item: 0.8741986751556396
train loss item: 0.5293667912483215
train loss item: 0.5353571176528931
train loss item: 0.5791845321655273
train loss item: 0.5059974789619446
train loss item: 0.4314745366573334
train loss item: 0.6558837294578552
train loss item: 0.42855778336524963
train loss item: 2.206753730773926
train loss item: 0.6051461696624756
train loss item: 0.3908587694168091
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5420536398887634
train loss item: 0.3993499279022217
train loss item: 4.305393695831299
train loss item: 0.7225639224052429
train loss item: 0.537074863910675
train loss item: 0.44736871123313904
train loss item: 0.38459938764572144
train loss item: 0.7890965938568115
train loss item: 0.414558082818985
train loss item: 0.603987991809845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46700191497802734
train loss item: 0.4694973826408386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.5276029109954834
train loss item: 1.850875973701477
train loss item: 3.771341323852539
train loss item: 0.464836061000824
train loss item: 0.3977920413017273
train loss item: 1.2948168516159058
train loss item: 0.44135576486587524
train loss item: 0.9448678493499756
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5373835563659668
train loss item: 0.9716783761978149
train loss item: 1.4940139055252075
train loss item: 1.019716739654541
train loss item: 0.4043095111846924
train loss item: 0.6526936292648315
train loss item: 0.4361291527748108
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6763297915458679
train loss item: 0.846520721912384
train loss item: 0.5822674632072449
train loss item: 0.5073311924934387
train loss item: 0.6249715685844421
train loss item: 0.4491252601146698
train loss item: 0.41228458285331726
train loss item: 0.9837915897369385
train loss item: 0.43238136172294617
train loss item: 0.3756480813026428
train loss item: 0.6602489352226257
train loss item: 0.43490418791770935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4389401078224182
train loss item: 2.278047800064087
train loss item: 0.7019065022468567
train loss item: 2.877516031265259
train loss item: 0.5246642231941223
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3866238594055176
train loss item: 0.5449886918067932
train loss item: 0.6539317965507507
train loss item: 0.4264691472053528
train loss item: 0.45463478565216064
train loss item: 0.45638638734817505
train loss item: 0.4559684693813324
train loss item: 0.47985419631004333
train loss item: 0.6698529720306396
train loss item: 1.1541709899902344
train loss item: 1.3551671504974365
train loss item: 0.42673611640930176
train loss item: 0.969355583190918
train loss item: 1.86638605594635
train loss item: 0.41490432620048523
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.436746597290039
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5215848684310913
train loss item: 0.6882298588752747
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8735782896217547
testing phase
test loss item: 0.2910808324813843
test loss item: 0.339705228805542
test loss item: 0.32693812251091003
test loss item: 0.3572648763656616
test loss item: 1.7474555969238281
test loss item: 0.4156818687915802
test loss item: 0.5146547555923462
test loss item: 0.3263559937477112
test loss item: 0.4050033688545227
test loss item: 0.6628684997558594
test loss item: 0.3095269501209259
test loss item: 0.2691153585910797
test loss item: 3.3218436241149902
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3713886737823486
test loss item: 0.2535076141357422
test loss item: 0.34903863072395325
test loss item: 0.5911073684692383
test loss item: 0.839975893497467
test loss item: 0.7068681120872498
test loss item: 0.29752203822135925
test loss item: 2.363287925720215
test loss item: 0.28166744112968445
test loss item: 0.3891099989414215
test loss item: 0.38980233669281006
test loss item: 0.3471679389476776
test loss item: 0.605440080165863
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4457036554813385
test loss item: 0.2734906077384949
test loss item: 0.32835954427719116
test loss item: 0.359563946723938
test loss item: 0.337926983833313
test loss item: 0.5774652361869812
test loss item: 0.985427737236023
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26352038979530334
test loss item: 1.312412142753601
test loss item: 0.6180955171585083
test loss item: 0.33285030722618103
test loss item: 1.6097663640975952
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46562203764915466
test loss item: 0.8245884776115417
test loss item: 0.37139299511909485
test loss item: 0.7158008813858032
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651127815246582
test loss item: 0.463326096534729
test loss item: 0.3075437545776367
test loss item: 0.3215090334415436
test loss item: 0.3938661515712738
test loss item: 0.3162213861942291
test loss item: 0.8167585730552673
test loss item: 0.4902053773403168
test loss item: 0.30435505509376526
test loss item: 1.063299536705017
test loss item: 0.5574160814285278
test loss item: 0.6326975226402283
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.0866880416870117
test loss item: 0.25975120067596436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3224281370639801
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33894896507263184
test loss item: 1.4440157413482666
test loss item: 0.4990064203739166
test loss item: 0.35088396072387695
test loss item: 1.121922254562378
test loss item: 0.6656253337860107
test loss item: 1.443213701248169
test loss item: 0.8518323302268982
test loss item: 1.8705593347549438
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 3.0004007816314697
test loss item: 0.558804452419281
test loss item: 1.2101176977157593
test loss item: 0.5939472913742065
test loss item: 0.3301582634449005
test loss item: 0.6018231511116028
test loss item: 0.3240443766117096
test loss item: 0.3134249448776245
test loss item: 0.3312011957168579
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7392765283584595
test loss item: 0.4460921585559845
test loss item: 0.43280500173568726
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2830102443695068
test loss item: 0.8499088883399963
test loss item: 0.32469800114631653
test loss item: 0.41468173265457153
test loss item: 0.6516105532646179
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.41941824555397034
test loss item: 0.4853822886943817
test loss item: 1.3014832735061646
test loss item: 1.503757357597351
test loss item: 0.4332665205001831
test loss item: 1.2588262557983398
test loss item: 0.6188225150108337
test loss item: 0.311491996049881
test loss item: 0.30573493242263794
test loss item: 0.4062337577342987
test loss item: 0.5489872097969055
test loss item: 0.4325945973396301
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4763507843017578
test loss item: 0.5425165891647339
test loss item: 0.3263673484325409
test loss item: 2.2154507637023926
test loss item: 0.3110277056694031
test loss item: 1.698416829109192
test loss item: 0.7162654399871826
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30421683192253113
test loss item: 0.4955833852291107
test loss item: 0.49102482199668884
test loss item: 0.35175445675849915
test loss item: 0.30143868923187256
test loss item: 0.9524814486503601
test loss item: 0.3364218473434448
test loss item: 0.49853748083114624
test loss item: 0.29945695400238037
test loss item: 0.3815131187438965
test loss item: 0.43095663189888
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5015162229537964
test loss item: 2.695323944091797
test loss item: 0.5596435070037842
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5550315380096436
test loss item: 0.5891832113265991
test loss item: 0.5201020836830139
test loss item: 0.2705438733100891
test loss item: 1.226020097732544
test loss item: 0.3457849621772766
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.817513108253479
test loss item: 0.3333521783351898
test loss item: 0.23765070736408234
test loss item: 0.29328033328056335
test loss item: 2.050132989883423
test loss item: 0.3751061260700226
test loss item: 1.4154950380325317
test loss item: 0.7316104173660278
test loss item: 0.3002190589904785
test loss item: 0.3222099840641022
test loss item: 0.24503745138645172
test loss item: 0.3516719341278076
test loss item: 0.2509263753890991
test loss item: 0.27331241965293884
test loss item: 0.3810742199420929
test loss item: 4.645137786865234
test loss item: 0.3096846044063568
test loss item: 0.8747075200080872
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29147544503211975
test loss item: 0.374784916639328
test loss item: 0.3082745373249054
test loss item: 0.2408846616744995
test loss item: 0.34978386759757996
test loss item: 2.380443811416626
test loss item: 1.1850717067718506
test loss item: 1.818363070487976
test loss item: 0.509240984916687
test loss item: 3.1835126876831055
test loss item: 0.4001874327659607
test loss item: 0.7113765478134155
test loss item: 0.36970239877700806
test loss item: 0.4301750063896179
test loss item: 0.25047388672828674
test loss item: 0.34190893173217773
test loss item: 0.334003746509552
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28028765320777893
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [2/10], Training Loss: 0.8736, Testing Loss: 0.7150
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 3/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.8051015734672546
train loss item: 0.8529430627822876
train loss item: 2.214339017868042
train loss item: 1.5116938352584839
train loss item: 0.5819724798202515
train loss item: 0.4383721649646759
train loss item: 0.41861456632614136
train loss item: 1.3880025148391724
train loss item: 0.7734600305557251
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5285988450050354
train loss item: 0.6681726574897766
train loss item: 0.4541483521461487
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.9507399797439575
train loss item: 0.39212068915367126
train loss item: 0.3957740068435669
train loss item: 0.7045068740844727
train loss item: 0.3592888116836548
train loss item: 0.640126645565033
train loss item: 0.45678287744522095
train loss item: 0.8674015998840332
train loss item: 0.3970751464366913
train loss item: 0.5010831356048584
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37873467803001404
train loss item: 0.7549389600753784
train loss item: 1.209031105041504
train loss item: 0.6678506731987
train loss item: 0.41784077882766724
train loss item: 0.4937847852706909
train loss item: 1.4121454954147339
train loss item: 0.35888829827308655
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4921519160270691
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8699957728385925
train loss item: 0.5450640916824341
train loss item: 0.3905563950538635
train loss item: 0.5765966773033142
train loss item: 0.43139874935150146
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3643650412559509
train loss item: 1.7877963781356812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3885669708251953
train loss item: 2.3744027614593506
train loss item: 0.9635235071182251
train loss item: 0.9398651123046875
train loss item: 0.3759452998638153
train loss item: 0.6498486995697021
train loss item: 0.42940425872802734
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4148862063884735
train loss item: 0.7516554594039917
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35976043343544006
train loss item: 0.34368252754211426
train loss item: 1.7625540494918823
train loss item: 1.1395182609558105
train loss item: 3.423069477081299
train loss item: 0.9135857224464417
train loss item: 1.1172702312469482
train loss item: 0.4248979389667511
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9466566443443298
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4133960008621216
train loss item: 4.23195743560791
train loss item: 1.3307774066925049
train loss item: 0.7032762765884399
train loss item: 1.1340081691741943
train loss item: 0.390132337808609
train loss item: 0.5579783916473389
train loss item: 1.0716018676757812
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.802668571472168
train loss item: 0.38565701246261597
train loss item: 0.32250872254371643
train loss item: 0.47355711460113525
train loss item: 0.661649763584137
train loss item: 0.5043798685073853
train loss item: 0.4497036635875702
train loss item: 0.438198983669281
train loss item: 0.5030548572540283
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.0335768461227417
train loss item: 1.2954051494598389
train loss item: 0.44945961236953735
train loss item: 0.41032615303993225
train loss item: 0.44713613390922546
train loss item: 0.4125525653362274
train loss item: 0.8212732076644897
train loss item: 0.5073781609535217
train loss item: 0.5154852271080017
train loss item: 0.5469192266464233
train loss item: 0.4909832775592804
train loss item: 0.3931466341018677
train loss item: 0.621256947517395
train loss item: 0.39793649315834045
train loss item: 2.1539275646209717
train loss item: 0.5704979300498962
train loss item: 0.3635222911834717
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.516581118106842
train loss item: 0.403873085975647
train loss item: 4.208215236663818
train loss item: 0.6724585890769958
train loss item: 0.5222636461257935
train loss item: 0.4144033193588257
train loss item: 0.35863155126571655
train loss item: 0.746972918510437
train loss item: 0.3903963267803192
train loss item: 0.5846830606460571
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43731755018234253
train loss item: 0.4497511386871338
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.481804609298706
train loss item: 1.7918583154678345
train loss item: 3.672724723815918
train loss item: 0.42840874195098877
train loss item: 0.36995062232017517
train loss item: 1.1104559898376465
train loss item: 0.41665565967559814
train loss item: 0.9020617604255676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5116944313049316
train loss item: 0.9252290725708008
train loss item: 1.414633870124817
train loss item: 0.9859626293182373
train loss item: 0.3803067207336426
train loss item: 0.5922043323516846
train loss item: 0.402712345123291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6224695444107056
train loss item: 0.794919490814209
train loss item: 0.5667665600776672
train loss item: 0.4867575764656067
train loss item: 0.5816335678100586
train loss item: 0.4143410921096802
train loss item: 0.44441157579421997
train loss item: 0.8031931519508362
train loss item: 0.40109309554100037
train loss item: 0.3602941930294037
train loss item: 0.627627432346344
train loss item: 0.3945261240005493
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4165565073490143
train loss item: 2.199267625808716
train loss item: 0.6530634164810181
train loss item: 2.8289592266082764
train loss item: 0.5036813020706177
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3602833151817322
train loss item: 0.5181873440742493
train loss item: 0.6069742441177368
train loss item: 0.4211292862892151
train loss item: 0.40407049655914307
train loss item: 0.4450536072254181
train loss item: 0.4276082515716553
train loss item: 0.4543696343898773
train loss item: 0.6541560292243958
train loss item: 1.1092151403427124
train loss item: 1.3023735284805298
train loss item: 0.39061033725738525
train loss item: 0.9333477020263672
train loss item: 1.7632112503051758
train loss item: 0.39761194586753845
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.3332133293151855
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4968581199645996
train loss item: 0.6446283459663391
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.834411295032815
testing phase
test loss item: 0.3009817898273468
test loss item: 0.330905556678772
test loss item: 0.3250221312046051
test loss item: 0.36568427085876465
test loss item: 1.7290055751800537
test loss item: 0.4011066257953644
test loss item: 0.48552170395851135
test loss item: 0.3112458288669586
test loss item: 0.41055041551589966
test loss item: 0.6634652614593506
test loss item: 0.30854499340057373
test loss item: 0.2624979615211487
test loss item: 3.001563787460327
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1593984365463257
test loss item: 0.25046947598457336
test loss item: 0.3570266366004944
test loss item: 0.6015494465827942
test loss item: 0.8486559391021729
test loss item: 0.6967743635177612
test loss item: 0.3074794411659241
test loss item: 2.3161771297454834
test loss item: 0.2662135362625122
test loss item: 0.3801100254058838
test loss item: 0.41451993584632874
test loss item: 0.33388975262641907
test loss item: 0.6711161732673645
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4386739730834961
test loss item: 0.25802141427993774
test loss item: 0.3298342227935791
test loss item: 0.36932167410850525
test loss item: 0.34090322256088257
test loss item: 0.5406013131141663
test loss item: 0.9884539246559143
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2765680253505707
test loss item: 1.1859983205795288
test loss item: 0.5981932878494263
test loss item: 0.3725060820579529
test loss item: 1.607072114944458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44445177912712097
test loss item: 0.7472361326217651
test loss item: 0.39165690541267395
test loss item: 0.7237173914909363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34490087628364563
test loss item: 0.472190797328949
test loss item: 0.2848226726055145
test loss item: 0.34840014576911926
test loss item: 0.39614784717559814
test loss item: 0.3048010468482971
test loss item: 0.8159636855125427
test loss item: 0.4987246096134186
test loss item: 0.29605478048324585
test loss item: 1.0098850727081299
test loss item: 0.5547215938568115
test loss item: 0.6246765851974487
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.991248369216919
test loss item: 0.2810724377632141
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3176041841506958
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32212337851524353
test loss item: 1.4440407752990723
test loss item: 0.45975369215011597
test loss item: 0.35753685235977173
test loss item: 1.117979884147644
test loss item: 0.7108076214790344
test loss item: 1.2748773097991943
test loss item: 0.854532778263092
test loss item: 1.683098554611206
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.9541757106781006
test loss item: 0.5188186168670654
test loss item: 1.2081797122955322
test loss item: 0.553598165512085
test loss item: 0.32514896988868713
test loss item: 0.5683735609054565
test loss item: 0.3221145570278168
test loss item: 0.31752318143844604
test loss item: 0.33040767908096313
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7612084150314331
test loss item: 0.4317520260810852
test loss item: 0.40538257360458374
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2936357259750366
test loss item: 0.7912000417709351
test loss item: 0.3224804103374481
test loss item: 0.40222427248954773
test loss item: 0.6621419787406921
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4554203152656555
test loss item: 0.4259212911128998
test loss item: 1.2992507219314575
test loss item: 1.4417893886566162
test loss item: 0.4654732048511505
test loss item: 1.283136248588562
test loss item: 0.6391441226005554
test loss item: 0.31901559233665466
test loss item: 0.28225088119506836
test loss item: 0.3957742750644684
test loss item: 0.5741451978683472
test loss item: 0.4031803607940674
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4844486713409424
test loss item: 0.5654609203338623
test loss item: 0.35035383701324463
test loss item: 2.1807587146759033
test loss item: 0.3085588812828064
test loss item: 1.5360468626022339
test loss item: 0.7421764135360718
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28466877341270447
test loss item: 0.49001529812812805
test loss item: 0.5204781293869019
test loss item: 0.3741951584815979
test loss item: 0.28276923298835754
test loss item: 0.9604619145393372
test loss item: 0.3327066898345947
test loss item: 0.4392565190792084
test loss item: 0.30512797832489014
test loss item: 0.3779858350753784
test loss item: 0.4165716767311096
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46648362278938293
test loss item: 2.556732654571533
test loss item: 0.5200418829917908
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5626492500305176
test loss item: 0.5143386125564575
test loss item: 0.49985259771347046
test loss item: 0.29393497109413147
test loss item: 1.2227551937103271
test loss item: 0.34601378440856934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.774863600730896
test loss item: 0.33298274874687195
test loss item: 0.25237441062927246
test loss item: 0.2771851718425751
test loss item: 1.8044041395187378
test loss item: 0.41706353425979614
test loss item: 1.4191418886184692
test loss item: 0.6663928031921387
test loss item: 0.30404987931251526
test loss item: 0.33640095591545105
test loss item: 0.2615906298160553
test loss item: 0.36013948917388916
test loss item: 0.25128769874572754
test loss item: 0.26732322573661804
test loss item: 0.36157360672950745
test loss item: 4.54500150680542
test loss item: 0.3109053671360016
test loss item: 0.9009257555007935
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29989805817604065
test loss item: 0.3699263036251068
test loss item: 0.28110992908477783
test loss item: 0.24399077892303467
test loss item: 0.3538863956928253
test loss item: 2.2433714866638184
test loss item: 1.2035903930664062
test loss item: 1.6739643812179565
test loss item: 0.5127902626991272
test loss item: 3.1049587726593018
test loss item: 0.42440757155418396
test loss item: 0.6008726954460144
test loss item: 0.3786293864250183
test loss item: 0.45941489934921265
test loss item: 0.24955444037914276
test loss item: 0.3433588147163391
test loss item: 0.3361283540725708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28827813267707825
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [3/10], Training Loss: 0.8344, Testing Loss: 0.6973
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 4/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.7930572628974915
train loss item: 0.8106309175491333
train loss item: 2.154629945755005
train loss item: 1.4358925819396973
train loss item: 0.5403582453727722
train loss item: 0.42518410086631775
train loss item: 0.3946791887283325
train loss item: 1.337820291519165
train loss item: 0.7283328771591187
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5086467266082764
train loss item: 0.6587628722190857
train loss item: 0.43243226408958435
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8997114896774292
train loss item: 0.3564055263996124
train loss item: 0.3781545162200928
train loss item: 0.6633870601654053
train loss item: 0.34436315298080444
train loss item: 0.6021005511283875
train loss item: 0.4337024390697479
train loss item: 0.8381946086883545
train loss item: 0.3798515796661377
train loss item: 0.46760791540145874
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36306190490722656
train loss item: 0.7336841821670532
train loss item: 1.1666553020477295
train loss item: 0.6589175462722778
train loss item: 0.40363696217536926
train loss item: 0.4622725248336792
train loss item: 1.3715578317642212
train loss item: 0.3419116735458374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.46878868341445923
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8391717672348022
train loss item: 0.5013014674186707
train loss item: 0.37441208958625793
train loss item: 0.5385311841964722
train loss item: 0.3904067277908325
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35047394037246704
train loss item: 1.732211947441101
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3668222427368164
train loss item: 2.326054096221924
train loss item: 0.9112567901611328
train loss item: 0.8813654184341431
train loss item: 0.35766473412513733
train loss item: 0.6242033839225769
train loss item: 0.4178542494773865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39821115136146545
train loss item: 0.7165666818618774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34212782979011536
train loss item: 0.3284926116466522
train loss item: 1.7136108875274658
train loss item: 0.9933941960334778
train loss item: 3.3595523834228516
train loss item: 0.8102750778198242
train loss item: 1.0816224813461304
train loss item: 0.413299024105072
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9135479927062988
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4067084491252899
train loss item: 4.174579620361328
train loss item: 1.2894893884658813
train loss item: 0.6825628876686096
train loss item: 1.094824194908142
train loss item: 0.36362388730049133
train loss item: 0.5129873752593994
train loss item: 1.030917763710022
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7728220224380493
train loss item: 0.37418532371520996
train loss item: 0.30440935492515564
train loss item: 0.46403172612190247
train loss item: 0.6374162435531616
train loss item: 0.47682198882102966
train loss item: 0.4160236716270447
train loss item: 0.41514167189598083
train loss item: 0.4792505204677582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9984489679336548
train loss item: 1.2547656297683716
train loss item: 0.42159074544906616
train loss item: 0.3940301835536957
train loss item: 0.43876731395721436
train loss item: 0.3962877094745636
train loss item: 0.7742434144020081
train loss item: 0.48457634449005127
train loss item: 0.4956094026565552
train loss item: 0.5226385593414307
train loss item: 0.4763917326927185
train loss item: 0.3738737106323242
train loss item: 0.5782414078712463
train loss item: 0.3818342983722687
train loss item: 2.098876714706421
train loss item: 0.5317774415016174
train loss item: 0.34576982259750366
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.49367421865463257
train loss item: 0.38496139645576477
train loss item: 4.151196479797363
train loss item: 0.6276695728302002
train loss item: 0.5083506107330322
train loss item: 0.4003390669822693
train loss item: 0.34301993250846863
train loss item: 0.722851037979126
train loss item: 0.37242257595062256
train loss item: 0.5657562613487244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41457399725914
train loss item: 0.43614786863327026
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4422942399978638
train loss item: 1.7304792404174805
train loss item: 3.612187385559082
train loss item: 0.4083971083164215
train loss item: 0.35246723890304565
train loss item: 0.9530659914016724
train loss item: 0.40092340111732483
train loss item: 0.8486791849136353
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.490337997674942
train loss item: 0.8784583210945129
train loss item: 1.2507680654525757
train loss item: 0.9552468061447144
train loss item: 0.3652568459510803
train loss item: 0.5493290424346924
train loss item: 0.3815479874610901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5802987217903137
train loss item: 0.7484342455863953
train loss item: 0.5494769811630249
train loss item: 0.4643653333187103
train loss item: 0.5457404851913452
train loss item: 0.3989465534687042
train loss item: 0.42997774481773376
train loss item: 0.7423388957977295
train loss item: 0.38405466079711914
train loss item: 0.3448895215988159
train loss item: 0.5970014333724976
train loss item: 0.376468688249588
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40056467056274414
train loss item: 2.1499416828155518
train loss item: 0.6170884370803833
train loss item: 2.7615437507629395
train loss item: 0.4902063310146332
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.342864990234375
train loss item: 0.5018545985221863
train loss item: 0.5526416301727295
train loss item: 0.3963841199874878
train loss item: 0.3859878480434418
train loss item: 0.43436458706855774
train loss item: 0.40195322036743164
train loss item: 0.4347972571849823
train loss item: 0.6304241418838501
train loss item: 1.0596929788589478
train loss item: 1.2464430332183838
train loss item: 0.35329416394233704
train loss item: 0.8949295878410339
train loss item: 1.693165898323059
train loss item: 0.38602107763290405
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.273541450500488
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47628358006477356
train loss item: 0.6043571829795837
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.8012571311310718
testing phase
test loss item: 0.3012368679046631
test loss item: 0.31970176100730896
test loss item: 0.31297439336776733
test loss item: 0.3660229742527008
test loss item: 1.690245509147644
test loss item: 0.3909095525741577
test loss item: 0.48050469160079956
test loss item: 0.2977859675884247
test loss item: 0.4014168977737427
test loss item: 0.6510108709335327
test loss item: 0.2988084554672241
test loss item: 0.2572886347770691
test loss item: 2.747511148452759
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0475670099258423
test loss item: 0.2501181662082672
test loss item: 0.3536822497844696
test loss item: 0.5904970169067383
test loss item: 0.832817792892456
test loss item: 0.673137366771698
test loss item: 0.3048330247402191
test loss item: 2.3256118297576904
test loss item: 0.25499701499938965
test loss item: 0.3805064260959625
test loss item: 0.4134778380393982
test loss item: 0.3232080638408661
test loss item: 0.7014595866203308
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42298492789268494
test loss item: 0.24957628548145294
test loss item: 0.32426854968070984
test loss item: 0.3672144114971161
test loss item: 0.33481621742248535
test loss item: 0.5141910910606384
test loss item: 0.9611759185791016
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28698059916496277
test loss item: 1.147149682044983
test loss item: 0.5965621471405029
test loss item: 0.3660498261451721
test loss item: 1.560685396194458
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.44465866684913635
test loss item: 0.6966552734375
test loss item: 0.4107983708381653
test loss item: 0.7075685858726501
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3296741843223572
test loss item: 0.46276840567588806
test loss item: 0.26597264409065247
test loss item: 0.36987045407295227
test loss item: 0.396967351436615
test loss item: 0.2927326261997223
test loss item: 0.8069980144500732
test loss item: 0.48971521854400635
test loss item: 0.2855314314365387
test loss item: 0.9718844294548035
test loss item: 0.539330244064331
test loss item: 0.6028634309768677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.9420925378799438
test loss item: 0.29041188955307007
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3132390081882477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.307876318693161
test loss item: 1.4092395305633545
test loss item: 0.45433834195137024
test loss item: 0.3532947301864624
test loss item: 1.0861068964004517
test loss item: 0.7153897881507874
test loss item: 1.198390007019043
test loss item: 0.835419237613678
test loss item: 1.572530746459961
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.95797061920166
test loss item: 0.5017762184143066
test loss item: 1.1789615154266357
test loss item: 0.5256514549255371
test loss item: 0.3139766752719879
test loss item: 0.5398204922676086
test loss item: 0.3169075548648834
test loss item: 0.31616872549057007
test loss item: 0.3230401575565338
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.739900529384613
test loss item: 0.414083868265152
test loss item: 0.4060840904712677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.262861967086792
test loss item: 0.7650795578956604
test loss item: 0.31631267070770264
test loss item: 0.39587271213531494
test loss item: 0.6478325128555298
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.46878260374069214
test loss item: 0.39369410276412964
test loss item: 1.2722307443618774
test loss item: 1.420563817024231
test loss item: 0.4882575571537018
test loss item: 1.242414116859436
test loss item: 0.6250495910644531
test loss item: 0.31117379665374756
test loss item: 0.26315516233444214
test loss item: 0.38204920291900635
test loss item: 0.5719656348228455
test loss item: 0.4046474099159241
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.4417085647583008
test loss item: 0.5625807642936707
test loss item: 0.35835471749305725
test loss item: 2.158461093902588
test loss item: 0.30063894391059875
test loss item: 1.453438639640808
test loss item: 0.7092558741569519
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2675003409385681
test loss item: 0.47363173961639404
test loss item: 0.522057056427002
test loss item: 0.3735804557800293
test loss item: 0.267120361328125
test loss item: 0.9331150650978088
test loss item: 0.32634595036506653
test loss item: 0.4083330035209656
test loss item: 0.3046513497829437
test loss item: 0.37604475021362305
test loss item: 0.4043574333190918
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4441695511341095
test loss item: 2.4657676219940186
test loss item: 0.5131370425224304
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5579653382301331
test loss item: 0.4767725169658661
test loss item: 0.47972288727760315
test loss item: 0.3032236099243164
test loss item: 1.2048949003219604
test loss item: 0.33914628624916077
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8306203484535217
test loss item: 0.32698312401771545
test loss item: 0.257927268743515
test loss item: 0.263372540473938
test loss item: 1.629010558128357
test loss item: 0.4208572208881378
test loss item: 1.3661460876464844
test loss item: 0.6246269941329956
test loss item: 0.30754056572914124
test loss item: 0.33570539951324463
test loss item: 0.27124306559562683
test loss item: 0.35954025387763977
test loss item: 0.2540150582790375
test loss item: 0.2586996555328369
test loss item: 0.34557339549064636
test loss item: 4.521927356719971
test loss item: 0.30516377091407776
test loss item: 0.9029436111450195
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29996195435523987
test loss item: 0.3614443242549896
test loss item: 0.26104655861854553
test loss item: 0.24388191103935242
test loss item: 0.3486596643924713
test loss item: 2.1739208698272705
test loss item: 1.181578516960144
test loss item: 1.6020362377166748
test loss item: 0.4968569278717041
test loss item: 3.0913279056549072
test loss item: 0.4294140636920929
test loss item: 0.5676483511924744
test loss item: 0.3767203986644745
test loss item: 0.4774298667907715
test loss item: 0.25155019760131836
test loss item: 0.33522745966911316
test loss item: 0.32908767461776733
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29339343309402466
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [4/10], Training Loss: 0.8013, Testing Loss: 0.6807
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 5/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.7696083784103394
train loss item: 0.7738329172134399
train loss item: 2.1072099208831787
train loss item: 1.4392237663269043
train loss item: 0.5005015730857849
train loss item: 0.3845720589160919
train loss item: 0.3539958596229553
train loss item: 1.3030188083648682
train loss item: 0.7387155294418335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.48472341895103455
train loss item: 0.6403278708457947
train loss item: 0.413040429353714
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8626539707183838
train loss item: 0.324313223361969
train loss item: 0.35225561261177063
train loss item: 0.6438730955123901
train loss item: 0.32586467266082764
train loss item: 0.574292778968811
train loss item: 0.41302573680877686
train loss item: 0.8201944231987
train loss item: 0.36107563972473145
train loss item: 0.4429234266281128
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480510413646698
train loss item: 0.7084197998046875
train loss item: 1.1274973154067993
train loss item: 0.6368315815925598
train loss item: 0.3884425163269043
train loss item: 0.41889122128486633
train loss item: 1.3325780630111694
train loss item: 0.32780951261520386
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44647303223609924
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.807952344417572
train loss item: 0.4614025950431824
train loss item: 0.3634142279624939
train loss item: 0.507057785987854
train loss item: 0.35348328948020935
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3369205892086029
train loss item: 1.6761924028396606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.34206584095954895
train loss item: 2.289836883544922
train loss item: 0.8633443713188171
train loss item: 0.8268972635269165
train loss item: 0.33858802914619446
train loss item: 0.5944257974624634
train loss item: 0.39823782444000244
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.382181316614151
train loss item: 0.6845089793205261
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32874244451522827
train loss item: 0.3081795275211334
train loss item: 1.6619094610214233
train loss item: 0.8459346890449524
train loss item: 3.321760416030884
train loss item: 0.7155598998069763
train loss item: 1.0504289865493774
train loss item: 0.40089112520217896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8821102380752563
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3742945194244385
train loss item: 4.1395344734191895
train loss item: 1.2572300434112549
train loss item: 0.6645398736000061
train loss item: 1.0516414642333984
train loss item: 0.3420185446739197
train loss item: 0.4718320369720459
train loss item: 0.9858909249305725
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7448924779891968
train loss item: 0.3587813079357147
train loss item: 0.2892478406429291
train loss item: 0.446908563375473
train loss item: 0.6241509914398193
train loss item: 0.452237606048584
train loss item: 0.38668879866600037
train loss item: 0.39500245451927185
train loss item: 0.4571174681186676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9703024625778198
train loss item: 1.2268974781036377
train loss item: 0.38222089409828186
train loss item: 0.3834834098815918
train loss item: 0.4158337712287903
train loss item: 0.38689056038856506
train loss item: 0.7324391007423401
train loss item: 0.4568125903606415
train loss item: 0.46983617544174194
train loss item: 0.5018084049224854
train loss item: 0.45918580889701843
train loss item: 0.34954211115837097
train loss item: 0.5389177799224854
train loss item: 0.3717734217643738
train loss item: 2.0475189685821533
train loss item: 0.49729806184768677
train loss item: 0.33280983567237854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4671946167945862
train loss item: 0.34541434049606323
train loss item: 4.116434574127197
train loss item: 0.5871601700782776
train loss item: 0.4871812164783478
train loss item: 0.3709505498409271
train loss item: 0.3285726010799408
train loss item: 0.7077078819274902
train loss item: 0.3541874587535858
train loss item: 0.540101170539856
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39517709612846375
train loss item: 0.4215240776538849
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.4052671194076538
train loss item: 1.6727595329284668
train loss item: 3.5740201473236084
train loss item: 0.3823288679122925
train loss item: 0.33647620677948
train loss item: 0.8517757058143616
train loss item: 0.38571423292160034
train loss item: 0.7971600890159607
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.47017186880111694
train loss item: 0.8344438076019287
train loss item: 1.068676471710205
train loss item: 0.9240391254425049
train loss item: 0.35040900111198425
train loss item: 0.511786937713623
train loss item: 0.36324790120124817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5441670417785645
train loss item: 0.7062374949455261
train loss item: 0.5278030037879944
train loss item: 0.43699127435684204
train loss item: 0.5143771767616272
train loss item: 0.3693526089191437
train loss item: 0.3911777138710022
train loss item: 0.763845682144165
train loss item: 0.35922425985336304
train loss item: 0.3260841965675354
train loss item: 0.566985011100769
train loss item: 0.3556440770626068
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3841143846511841
train loss item: 2.1170198917388916
train loss item: 0.5884301662445068
train loss item: 2.694685697555542
train loss item: 0.4767865240573883
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.328854501247406
train loss item: 0.4874052405357361
train loss item: 0.501418948173523
train loss item: 0.35631272196769714
train loss item: 0.3638763725757599
train loss item: 0.415113240480423
train loss item: 0.3737080991268158
train loss item: 0.41739779710769653
train loss item: 0.5961752533912659
train loss item: 1.011290192604065
train loss item: 1.192165732383728
train loss item: 0.3219052255153656
train loss item: 0.8539865016937256
train loss item: 1.6443272829055786
train loss item: 0.3701934218406677
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.238527774810791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.45275771617889404
train loss item: 0.564845860004425
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7706244382026949
testing phase
test loss item: 0.29242295026779175
test loss item: 0.30694466829299927
test loss item: 0.29486018419265747
test loss item: 0.35904279351234436
test loss item: 1.6190273761749268
test loss item: 0.3806266188621521
test loss item: 0.4854602813720703
test loss item: 0.28538408875465393
test loss item: 0.3793865442276001
test loss item: 0.6268377900123596
test loss item: 0.28131523728370667
test loss item: 0.2499779462814331
test loss item: 2.553192138671875
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9970446825027466
test loss item: 0.24678665399551392
test loss item: 0.34215492010116577
test loss item: 0.5527942180633545
test loss item: 0.7886224985122681
test loss item: 0.6321165561676025
test loss item: 0.2929966449737549
test loss item: 2.3180034160614014
test loss item: 0.24464894831180573
test loss item: 0.38144412636756897
test loss item: 0.3909912705421448
test loss item: 0.30348044633865356
test loss item: 0.6893525719642639
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.40004125237464905
test loss item: 0.24053430557250977
test loss item: 0.3139818608760834
test loss item: 0.3575308918952942
test loss item: 0.31889715790748596
test loss item: 0.4938168525695801
test loss item: 0.9058525562286377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28993189334869385
test loss item: 1.1365634202957153
test loss item: 0.576494038105011
test loss item: 0.3291012942790985
test loss item: 1.4704976081848145
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.45042121410369873
test loss item: 0.6596638560295105
test loss item: 0.41062912344932556
test loss item: 0.6744186282157898
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31618207693099976
test loss item: 0.4390098750591278
test loss item: 0.2503778636455536
test loss item: 0.37895047664642334
test loss item: 0.3856774568557739
test loss item: 0.2797548770904541
test loss item: 0.7690435647964478
test loss item: 0.4659157395362854
test loss item: 0.27144327759742737
test loss item: 0.9397398829460144
test loss item: 0.5116236209869385
test loss item: 0.5636081099510193
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.8889204263687134
test loss item: 0.287923127412796
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.306144654750824
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.295002818107605
test loss item: 1.3412339687347412
test loss item: 0.4607603847980499
test loss item: 0.34314510226249695
test loss item: 1.0258980989456177
test loss item: 0.6652969717979431
test loss item: 1.1410574913024902
test loss item: 0.7935885787010193
test loss item: 1.50518000125885
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.932213544845581
test loss item: 0.4940015971660614
test loss item: 1.1216275691986084
test loss item: 0.5037949681282043
test loss item: 0.29583778977394104
test loss item: 0.5142130851745605
test loss item: 0.3078610599040985
test loss item: 0.31545454263687134
test loss item: 0.31284379959106445
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6879713535308838
test loss item: 0.3925850987434387
test loss item: 0.4154396057128906
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1918821334838867
test loss item: 0.741824746131897
test loss item: 0.3062627911567688
test loss item: 0.3919179439544678
test loss item: 0.6170976758003235
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4367297887802124
test loss item: 0.3697933256626129
test loss item: 1.2174403667449951
test loss item: 1.3939220905303955
test loss item: 0.4974677860736847
test loss item: 1.141736626625061
test loss item: 0.5816168785095215
test loss item: 0.28442710638046265
test loss item: 0.2475801557302475
test loss item: 0.36322134733200073
test loss item: 0.5457797050476074
test loss item: 0.4152674674987793
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.3504875898361206
test loss item: 0.5359073281288147
test loss item: 0.35291677713394165
test loss item: 2.104086399078369
test loss item: 0.2886122763156891
test loss item: 1.4010043144226074
test loss item: 0.6327466368675232
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25237253308296204
test loss item: 0.4452364444732666
test loss item: 0.4997848570346832
test loss item: 0.3531026542186737
test loss item: 0.2538644075393677
test loss item: 0.8711761236190796
test loss item: 0.3172452747821808
test loss item: 0.38651421666145325
test loss item: 0.2968006432056427
test loss item: 0.3677091598510742
test loss item: 0.38730481266975403
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.42791426181793213
test loss item: 2.3819661140441895
test loss item: 0.5190818309783936
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.535728931427002
test loss item: 0.4554807245731354
test loss item: 0.4571572244167328
test loss item: 0.2997739613056183
test loss item: 1.16996169090271
test loss item: 0.3281099498271942
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8774874806404114
test loss item: 0.31678879261016846
test loss item: 0.25283941626548767
test loss item: 0.25049087405204773
test loss item: 1.5056015253067017
test loss item: 0.3969426453113556
test loss item: 1.263473629951477
test loss item: 0.5940310955047607
test loss item: 0.3030366003513336
test loss item: 0.3230897784233093
test loss item: 0.27130836248397827
test loss item: 0.35870254039764404
test loss item: 0.2523728907108307
test loss item: 0.24684946238994598
test loss item: 0.3298105001449585
test loss item: 4.471343040466309
test loss item: 0.29372677206993103
test loss item: 0.8750130534172058
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29182004928588867
test loss item: 0.3476558029651642
test loss item: 0.24619902670383453
test loss item: 0.23692567646503448
test loss item: 0.33756422996520996
test loss item: 2.119381904602051
test loss item: 1.107720136642456
test loss item: 1.5533820390701294
test loss item: 0.46033981442451477
test loss item: 3.059946298599243
test loss item: 0.41607439517974854
test loss item: 0.566013514995575
test loss item: 0.36496686935424805
test loss item: 0.4823894202709198
test loss item: 0.2495037466287613
test loss item: 0.32269343733787537
test loss item: 0.31713828444480896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29266154766082764
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [5/10], Training Loss: 0.7706, Testing Loss: 0.6558
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 6/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.7437087893486023
train loss item: 0.7437713742256165
train loss item: 2.0666611194610596
train loss item: 1.4547584056854248
train loss item: 0.4739750623703003
train loss item: 0.3508828282356262
train loss item: 0.3234092891216278
train loss item: 1.2739440202713013
train loss item: 0.7835104465484619
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647943675518036
train loss item: 0.6195951104164124
train loss item: 0.3989918529987335
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.83207368850708
train loss item: 0.30287811160087585
train loss item: 0.32705992460250854
train loss item: 0.6540850400924683
train loss item: 0.32307741045951843
train loss item: 0.553713858127594
train loss item: 0.3983871340751648
train loss item: 0.8048974275588989
train loss item: 0.34606677293777466
train loss item: 0.42535436153411865
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33705025911331177
train loss item: 0.6835212707519531
train loss item: 1.089398980140686
train loss item: 0.6109908223152161
train loss item: 0.37597376108169556
train loss item: 0.38276466727256775
train loss item: 1.2975618839263916
train loss item: 0.3183952271938324
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4295913279056549
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7786715626716614
train loss item: 0.43221718072891235
train loss item: 0.3559081554412842
train loss item: 0.48468106985092163
train loss item: 0.32916566729545593
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3274155557155609
train loss item: 1.625609278678894
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.32250678539276123
train loss item: 2.256333589553833
train loss item: 0.8248248100280762
train loss item: 0.7831247448921204
train loss item: 0.32505783438682556
train loss item: 0.5658968687057495
train loss item: 0.37843772768974304
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37125566601753235
train loss item: 0.657664954662323
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3204960823059082
train loss item: 0.3045646548271179
train loss item: 1.614041805267334
train loss item: 0.7644869685173035
train loss item: 3.2923824787139893
train loss item: 0.6829583048820496
train loss item: 1.0228385925292969
train loss item: 0.38931605219841003
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8528540134429932
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3485627770423889
train loss item: 4.111616611480713
train loss item: 1.2297002077102661
train loss item: 0.6492116451263428
train loss item: 1.008128046989441
train loss item: 0.3284187912940979
train loss item: 0.4428568184375763
train loss item: 0.9412129521369934
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7195854187011719
train loss item: 0.34543299674987793
train loss item: 0.2819531559944153
train loss item: 0.4309505522251129
train loss item: 0.6133702993392944
train loss item: 0.43492189049720764
train loss item: 0.3658623695373535
train loss item: 0.37986767292022705
train loss item: 0.44018375873565674
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9464237093925476
train loss item: 1.2035741806030273
train loss item: 0.3545955717563629
train loss item: 0.3758346438407898
train loss item: 0.39175179600715637
train loss item: 0.3806363046169281
train loss item: 0.6995801329612732
train loss item: 0.43269583582878113
train loss item: 0.44496119022369385
train loss item: 0.4859105348587036
train loss item: 0.4437786638736725
train loss item: 0.3284643292427063
train loss item: 0.5112730264663696
train loss item: 0.36504316329956055
train loss item: 2.0017402172088623
train loss item: 0.47355973720550537
train loss item: 0.32535889744758606
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4425390660762787
train loss item: 0.3178510069847107
train loss item: 4.0886030197143555
train loss item: 0.5539808869361877
train loss item: 0.4657462239265442
train loss item: 0.35042551159858704
train loss item: 0.318915456533432
train loss item: 0.6950581073760986
train loss item: 0.34033575654029846
train loss item: 0.5144366025924683
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3827149271965027
train loss item: 0.4091763198375702
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.3682557344436646
train loss item: 1.6217763423919678
train loss item: 3.543980598449707
train loss item: 0.35708898305892944
train loss item: 0.3252008557319641
train loss item: 0.8107115626335144
train loss item: 0.37360048294067383
train loss item: 0.7553129196166992
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4545861482620239
train loss item: 0.7977326512336731
train loss item: 0.9332625269889832
train loss item: 0.8923819065093994
train loss item: 0.339046835899353
train loss item: 0.4856336712837219
train loss item: 0.3496454358100891
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.5165325999259949
train loss item: 0.6721661686897278
train loss item: 0.5066771507263184
train loss item: 0.41250136494636536
train loss item: 0.4908815622329712
train loss item: 0.3487595319747925
train loss item: 0.3607846796512604
train loss item: 0.8139474987983704
train loss item: 0.33619898557662964
train loss item: 0.3233568072319031
train loss item: 0.5422070026397705
train loss item: 0.33855047821998596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3711854815483093
train loss item: 2.088186502456665
train loss item: 0.5678302049636841
train loss item: 2.637929677963257
train loss item: 0.46539825201034546
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31939923763275146
train loss item: 0.47557511925697327
train loss item: 0.46110841631889343
train loss item: 0.3283836245536804
train loss item: 0.35422033071517944
train loss item: 0.39511236548423767
train loss item: 0.35176724195480347
train loss item: 0.4055427610874176
train loss item: 0.5598140954971313
train loss item: 0.9668205976486206
train loss item: 1.1445995569229126
train loss item: 0.3026847243309021
train loss item: 0.8137850761413574
train loss item: 1.6032146215438843
train loss item: 0.35565489530563354
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.211021900177002
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43184077739715576
train loss item: 0.5301486849784851
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7472523711621761
testing phase
test loss item: 0.2853342592716217
test loss item: 0.2956409454345703
test loss item: 0.2763412296772003
test loss item: 0.34351977705955505
test loss item: 1.5194257497787476
test loss item: 0.37417250871658325
test loss item: 0.4798023998737335
test loss item: 0.274980753660202
test loss item: 0.35274454951286316
test loss item: 0.5957518219947815
test loss item: 0.2628119885921478
test loss item: 0.2411004900932312
test loss item: 2.4031665325164795
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9368749260902405
test loss item: 0.24098557233810425
test loss item: 0.3278825581073761
test loss item: 0.4997267723083496
test loss item: 0.727429211139679
test loss item: 0.5877865552902222
test loss item: 0.2781693935394287
test loss item: 2.235703468322754
test loss item: 0.23512224853038788
test loss item: 0.37032878398895264
test loss item: 0.3594155013561249
test loss item: 0.2891017496585846
test loss item: 0.6464451551437378
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37411990761756897
test loss item: 0.2290380299091339
test loss item: 0.2992473244667053
test loss item: 0.3420376777648926
test loss item: 0.30307260155677795
test loss item: 0.4816721975803375
test loss item: 0.8388409614562988
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2918868362903595
test loss item: 1.0871968269348145
test loss item: 0.541047990322113
test loss item: 0.28996866941452026
test loss item: 1.3603168725967407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.441199392080307
test loss item: 0.6317411065101624
test loss item: 0.39445099234580994
test loss item: 0.6324725151062012
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3040800988674164
test loss item: 0.4114021956920624
test loss item: 0.2389376163482666
test loss item: 0.38056203722953796
test loss item: 0.3681202530860901
test loss item: 0.26839327812194824
test loss item: 0.7123527526855469
test loss item: 0.43564504384994507
test loss item: 0.256464421749115
test loss item: 0.9131125211715698
test loss item: 0.47762155532836914
test loss item: 0.5229877829551697
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.7973018884658813
test loss item: 0.27950358390808105
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2920204699039459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.284163236618042
test loss item: 1.2565852403640747
test loss item: 0.45255938172340393
test loss item: 0.32960352301597595
test loss item: 0.9527429938316345
test loss item: 0.5878938436508179
test loss item: 1.063238263130188
test loss item: 0.7417483925819397
test loss item: 1.433369755744934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.8187577724456787
test loss item: 0.48014530539512634
test loss item: 1.0488536357879639
test loss item: 0.48642757534980774
test loss item: 0.2752259075641632
test loss item: 0.49390438199043274
test loss item: 0.29315513372421265
test loss item: 0.31459569931030273
test loss item: 0.3075144290924072
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6290170550346375
test loss item: 0.3742712736129761
test loss item: 0.4078744649887085
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1018058061599731
test loss item: 0.7153106331825256
test loss item: 0.29101479053497314
test loss item: 0.39315739274024963
test loss item: 0.5771177411079407
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3878004550933838
test loss item: 0.35083910822868347
test loss item: 1.1446973085403442
test loss item: 1.3254486322402954
test loss item: 0.4978930950164795
test loss item: 1.0120670795440674
test loss item: 0.5283975601196289
test loss item: 0.26087716221809387
test loss item: 0.23632659018039703
test loss item: 0.34641677141189575
test loss item: 0.5081062316894531
test loss item: 0.4093702435493469
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.2374318838119507
test loss item: 0.497432678937912
test loss item: 0.3402155637741089
test loss item: 1.9923672676086426
test loss item: 0.27656662464141846
test loss item: 1.332456111907959
test loss item: 0.5475469827651978
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24077774584293365
test loss item: 0.4162616729736328
test loss item: 0.46637165546417236
test loss item: 0.32362639904022217
test loss item: 0.24347461760044098
test loss item: 0.7955998778343201
test loss item: 0.3036046326160431
test loss item: 0.36911171674728394
test loss item: 0.29079514741897583
test loss item: 0.35584986209869385
test loss item: 0.36776334047317505
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4145348072052002
test loss item: 2.2703583240509033
test loss item: 0.5129919648170471
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5031678676605225
test loss item: 0.44407010078430176
test loss item: 0.4363897740840912
test loss item: 0.2899405360221863
test loss item: 1.1212902069091797
test loss item: 0.3140915036201477
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8311681151390076
test loss item: 0.3023761808872223
test loss item: 0.24213236570358276
test loss item: 0.23973584175109863
test loss item: 1.4098821878433228
test loss item: 0.3664417564868927
test loss item: 1.1438629627227783
test loss item: 0.5719294548034668
test loss item: 0.2972385585308075
test loss item: 0.3105068802833557
test loss item: 0.2661622166633606
test loss item: 0.35373014211654663
test loss item: 0.24815213680267334
test loss item: 0.23465566337108612
test loss item: 0.31489384174346924
test loss item: 4.320677757263184
test loss item: 0.2809644341468811
test loss item: 0.8272011876106262
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2855583131313324
test loss item: 0.331924706697464
test loss item: 0.23570218682289124
test loss item: 0.22722816467285156
test loss item: 0.3313267230987549
test loss item: 2.030010223388672
test loss item: 1.0048447847366333
test loss item: 1.4741171598434448
test loss item: 0.4238664209842682
test loss item: 2.9496610164642334
test loss item: 0.393769770860672
test loss item: 0.5542995929718018
test loss item: 0.35248854756355286
test loss item: 0.48090875148773193
test loss item: 0.24504128098487854
test loss item: 0.3086182773113251
test loss item: 0.30285143852233887
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29328230023384094
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [6/10], Training Loss: 0.7473, Testing Loss: 0.6218
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 7/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.723175048828125
train loss item: 0.718856155872345
train loss item: 2.028942108154297
train loss item: 1.4304053783416748
train loss item: 0.45900553464889526
train loss item: 0.33748161792755127
train loss item: 0.31310099363327026
train loss item: 1.2421724796295166
train loss item: 0.8151156306266785
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4519675076007843
train loss item: 0.6022875308990479
train loss item: 0.38473716378211975
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.8026916980743408
train loss item: 0.287600040435791
train loss item: 0.30573081970214844
train loss item: 0.652103841304779
train loss item: 0.3306933641433716
train loss item: 0.5344435572624207
train loss item: 0.38471439480781555
train loss item: 0.7849844098091125
train loss item: 0.33515018224716187
train loss item: 0.40964803099632263
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3287726640701294
train loss item: 0.6621514558792114
train loss item: 1.0514967441558838
train loss item: 0.5896925330162048
train loss item: 0.36614593863487244
train loss item: 0.36037692427635193
train loss item: 1.2676422595977783
train loss item: 0.3083057403564453
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.41466179490089417
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7532024383544922
train loss item: 0.41358983516693115
train loss item: 0.3455303907394409
train loss item: 0.4698421061038971
train loss item: 0.3146267831325531
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3215275704860687
train loss item: 1.5843149423599243
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3101251423358917
train loss item: 2.220048666000366
train loss item: 0.7976096272468567
train loss item: 0.7521964311599731
train loss item: 0.31254225969314575
train loss item: 0.5406280159950256
train loss item: 0.36393192410469055
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3654620349407196
train loss item: 0.636022686958313
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3111319839954376
train loss item: 0.3127814531326294
train loss item: 1.5739250183105469
train loss item: 0.735058069229126
train loss item: 3.2600882053375244
train loss item: 0.6824032664299011
train loss item: 0.9979923367500305
train loss item: 0.3777829110622406
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.826256513595581
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3405210077762604
train loss item: 4.080611228942871
train loss item: 1.2025891542434692
train loss item: 0.6337785124778748
train loss item: 0.9671251177787781
train loss item: 0.3173796534538269
train loss item: 0.4255298674106598
train loss item: 0.9008482694625854
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.69732666015625
train loss item: 0.33567777276039124
train loss item: 0.27587974071502686
train loss item: 0.4161907136440277
train loss item: 0.5964747071266174
train loss item: 0.42475447058677673
train loss item: 0.35216233134269714
train loss item: 0.36862891912460327
train loss item: 0.42884722352027893
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.924312174320221
train loss item: 1.1783323287963867
train loss item: 0.34544917941093445
train loss item: 0.3645091652870178
train loss item: 0.3730444312095642
train loss item: 0.3705114424228668
train loss item: 0.6758893728256226
train loss item: 0.41454723477363586
train loss item: 0.4214242398738861
train loss item: 0.4737102687358856
train loss item: 0.4317299723625183
train loss item: 0.3111536204814911
train loss item: 0.49499887228012085
train loss item: 0.35472050309181213
train loss item: 1.961248755455017
train loss item: 0.45868903398513794
train loss item: 0.3169795572757721
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4208192527294159
train loss item: 0.3132786750793457
train loss item: 4.057366371154785
train loss item: 0.5287954807281494
train loss item: 0.4487692713737488
train loss item: 0.33699437975883484
train loss item: 0.3130371570587158
train loss item: 0.6779537200927734
train loss item: 0.3303520083427429
train loss item: 0.4945813715457916
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37621408700942993
train loss item: 0.3988354504108429
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.330076813697815
train loss item: 1.579289197921753
train loss item: 3.5126287937164307
train loss item: 0.3340296745300293
train loss item: 0.3169589936733246
train loss item: 0.7846478223800659
train loss item: 0.3635338246822357
train loss item: 0.725496232509613
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.44399502873420715
train loss item: 0.7699281573295593
train loss item: 0.8696199655532837
train loss item: 0.8602725863456726
train loss item: 0.3302028179168701
train loss item: 0.4687436521053314
train loss item: 0.33963802456855774
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4965958893299103
train loss item: 0.6479334235191345
train loss item: 0.48864591121673584
train loss item: 0.39237332344055176
train loss item: 0.47472578287124634
train loss item: 0.33520302176475525
train loss item: 0.3509271442890167
train loss item: 0.8338758945465088
train loss item: 0.31649288535118103
train loss item: 0.33143237233161926
train loss item: 0.5244999527931213
train loss item: 0.324046790599823
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.36128175258636475
train loss item: 2.0560989379882812
train loss item: 0.553006112575531
train loss item: 2.594550609588623
train loss item: 0.45530781149864197
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3091706931591034
train loss item: 0.4647732377052307
train loss item: 0.43392854928970337
train loss item: 0.321036696434021
train loss item: 0.34806233644485474
train loss item: 0.37958210706710815
train loss item: 0.3358091115951538
train loss item: 0.3980853259563446
train loss item: 0.526502251625061
train loss item: 0.9276179671287537
train loss item: 1.1062926054000854
train loss item: 0.2902069091796875
train loss item: 0.7763500809669495
train loss item: 1.5605475902557373
train loss item: 0.3448650538921356
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.180288791656494
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4129044711589813
train loss item: 0.5026814937591553
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7288171799951478
testing phase
test loss item: 0.2819637358188629
test loss item: 0.28770360350608826
test loss item: 0.2636163830757141
test loss item: 0.32420626282691956
test loss item: 1.4288872480392456
test loss item: 0.3625194728374481
test loss item: 0.4617982804775238
test loss item: 0.26610681414604187
test loss item: 0.3336257040500641
test loss item: 0.5699796080589294
test loss item: 0.24983088672161102
test loss item: 0.23368193209171295
test loss item: 2.291015386581421
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8590714335441589
test loss item: 0.23602014780044556
test loss item: 0.31633156538009644
test loss item: 0.45808982849121094
test loss item: 0.6788166761398315
test loss item: 0.5597608089447021
test loss item: 0.2661450207233429
test loss item: 2.1133205890655518
test loss item: 0.22801150381565094
test loss item: 0.34859681129455566
test loss item: 0.3340466320514679
test loss item: 0.2831355929374695
test loss item: 0.6024402379989624
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3543432354927063
test loss item: 0.21825376152992249
test loss item: 0.283079594373703
test loss item: 0.32539498805999756
test loss item: 0.2918989956378937
test loss item: 0.4701578617095947
test loss item: 0.7902490496635437
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29730820655822754
test loss item: 1.0080939531326294
test loss item: 0.5150833129882812
test loss item: 0.26790851354599
test loss item: 1.2812215089797974
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4172869920730591
test loss item: 0.6102413535118103
test loss item: 0.37718501687049866
test loss item: 0.5996302366256714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.29315513372421265
test loss item: 0.3914578855037689
test loss item: 0.23227190971374512
test loss item: 0.3819723129272461
test loss item: 0.35327938199043274
test loss item: 0.26030924916267395
test loss item: 0.6735773086547852
test loss item: 0.4133465886116028
test loss item: 0.24360932409763336
test loss item: 0.8924618363380432
test loss item: 0.45145827531814575
test loss item: 0.49981898069381714
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6961153745651245
test loss item: 0.27212634682655334
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27361127734184265
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27483391761779785
test loss item: 1.1887280941009521
test loss item: 0.42819780111312866
test loss item: 0.3164704442024231
test loss item: 0.8965837359428406
test loss item: 0.5502073168754578
test loss item: 0.9886674284934998
test loss item: 0.7053496837615967
test loss item: 1.356757402420044
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.662095308303833
test loss item: 0.45746007561683655
test loss item: 0.9936001300811768
test loss item: 0.4722396433353424
test loss item: 0.25911158323287964
test loss item: 0.47929394245147705
test loss item: 0.27549582719802856
test loss item: 0.30608054995536804
test loss item: 0.3104345202445984
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5903902053833008
test loss item: 0.3615652024745941
test loss item: 0.38258782029151917
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0399285554885864
test loss item: 0.6907818913459778
test loss item: 0.27336108684539795
test loss item: 0.3880247473716736
test loss item: 0.5458834171295166
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.37311437726020813
test loss item: 0.33674970269203186
test loss item: 1.0839238166809082
test loss item: 1.24315345287323
test loss item: 0.4973806142807007
test loss item: 0.9291477203369141
test loss item: 0.49378570914268494
test loss item: 0.2506822943687439
test loss item: 0.22969000041484833
test loss item: 0.33426618576049805
test loss item: 0.477505624294281
test loss item: 0.3860557973384857
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1626086235046387
test loss item: 0.46582722663879395
test loss item: 0.3280062973499298
test loss item: 1.8719044923782349
test loss item: 0.2678036689758301
test loss item: 1.2578768730163574
test loss item: 0.506523609161377
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2337164729833603
test loss item: 0.3984818756580353
test loss item: 0.43967628479003906
test loss item: 0.29942598938941956
test loss item: 0.23692616820335388
test loss item: 0.7446673512458801
test loss item: 0.28848400712013245
test loss item: 0.3557126522064209
test loss item: 0.287690669298172
test loss item: 0.34375202655792236
test loss item: 0.35258710384368896
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4012581408023834
test loss item: 2.1563503742218018
test loss item: 0.49240854382514954
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.47557532787323
test loss item: 0.4353053867816925
test loss item: 0.4211980402469635
test loss item: 0.28077206015586853
test loss item: 1.0750941038131714
test loss item: 0.3000584542751312
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7197017073631287
test loss item: 0.2867676913738251
test loss item: 0.23224659264087677
test loss item: 0.23271341621875763
test loss item: 1.3371460437774658
test loss item: 0.35128894448280334
test loss item: 1.0693145990371704
test loss item: 0.5551795959472656
test loss item: 0.29413294792175293
test loss item: 0.2961421608924866
test loss item: 0.26193204522132874
test loss item: 0.34087952971458435
test loss item: 0.24544769525527954
test loss item: 0.22542597353458405
test loss item: 0.3025367558002472
test loss item: 4.116911888122559
test loss item: 0.27099350094795227
test loss item: 0.7856810092926025
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2826017737388611
test loss item: 0.31932705640792847
test loss item: 0.22971223294734955
test loss item: 0.21949449181556702
test loss item: 0.3343442678451538
test loss item: 1.9184269905090332
test loss item: 0.9408132433891296
test loss item: 1.3740744590759277
test loss item: 0.4064757525920868
test loss item: 2.7986903190612793
test loss item: 0.37467947602272034
test loss item: 0.5294134020805359
test loss item: 0.3361908793449402
test loss item: 0.48098933696746826
test loss item: 0.2420777678489685
test loss item: 0.2961435317993164
test loss item: 0.28921744227409363
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2992883622646332
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [7/10], Training Loss: 0.7288, Testing Loss: 0.5910
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 8/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.7098458409309387
train loss item: 0.6970778703689575
train loss item: 1.993215560913086
train loss item: 1.361167550086975
train loss item: 0.4433552026748657
train loss item: 0.3333328068256378
train loss item: 0.3102828562259674
train loss item: 1.2063350677490234
train loss item: 0.8118047714233398
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4439007639884949
train loss item: 0.5893954634666443
train loss item: 0.3698454797267914
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7727218866348267
train loss item: 0.27374371886253357
train loss item: 0.2851434350013733
train loss item: 0.6276633143424988
train loss item: 0.3264438509941101
train loss item: 0.5133658647537231
train loss item: 0.37052497267723083
train loss item: 0.7600528001785278
train loss item: 0.324270099401474
train loss item: 0.39370864629745483
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3186584711074829
train loss item: 0.6454132795333862
train loss item: 1.0152084827423096
train loss item: 0.575340986251831
train loss item: 0.3553259074687958
train loss item: 0.34137189388275146
train loss item: 1.2435381412506104
train loss item: 0.29306724667549133
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4008773863315582
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.731844425201416
train loss item: 0.4023657441139221
train loss item: 0.3284552991390228
train loss item: 0.45803284645080566
train loss item: 0.30404379963874817
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.31538671255111694
train loss item: 1.5533117055892944
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3011203706264496
train loss item: 2.1825239658355713
train loss item: 0.7800406217575073
train loss item: 0.7315957546234131
train loss item: 0.29639318585395813
train loss item: 0.5183584690093994
train loss item: 0.3537620007991791
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583802580833435
train loss item: 0.6166451573371887
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2961908280849457
train loss item: 0.3096919357776642
train loss item: 1.5434669256210327
train loss item: 0.7250176072120667
train loss item: 3.2225394248962402
train loss item: 0.6801353096961975
train loss item: 0.975432276725769
train loss item: 0.36429905891418457
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8020622134208679
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.33765748143196106
train loss item: 4.044615268707275
train loss item: 1.174917459487915
train loss item: 0.6165820956230164
train loss item: 0.9317919611930847
train loss item: 0.30421990156173706
train loss item: 0.41483116149902344
train loss item: 0.8679857850074768
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6773892045021057
train loss item: 0.3277986943721771
train loss item: 0.26407402753829956
train loss item: 0.3954724073410034
train loss item: 0.5719655156135559
train loss item: 0.41636985540390015
train loss item: 0.34038442373275757
train loss item: 0.35828423500061035
train loss item: 0.4188620150089264
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.9020735025405884
train loss item: 1.1499011516571045
train loss item: 0.3417537212371826
train loss item: 0.34626662731170654
train loss item: 0.35472482442855835
train loss item: 0.35314419865608215
train loss item: 0.6580479145050049
train loss item: 0.3996224105358124
train loss item: 0.4013262093067169
train loss item: 0.46032166481018066
train loss item: 0.42160987854003906
train loss item: 0.2922847867012024
train loss item: 0.48536011576652527
train loss item: 0.3375800549983978
train loss item: 1.9268697500228882
train loss item: 0.44759947061538696
train loss item: 0.30262506008148193
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.401305228471756
train loss item: 0.3150266408920288
train loss item: 4.020753860473633
train loss item: 0.509464681148529
train loss item: 0.43568670749664307
train loss item: 0.31719741225242615
train loss item: 0.30639827251434326
train loss item: 0.6550703048706055
train loss item: 0.3199657201766968
train loss item: 0.4804512858390808
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3688831031322479
train loss item: 0.3875214755535126
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2929304838180542
train loss item: 1.545644760131836
train loss item: 3.4781038761138916
train loss item: 0.30991798639297485
train loss item: 0.3069058656692505
train loss item: 0.7484599947929382
train loss item: 0.3521009385585785
train loss item: 0.7055948972702026
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.43298038840293884
train loss item: 0.7503966093063354
train loss item: 0.8610623478889465
train loss item: 0.8302368521690369
train loss item: 0.3196645975112915
train loss item: 0.45290619134902954
train loss item: 0.3298962116241455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4801141321659088
train loss item: 0.632495105266571
train loss item: 0.47458669543266296
train loss item: 0.374237596988678
train loss item: 0.4621663987636566
train loss item: 0.31554439663887024
train loss item: 0.34858933091163635
train loss item: 0.8112183809280396
train loss item: 0.2961934208869934
train loss item: 0.3277743458747864
train loss item: 0.512164831161499
train loss item: 0.30690136551856995
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.35072124004364014
train loss item: 2.020768642425537
train loss item: 0.5399312376976013
train loss item: 2.5637624263763428
train loss item: 0.44393324851989746
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2937313914299011
train loss item: 0.4522640109062195
train loss item: 0.417385071516037
train loss item: 0.3195478916168213
train loss item: 0.3309571444988251
train loss item: 0.3678264617919922
train loss item: 0.32141485810279846
train loss item: 0.3885186016559601
train loss item: 0.4946769177913666
train loss item: 0.8951320648193359
train loss item: 1.077818751335144
train loss item: 0.2774108350276947
train loss item: 0.744400680065155
train loss item: 1.5157862901687622
train loss item: 0.33590614795684814
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.143923282623291
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3940907418727875
train loss item: 0.4830005466938019
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.7108607205905413
testing phase
test loss item: 0.28077825903892517
test loss item: 0.2831427752971649
test loss item: 0.2580695152282715
test loss item: 0.30747079849243164
test loss item: 1.368257761001587
test loss item: 0.3469848036766052
test loss item: 0.4426354765892029
test loss item: 0.25912222266197205
test loss item: 0.32450810074806213
test loss item: 0.5540763735771179
test loss item: 0.24309603869915009
test loss item: 0.22931939363479614
test loss item: 2.2108030319213867
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.8056052923202515
test loss item: 0.23406536877155304
test loss item: 0.3098304867744446
test loss item: 0.43529725074768066
test loss item: 0.6524211764335632
test loss item: 0.5449904799461365
test loss item: 0.25941839814186096
test loss item: 2.020453691482544
test loss item: 0.22402743995189667
test loss item: 0.3278222978115082
test loss item: 0.3195866644382477
test loss item: 0.271647185087204
test loss item: 0.5697140693664551
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.34331080317497253
test loss item: 0.21118231117725372
test loss item: 0.2689118981361389
test loss item: 0.3120101988315582
test loss item: 0.285260945558548
test loss item: 0.4573623836040497
test loss item: 0.7665647268295288
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3058246374130249
test loss item: 0.9533483386039734
test loss item: 0.49666595458984375
test loss item: 0.2551496922969818
test loss item: 1.2414391040802002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.39448946714401245
test loss item: 0.5922772288322449
test loss item: 0.3652132749557495
test loss item: 0.5826326012611389
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2842215895652771
test loss item: 0.38101741671562195
test loss item: 0.2295476794242859
test loss item: 0.3875254690647125
test loss item: 0.3432953953742981
test loss item: 0.25575897097587585
test loss item: 0.6536464691162109
test loss item: 0.4023365080356598
test loss item: 0.2341625839471817
test loss item: 0.8755796551704407
test loss item: 0.4366801381111145
test loss item: 0.4859532117843628
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.6206845045089722
test loss item: 0.2691574692726135
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25652697682380676
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.26733604073524475
test loss item: 1.1487840414047241
test loss item: 0.40236181020736694
test loss item: 0.3070700168609619
test loss item: 0.8652639389038086
test loss item: 0.5346792936325073
test loss item: 0.9400052428245544
test loss item: 0.6875262260437012
test loss item: 1.3039321899414062
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.544032335281372
test loss item: 0.4349572956562042
test loss item: 0.9642191529273987
test loss item: 0.46040380001068115
test loss item: 0.2490927278995514
test loss item: 0.46805283427238464
test loss item: 0.25941580533981323
test loss item: 0.2947446405887604
test loss item: 0.31616106629371643
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5746510028839111
test loss item: 0.35291826725006104
test loss item: 0.3556984066963196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0129796266555786
test loss item: 0.6690344214439392
test loss item: 0.257463276386261
test loss item: 0.3752962350845337
test loss item: 0.5315700173377991
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3651319146156311
test loss item: 0.3257102966308594
test loss item: 1.0458858013153076
test loss item: 1.1880532503128052
test loss item: 0.5014374852180481
test loss item: 0.9008611440658569
test loss item: 0.47911226749420166
test loss item: 0.23994792997837067
test loss item: 0.22687427699565887
test loss item: 0.32588207721710205
test loss item: 0.46063026785850525
test loss item: 0.36179929971694946
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.131727933883667
test loss item: 0.44795113801956177
test loss item: 0.3206828534603119
test loss item: 1.7935847043991089
test loss item: 0.2633649706840515
test loss item: 1.203529953956604
test loss item: 0.5023612380027771
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23061822354793549
test loss item: 0.3901066184043884
test loss item: 0.4260311722755432
test loss item: 0.2853231728076935
test loss item: 0.2341378927230835
test loss item: 0.7224438190460205
test loss item: 0.27611643075942993
test loss item: 0.34494084119796753
test loss item: 0.28659266233444214
test loss item: 0.3334982693195343
test loss item: 0.34315726161003113
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.38844287395477295
test loss item: 2.0763285160064697
test loss item: 0.47050294280052185
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4594689905643463
test loss item: 0.4225814640522003
test loss item: 0.41086432337760925
test loss item: 0.2757987380027771
test loss item: 1.043376088142395
test loss item: 0.28928041458129883
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6406581997871399
test loss item: 0.2740798592567444
test loss item: 0.226435586810112
test loss item: 0.22943396866321564
test loss item: 1.2893985509872437
test loss item: 0.34649455547332764
test loss item: 1.0421289205551147
test loss item: 0.540880024433136
test loss item: 0.2938809394836426
test loss item: 0.2811625301837921
test loss item: 0.26153966784477234
test loss item: 0.32962867617607117
test loss item: 0.24620051681995392
test loss item: 0.22032558917999268
test loss item: 0.29354479908943176
test loss item: 3.9512617588043213
test loss item: 0.2655148208141327
test loss item: 0.7575567960739136
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2811620831489563
test loss item: 0.31155624985694885
test loss item: 0.22734268009662628
test loss item: 0.21543505787849426
test loss item: 0.341380774974823
test loss item: 1.8323131799697876
test loss item: 0.9158992767333984
test loss item: 1.3029309511184692
test loss item: 0.39460811018943787
test loss item: 2.6839306354522705
test loss item: 0.3637465536594391
test loss item: 0.5021467208862305
test loss item: 0.318839967250824
test loss item: 0.48700499534606934
test loss item: 0.2424938976764679
test loss item: 0.28725579380989075
test loss item: 0.27877357602119446
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.30815011262893677
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [8/10], Training Loss: 0.7109, Testing Loss: 0.5708
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 9/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.7012327909469604
train loss item: 0.6768987774848938
train loss item: 1.959564447402954
train loss item: 1.2730965614318848
train loss item: 0.4245123267173767
train loss item: 0.32746371626853943
train loss item: 0.30321088433265686
train loss item: 1.1697438955307007
train loss item: 0.7816647887229919
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4375529885292053
train loss item: 0.5793851613998413
train loss item: 0.36056557297706604
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.7435319423675537
train loss item: 0.2636568248271942
train loss item: 0.26824524998664856
train loss item: 0.6041659712791443
train loss item: 0.30960673093795776
train loss item: 0.4925594627857208
train loss item: 0.3610459864139557
train loss item: 0.7348750233650208
train loss item: 0.31261447072029114
train loss item: 0.37968042492866516
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3064850866794586
train loss item: 0.6322617530822754
train loss item: 0.9828314185142517
train loss item: 0.5660059452056885
train loss item: 0.34321141242980957
train loss item: 0.3221050202846527
train loss item: 1.2249256372451782
train loss item: 0.27635854482650757
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.39237332344055176
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.71439528465271
train loss item: 0.3958813548088074
train loss item: 0.3083411157131195
train loss item: 0.44660109281539917
train loss item: 0.2972389757633209
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3084021806716919
train loss item: 1.530341625213623
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2934279143810272
train loss item: 2.146493673324585
train loss item: 0.767556369304657
train loss item: 0.7163669466972351
train loss item: 0.27946630120277405
train loss item: 0.49904075264930725
train loss item: 0.3460235297679901
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3480775058269501
train loss item: 0.5983378291130066
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.27943864464759827
train loss item: 0.2939455211162567
train loss item: 1.5210046768188477
train loss item: 0.7247592210769653
train loss item: 3.1832032203674316
train loss item: 0.6760433912277222
train loss item: 0.9549425840377808
train loss item: 0.3498036563396454
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7805810570716858
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3302747905254364
train loss item: 4.007093906402588
train loss item: 1.1479820013046265
train loss item: 0.5999115705490112
train loss item: 0.9031261205673218
train loss item: 0.2931276857852936
train loss item: 0.4080217480659485
train loss item: 0.8418792486190796
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6597893238067627
train loss item: 0.32146796584129333
train loss item: 0.24960766732692719
train loss item: 0.3697932958602905
train loss item: 0.5459722876548767
train loss item: 0.4065341055393219
train loss item: 0.3288898468017578
train loss item: 0.3475848436355591
train loss item: 0.40844011306762695
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.880405843257904
train loss item: 1.121046543121338
train loss item: 0.3334875702857971
train loss item: 0.32480448484420776
train loss item: 0.33540695905685425
train loss item: 0.33273300528526306
train loss item: 0.6428158283233643
train loss item: 0.38700729608535767
train loss item: 0.38971251249313354
train loss item: 0.44530007243156433
train loss item: 0.4129522740840912
train loss item: 0.27337580919265747
train loss item: 0.47931110858917236
train loss item: 0.31752562522888184
train loss item: 1.8990013599395752
train loss item: 0.43906450271606445
train loss item: 0.2859288454055786
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3845539391040802
train loss item: 0.31036514043807983
train loss item: 3.982544422149658
train loss item: 0.4932782053947449
train loss item: 0.4250364303588867
train loss item: 0.2966454029083252
train loss item: 0.2986525893211365
train loss item: 0.6313495635986328
train loss item: 0.30833685398101807
train loss item: 0.46955808997154236
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3583366572856903
train loss item: 0.37499508261680603
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2596176862716675
train loss item: 1.518908977508545
train loss item: 3.4426724910736084
train loss item: 0.2881893217563629
train loss item: 0.29457002878189087
train loss item: 0.7104032635688782
train loss item: 0.33935871720314026
train loss item: 0.6920673847198486
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.42006558179855347
train loss item: 0.7361637949943542
train loss item: 0.8761228919029236
train loss item: 0.8045116066932678
train loss item: 0.30721744894981384
train loss item: 0.4349144697189331
train loss item: 0.32019585371017456
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4647907316684723
train loss item: 0.6221219301223755
train loss item: 0.46378180384635925
train loss item: 0.3581021726131439
train loss item: 0.4509026110172272
train loss item: 0.29534807801246643
train loss item: 0.3429086208343506
train loss item: 0.7649170160293579
train loss item: 0.2788582742214203
train loss item: 0.3115488588809967
train loss item: 0.5022445917129517
train loss item: 0.2896858751773834
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.339032381772995
train loss item: 1.9852867126464844
train loss item: 0.5266013741493225
train loss item: 2.5412187576293945
train loss item: 0.43140870332717896
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2765684127807617
train loss item: 0.43842560052871704
train loss item: 0.40749555826187134
train loss item: 0.31202223896980286
train loss item: 0.30966389179229736
train loss item: 0.3586636781692505
train loss item: 0.3084482252597809
train loss item: 0.3757885694503784
train loss item: 0.46557512879371643
train loss item: 0.8691501021385193
train loss item: 1.056811809539795
train loss item: 0.26584452390670776
train loss item: 0.719364583492279
train loss item: 1.472780466079712
train loss item: 0.3277837634086609
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.1056928634643555
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3768501877784729
train loss item: 0.4697430729866028
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6934512223264104
testing phase
test loss item: 0.282365083694458
test loss item: 0.28044119477272034
test loss item: 0.2573451101779938
test loss item: 0.29580986499786377
test loss item: 1.3389583826065063
test loss item: 0.33386191725730896
test loss item: 0.42554524540901184
test loss item: 0.2546594738960266
test loss item: 0.32113662362098694
test loss item: 0.5451223850250244
test loss item: 0.24059970676898956
test loss item: 0.22760626673698425
test loss item: 2.148270845413208
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7768157124519348
test loss item: 0.23504094779491425
test loss item: 0.3070046901702881
test loss item: 0.4261167347431183
test loss item: 0.6418741941452026
test loss item: 0.5393230319023132
test loss item: 0.256475567817688
test loss item: 1.981379747390747
test loss item: 0.22233065962791443
test loss item: 0.3114471137523651
test loss item: 0.31291574239730835
test loss item: 0.2600899636745453
test loss item: 0.5466905236244202
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33784735202789307
test loss item: 0.20760931074619293
test loss item: 0.2575719356536865
test loss item: 0.3025002181529999
test loss item: 0.28180843591690063
test loss item: 0.4456108808517456
test loss item: 0.7574329376220703
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3145149052143097
test loss item: 0.9282698035240173
test loss item: 0.48121634125709534
test loss item: 0.24847756326198578
test loss item: 1.222659945487976
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3761123716831207
test loss item: 0.5759959816932678
test loss item: 0.3575979471206665
test loss item: 0.579430103302002
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2779795229434967
test loss item: 0.37643274664878845
test loss item: 0.228834331035614
test loss item: 0.39619573950767517
test loss item: 0.33690181374549866
test loss item: 0.25325947999954224
test loss item: 0.6430351734161377
test loss item: 0.3981170058250427
test loss item: 0.22844967246055603
test loss item: 0.8616468906402588
test loss item: 0.4297161400318146
test loss item: 0.47900480031967163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5781680345535278
test loss item: 0.2701011002063751
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.24338659644126892
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2622242867946625
test loss item: 1.1302707195281982
test loss item: 0.38050466775894165
test loss item: 0.30076080560684204
test loss item: 0.8508455753326416
test loss item: 0.5220655202865601
test loss item: 0.9063291549682617
test loss item: 0.6805486083030701
test loss item: 1.2712759971618652
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4935593605041504
test loss item: 0.41536158323287964
test loss item: 0.9533884525299072
test loss item: 0.45014894008636475
test loss item: 0.24371987581253052
test loss item: 0.45786529779434204
test loss item: 0.24678707122802734
test loss item: 0.2938235402107239
test loss item: 0.31651389598846436
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5717474818229675
test loss item: 0.3462812602519989
test loss item: 0.33341896533966064
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.0040059089660645
test loss item: 0.6506787538528442
test loss item: 0.24487128853797913
test loss item: 0.36312049627304077
test loss item: 0.5328987240791321
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3523850739002228
test loss item: 0.3163529932498932
test loss item: 1.0244810581207275
test loss item: 1.1623117923736572
test loss item: 0.5089188814163208
test loss item: 0.896575927734375
test loss item: 0.47578227519989014
test loss item: 0.23195037245750427
test loss item: 0.22603535652160645
test loss item: 0.31984540820121765
test loss item: 0.45366373658180237
test loss item: 0.34104615449905396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.1202834844589233
test loss item: 0.44022881984710693
test loss item: 0.3182808458805084
test loss item: 1.763745665550232
test loss item: 0.2616625726222992
test loss item: 1.1668223142623901
test loss item: 0.5099415183067322
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.22965416312217712
test loss item: 0.38718289136886597
test loss item: 0.4212735593318939
test loss item: 0.2787012755870819
test loss item: 0.23359562456607819
test loss item: 0.7180608510971069
test loss item: 0.26723167300224304
test loss item: 0.33579355478286743
test loss item: 0.2880505323410034
test loss item: 0.3257860243320465
test loss item: 0.3367242217063904
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3769392967224121
test loss item: 2.0355801582336426
test loss item: 0.45055946707725525
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.451669305562973
test loss item: 0.40830886363983154
test loss item: 0.40289443731307983
test loss item: 0.2748531401157379
test loss item: 1.0275343656539917
test loss item: 0.28145653009414673
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6158629059791565
test loss item: 0.26500403881073
test loss item: 0.22463010251522064
test loss item: 0.22839811444282532
test loss item: 1.2514631748199463
test loss item: 0.3470570147037506
test loss item: 1.0347506999969482
test loss item: 0.5280968546867371
test loss item: 0.2961086630821228
test loss item: 0.27067068219184875
test loss item: 0.2644839286804199
test loss item: 0.3331437408924103
test loss item: 0.2498260736465454
test loss item: 0.21815115213394165
test loss item: 0.2876688838005066
test loss item: 3.8713436126708984
test loss item: 0.2632518410682678
test loss item: 0.7394022941589355
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.282009482383728
test loss item: 0.3076792359352112
test loss item: 0.22702088952064514
test loss item: 0.2143334150314331
test loss item: 0.34517231583595276
test loss item: 1.7852048873901367
test loss item: 0.9105796813964844
test loss item: 1.2673653364181519
test loss item: 0.3862597942352295
test loss item: 2.6340463161468506
test loss item: 0.3590925931930542
test loss item: 0.4798412322998047
test loss item: 0.306316077709198
test loss item: 0.49704980850219727
test loss item: 0.2456704080104828
test loss item: 0.2806437611579895
test loss item: 0.2708780765533447
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.31573575735092163
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [9/10], Training Loss: 0.6935, Testing Loss: 0.5601
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
Epoch 10/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 0.693540632724762
train loss item: 0.6579349637031555
train loss item: 1.928483247756958
train loss item: 1.1928136348724365
train loss item: 0.40681248903274536
train loss item: 0.3173936903476715
train loss item: 0.2905552089214325
train loss item: 1.136673092842102
train loss item: 0.7322322130203247
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4317569434642792
train loss item: 0.5698574185371399
train loss item: 0.3535853922367096
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.717613935470581
train loss item: 0.25894397497177124
train loss item: 0.2580583393573761
train loss item: 0.5890412330627441
train loss item: 0.29087549448013306
train loss item: 0.47456738352775574
train loss item: 0.35363325476646423
train loss item: 0.7146875262260437
train loss item: 0.30186089873313904
train loss item: 0.3687035143375397
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.29473981261253357
train loss item: 0.6211012005805969
train loss item: 0.9554638862609863
train loss item: 0.5585214495658875
train loss item: 0.3318652808666229
train loss item: 0.30660611391067505
train loss item: 1.2095849514007568
train loss item: 0.26302003860473633
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3856435716152191
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7001263499259949
train loss item: 0.39076924324035645
train loss item: 0.2909272015094757
train loss item: 0.4353330731391907
train loss item: 0.2934657633304596
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3020230829715729
train loss item: 1.5108436346054077
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.28752565383911133
train loss item: 2.1144323348999023
train loss item: 0.7548717856407166
train loss item: 0.7015661597251892
train loss item: 0.2655992805957794
train loss item: 0.4824598729610443
train loss item: 0.339358389377594
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3373473882675171
train loss item: 0.5819714665412903
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2661121189594269
train loss item: 0.27563580870628357
train loss item: 1.5024704933166504
train loss item: 0.7264050841331482
train loss item: 3.1469216346740723
train loss item: 0.6701516509056091
train loss item: 0.9373541474342346
train loss item: 0.33666372299194336
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.7623443603515625
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3192974925041199
train loss item: 3.9725024700164795
train loss item: 1.1234350204467773
train loss item: 0.5868390202522278
train loss item: 0.8784924745559692
train loss item: 0.28700289130210876
train loss item: 0.40265190601348877
train loss item: 0.818615734577179
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.6450898051261902
train loss item: 0.31625646352767944
train loss item: 0.23847685754299164
train loss item: 0.34598883986473083
train loss item: 0.5259736776351929
train loss item: 0.3959523141384125
train loss item: 0.31735894083976746
train loss item: 0.3372364044189453
train loss item: 0.3983061611652374
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.8612839579582214
train loss item: 1.0949510335922241
train loss item: 0.32029056549072266
train loss item: 0.3059912919998169
train loss item: 0.31798598170280457
train loss item: 0.3149357736110687
train loss item: 0.6279577016830444
train loss item: 0.37705492973327637
train loss item: 0.38158321380615234
train loss item: 0.4312494099140167
train loss item: 0.40601539611816406
train loss item: 0.25878503918647766
train loss item: 0.47405463457107544
train loss item: 0.30011799931526184
train loss item: 1.8759403228759766
train loss item: 0.43228986859321594
train loss item: 0.27250176668167114
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.37063175439834595
train loss item: 0.29902151226997375
train loss item: 3.947033166885376
train loss item: 0.478669673204422
train loss item: 0.41550976037979126
train loss item: 0.2823288142681122
train loss item: 0.2913677394390106
train loss item: 0.6122833490371704
train loss item: 0.29741814732551575
train loss item: 0.45951148867607117
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3470873236656189
train loss item: 0.36318981647491455
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 1.2315360307693481
train loss item: 1.4951473474502563
train loss item: 3.4098076820373535
train loss item: 0.2728656232357025
train loss item: 0.28271758556365967
train loss item: 0.6820204257965088
train loss item: 0.32747241854667664
train loss item: 0.6805041432380676
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.40764039754867554
train loss item: 0.7225446701049805
train loss item: 0.8893114328384399
train loss item: 0.7829195261001587
train loss item: 0.29536300897598267
train loss item: 0.41791871190071106
train loss item: 0.31172215938568115
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.4493716061115265
train loss item: 0.6113709807395935
train loss item: 0.45497411489486694
train loss item: 0.3454032242298126
train loss item: 0.4403054714202881
train loss item: 0.2816068232059479
train loss item: 0.3324041962623596
train loss item: 0.711246907711029
train loss item: 0.26826685667037964
train loss item: 0.2934325337409973
train loss item: 0.4922246038913727
train loss item: 0.2767014801502228
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3281143307685852
train loss item: 1.952993392944336
train loss item: 0.5135407447814941
train loss item: 2.5215725898742676
train loss item: 0.4196229577064514
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.2626209855079651
train loss item: 0.4253860414028168
train loss item: 0.39951568841934204
train loss item: 0.29863911867141724
train loss item: 0.29291844367980957
train loss item: 0.35073089599609375
train loss item: 0.29881617426872253
train loss item: 0.36321255564689636
train loss item: 0.44291359186172485
train loss item: 0.846362829208374
train loss item: 1.039322853088379
train loss item: 0.25906282663345337
train loss item: 0.698800802230835
train loss item: 1.4358466863632202
train loss item: 0.3205110430717468
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 5.070176601409912
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: 0.3621932864189148
train loss item: 0.45830103754997253
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 0.6778509462938497
testing phase
test loss item: 0.28452709317207336
test loss item: 0.27750322222709656
test loss item: 0.25660592317581177
test loss item: 0.28746941685676575
test loss item: 1.321226716041565
test loss item: 0.3246355652809143
test loss item: 0.4118399918079376
test loss item: 0.2510794401168823
test loss item: 0.31499814987182617
test loss item: 0.5332053303718567
test loss item: 0.23807156085968018
test loss item: 0.22704005241394043
test loss item: 2.09433650970459
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.7621927261352539
test loss item: 0.23657387495040894
test loss item: 0.30435454845428467
test loss item: 0.4238494038581848
test loss item: 0.6357289552688599
test loss item: 0.5361410975456238
test loss item: 0.25369006395339966
test loss item: 1.9749102592468262
test loss item: 0.2212529480457306
test loss item: 0.29852238297462463
test loss item: 0.3097169101238251
test loss item: 0.2544027268886566
test loss item: 0.5292916893959045
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33083000779151917
test loss item: 0.20523539185523987
test loss item: 0.24806785583496094
test loss item: 0.29494965076446533
test loss item: 0.27942851185798645
test loss item: 0.4357629120349884
test loss item: 0.7400079369544983
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32113826274871826
test loss item: 0.920724093914032
test loss item: 0.46982401609420776
test loss item: 0.24528712034225464
test loss item: 1.185249924659729
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.362166166305542
test loss item: 0.5612934231758118
test loss item: 0.35104185342788696
test loss item: 0.5727723240852356
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.27274641394615173
test loss item: 0.3718791604042053
test loss item: 0.22806613147258759
test loss item: 0.40313056111335754
test loss item: 0.330289751291275
test loss item: 0.2508367896080017
test loss item: 0.6369820833206177
test loss item: 0.3908909857273102
test loss item: 0.22380997240543365
test loss item: 0.8493472337722778
test loss item: 0.42159050703048706
test loss item: 0.47637856006622314
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.5565128326416016
test loss item: 0.2715296447277069
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.23315978050231934
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.25791722536087036
test loss item: 1.107936978340149
test loss item: 0.36367860436439514
test loss item: 0.29578182101249695
test loss item: 0.8318454027175903
test loss item: 0.5096808671951294
test loss item: 0.8839001655578613
test loss item: 0.674142599105835
test loss item: 1.250388503074646
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 2.4805564880371094
test loss item: 0.3992727994918823
test loss item: 0.9416117668151855
test loss item: 0.4406156539916992
test loss item: 0.23910972476005554
test loss item: 0.4481288492679596
test loss item: 0.2365357130765915
test loss item: 0.3032166361808777
test loss item: 0.3124372363090515
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.5640472173690796
test loss item: 0.34034740924835205
test loss item: 0.3170192241668701
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.9854164719581604
test loss item: 0.6356996893882751
test loss item: 0.23460397124290466
test loss item: 0.35497158765792847
test loss item: 0.5337303280830383
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.33994415402412415
test loss item: 0.3088575005531311
test loss item: 1.004417896270752
test loss item: 1.1520648002624512
test loss item: 0.5141924023628235
test loss item: 0.8914554119110107
test loss item: 0.4720558226108551
test loss item: 0.23125404119491577
test loss item: 0.22518108785152435
test loss item: 0.3148360252380371
test loss item: 0.44583502411842346
test loss item: 0.325125515460968
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 1.096725583076477
test loss item: 0.43123266100883484
test loss item: 0.31686681509017944
test loss item: 1.7535173892974854
test loss item: 0.2599175274372101
test loss item: 1.1437129974365234
test loss item: 0.5116574168205261
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.2286386638879776
test loss item: 0.38350096344947815
test loss item: 0.414139062166214
test loss item: 0.27577486634254456
test loss item: 0.23347342014312744
test loss item: 0.7135480046272278
test loss item: 0.2603089511394501
test loss item: 0.32836464047431946
test loss item: 0.29025208950042725
test loss item: 0.3176661729812622
test loss item: 0.3313581049442291
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.3665529489517212
test loss item: 2.010576009750366
test loss item: 0.43474280834198
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.4437514543533325
test loss item: 0.39633071422576904
test loss item: 0.39585283398628235
test loss item: 0.27430036664009094
test loss item: 1.014485239982605
test loss item: 0.27508360147476196
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.6246717572212219
test loss item: 0.2579965591430664
test loss item: 0.22365611791610718
test loss item: 0.22756364941596985
test loss item: 1.2180849313735962
test loss item: 0.34877100586891174
test loss item: 1.0104024410247803
test loss item: 0.5164872407913208
test loss item: 0.2987266182899475
test loss item: 0.2652544677257538
test loss item: 0.2675512135028839
test loss item: 0.3473600149154663
test loss item: 0.2536630928516388
test loss item: 0.21660175919532776
test loss item: 0.28258031606674194
test loss item: 3.838916540145874
test loss item: 0.26144176721572876
test loss item: 0.7256470918655396
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.28355398774147034
test loss item: 0.3036065697669983
test loss item: 0.22669397294521332
test loss item: 0.21362309157848358
test loss item: 0.3461401164531708
test loss item: 1.7638906240463257
test loss item: 0.9051079154014587
test loss item: 1.2534953355789185
test loss item: 0.38197052478790283
test loss item: 2.61982798576355
test loss item: 0.35264548659324646
test loss item: 0.4642265737056732
test loss item: 0.29921862483024597
test loss item: 0.5061467885971069
test loss item: 0.24907204508781433
test loss item: 0.2750127911567688
test loss item: 0.264115571975708
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: 0.32083743810653687
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
test loss item: nan
NaN encountered in loss calculation. Skipping this instance.
Epoch [10/10], Training Loss: 0.6779, Testing Loss: 0.5525
Best model saved!
Before cleanup - Allocated memory: 5696.27 MB, Reserved memory: 9962.00 MB
After cleanup - Allocated memory: 5696.27 MB, Reserved memory: 5814.00 MB
val loss item: 0.6908563375473022
UNet6 with 1 10 0.0001 256 360 done at Thu Nov 14 12:22:57 CET 2024
SBATCH job finished
